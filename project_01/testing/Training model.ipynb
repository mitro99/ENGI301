{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "def wavelet(data, level, wavelet):\n",
    "    (cA, cD) = pywt.dwt(data, wavelet=wavelet)\n",
    "    for i in range(1, level):\n",
    "        (cA, cD) = pywt.dwt(cA, wavelet=wavelet)\n",
    "    return cA, cD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gestures = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10\n",
    "]\n",
    "num_samples = 50\n",
    "num_gestures = len(gestures)\n",
    "\n",
    "one_hot = np.eye(len(gestures))\n",
    "\n",
    "\n",
    "\n",
    "fulldata = pd.DataFrame(columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "fullwavedata = pd.DataFrame(columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'])\n",
    "formatdata = pd.DataFrame()\n",
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "labels = []\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        filepath = 'hand/hand_{0}_{1}.csv'.format(gesture, i)\n",
    "        data = pd.read_csv(filepath, index_col=False)\n",
    "        wavedata = pd.DataFrame()\n",
    "        \n",
    "        level1 = 5\n",
    "        wavetype1 = 'db20'\n",
    "        \n",
    "        wavedata['aX_A1'], wavedata['aX_D1'] = wavelet(data['aX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aY_A1'], wavedata['aY_D1'] = wavelet(data['aY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aZ_A1'], wavedata['aZ_D1'] = wavelet(data['aZ'], level=level1, wavelet=wavetype1)\n",
    "\n",
    "        wavedata['gX_A1'], wavedata['gX_D1'] = wavelet(data['gX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gY_A1'], wavedata['gY_D1'] = wavelet(data['gY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gZ_A1'], wavedata['gZ_D1'] = wavelet(data['gZ'], level=level1, wavelet=wavetype1)\n",
    "        \n",
    "        level2 = 3\n",
    "        wavetype2 = 'rbio2.2'\n",
    "\n",
    "        wavedata['aX_A2'], wavedata['aX_D2'] = wavelet(data['aX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aY_A2'], wavedata['aY_D2'] = wavelet(data['aY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aZ_A2'], wavedata['aZ_D2'] = wavelet(data['aZ'], level=level2, wavelet=wavetype2)\n",
    "\n",
    "        wavedata['gX_A2'], wavedata['gX_D2'] = wavelet(data['gX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gY_A2'], wavedata['gY_D2'] = wavelet(data['gY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gZ_A2'], wavedata['gZ_D2'] = wavelet(data['gZ'], level=level2, wavelet=wavetype2)\n",
    "        \n",
    "        wavelen = len(wavedata)\n",
    "        \n",
    "        fullwavedata = fullwavedata.append(wavedata)\n",
    "        fulldata = fulldata.append(data)\n",
    "        label = gesture\n",
    "        labels.append(label)\n",
    "        #del data, wavedata\n",
    "\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX</th>\n",
       "      <th>aY</th>\n",
       "      <th>aZ</th>\n",
       "      <th>gX</th>\n",
       "      <th>gY</th>\n",
       "      <th>gZ</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.579977</td>\n",
       "      <td>-7.139509</td>\n",
       "      <td>3.031059</td>\n",
       "      <td>-1.203078</td>\n",
       "      <td>-1.997403</td>\n",
       "      <td>-2.221498</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.735600</td>\n",
       "      <td>-7.965509</td>\n",
       "      <td>3.031059</td>\n",
       "      <td>-1.054392</td>\n",
       "      <td>-2.066683</td>\n",
       "      <td>-2.209773</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.965444</td>\n",
       "      <td>-8.616732</td>\n",
       "      <td>2.918532</td>\n",
       "      <td>-0.877461</td>\n",
       "      <td>-2.145289</td>\n",
       "      <td>-2.162609</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11.042058</td>\n",
       "      <td>-9.119514</td>\n",
       "      <td>2.705448</td>\n",
       "      <td>-0.444193</td>\n",
       "      <td>-2.352331</td>\n",
       "      <td>-1.929721</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.187328</td>\n",
       "      <td>-9.586383</td>\n",
       "      <td>2.731784</td>\n",
       "      <td>-0.259801</td>\n",
       "      <td>-2.428539</td>\n",
       "      <td>-1.797822</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-9.746795</td>\n",
       "      <td>-0.210690</td>\n",
       "      <td>-0.208296</td>\n",
       "      <td>-0.028778</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-9.818621</td>\n",
       "      <td>-0.215478</td>\n",
       "      <td>-0.232238</td>\n",
       "      <td>-0.022649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020784</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-9.734824</td>\n",
       "      <td>-0.234632</td>\n",
       "      <td>-0.260968</td>\n",
       "      <td>-0.019985</td>\n",
       "      <td>-0.004530</td>\n",
       "      <td>0.030377</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-9.732430</td>\n",
       "      <td>-0.177171</td>\n",
       "      <td>-0.320823</td>\n",
       "      <td>-0.017054</td>\n",
       "      <td>-0.014123</td>\n",
       "      <td>0.031709</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-9.756372</td>\n",
       "      <td>-0.186748</td>\n",
       "      <td>-0.205901</td>\n",
       "      <td>-0.011191</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>0.036505</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aX        aY        aZ        gX        gY        gZ  Unnamed: 0\n",
       "0   -10.579977 -7.139509  3.031059 -1.203078 -1.997403 -2.221498         NaN\n",
       "1   -10.735600 -7.965509  3.031059 -1.054392 -2.066683 -2.209773         NaN\n",
       "2   -10.965444 -8.616732  2.918532 -0.877461 -2.145289 -2.162609         NaN\n",
       "3   -11.042058 -9.119514  2.705448 -0.444193 -2.352331 -1.929721         NaN\n",
       "4   -10.187328 -9.586383  2.731784 -0.259801 -2.428539 -1.797822         NaN\n",
       "..         ...       ...       ...       ...       ...       ...         ...\n",
       "345  -9.746795 -0.210690 -0.208296 -0.028778  0.008527 -0.000266         NaN\n",
       "346  -9.818621 -0.215478 -0.232238 -0.022649  0.000000  0.020784         NaN\n",
       "347  -9.734824 -0.234632 -0.260968 -0.019985 -0.004530  0.030377         NaN\n",
       "348  -9.732430 -0.177171 -0.320823 -0.017054 -0.014123  0.031709         NaN\n",
       "349  -9.756372 -0.186748 -0.205901 -0.011191 -0.015721  0.036505         NaN\n",
       "\n",
       "[192500 rows x 7 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata = fulldata.iloc[0:, 0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX</th>\n",
       "      <th>aY</th>\n",
       "      <th>aZ</th>\n",
       "      <th>gX</th>\n",
       "      <th>gY</th>\n",
       "      <th>gZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.579977</td>\n",
       "      <td>-7.139509</td>\n",
       "      <td>3.031059</td>\n",
       "      <td>-1.203078</td>\n",
       "      <td>-1.997403</td>\n",
       "      <td>-2.221498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.735600</td>\n",
       "      <td>-7.965509</td>\n",
       "      <td>3.031059</td>\n",
       "      <td>-1.054392</td>\n",
       "      <td>-2.066683</td>\n",
       "      <td>-2.209773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.965444</td>\n",
       "      <td>-8.616732</td>\n",
       "      <td>2.918532</td>\n",
       "      <td>-0.877461</td>\n",
       "      <td>-2.145289</td>\n",
       "      <td>-2.162609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11.042058</td>\n",
       "      <td>-9.119514</td>\n",
       "      <td>2.705448</td>\n",
       "      <td>-0.444193</td>\n",
       "      <td>-2.352331</td>\n",
       "      <td>-1.929721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.187328</td>\n",
       "      <td>-9.586383</td>\n",
       "      <td>2.731784</td>\n",
       "      <td>-0.259801</td>\n",
       "      <td>-2.428539</td>\n",
       "      <td>-1.797822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-9.746795</td>\n",
       "      <td>-0.210690</td>\n",
       "      <td>-0.208296</td>\n",
       "      <td>-0.028778</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>-0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-9.818621</td>\n",
       "      <td>-0.215478</td>\n",
       "      <td>-0.232238</td>\n",
       "      <td>-0.022649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-9.734824</td>\n",
       "      <td>-0.234632</td>\n",
       "      <td>-0.260968</td>\n",
       "      <td>-0.019985</td>\n",
       "      <td>-0.004530</td>\n",
       "      <td>0.030377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-9.732430</td>\n",
       "      <td>-0.177171</td>\n",
       "      <td>-0.320823</td>\n",
       "      <td>-0.017054</td>\n",
       "      <td>-0.014123</td>\n",
       "      <td>0.031709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-9.756372</td>\n",
       "      <td>-0.186748</td>\n",
       "      <td>-0.205901</td>\n",
       "      <td>-0.011191</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>0.036505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aX        aY        aZ        gX        gY        gZ\n",
       "0   -10.579977 -7.139509  3.031059 -1.203078 -1.997403 -2.221498\n",
       "1   -10.735600 -7.965509  3.031059 -1.054392 -2.066683 -2.209773\n",
       "2   -10.965444 -8.616732  2.918532 -0.877461 -2.145289 -2.162609\n",
       "3   -11.042058 -9.119514  2.705448 -0.444193 -2.352331 -1.929721\n",
       "4   -10.187328 -9.586383  2.731784 -0.259801 -2.428539 -1.797822\n",
       "..         ...       ...       ...       ...       ...       ...\n",
       "345  -9.746795 -0.210690 -0.208296 -0.028778  0.008527 -0.000266\n",
       "346  -9.818621 -0.215478 -0.232238 -0.022649  0.000000  0.020784\n",
       "347  -9.734824 -0.234632 -0.260968 -0.019985 -0.004530  0.030377\n",
       "348  -9.732430 -0.177171 -0.320823 -0.017054 -0.014123  0.031709\n",
       "349  -9.756372 -0.186748 -0.205901 -0.011191 -0.015721  0.036505\n",
       "\n",
       "[192500 rows x 6 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX</th>\n",
       "      <th>aY</th>\n",
       "      <th>aZ</th>\n",
       "      <th>gX</th>\n",
       "      <th>gY</th>\n",
       "      <th>gZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.400953</td>\n",
       "      <td>0.508082</td>\n",
       "      <td>0.541712</td>\n",
       "      <td>0.499318</td>\n",
       "      <td>0.427822</td>\n",
       "      <td>0.502331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.074306</td>\n",
       "      <td>0.068467</td>\n",
       "      <td>0.085276</td>\n",
       "      <td>0.096042</td>\n",
       "      <td>0.095247</td>\n",
       "      <td>0.095711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.377844</td>\n",
       "      <td>0.486061</td>\n",
       "      <td>0.488569</td>\n",
       "      <td>0.484298</td>\n",
       "      <td>0.406824</td>\n",
       "      <td>0.492653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.388312</td>\n",
       "      <td>0.508553</td>\n",
       "      <td>0.539899</td>\n",
       "      <td>0.505739</td>\n",
       "      <td>0.420533</td>\n",
       "      <td>0.502602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.411963</td>\n",
       "      <td>0.535409</td>\n",
       "      <td>0.591876</td>\n",
       "      <td>0.521076</td>\n",
       "      <td>0.432317</td>\n",
       "      <td>0.517067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aX             aY             aZ             gX  \\\n",
       "count  192500.000000  192500.000000  192500.000000  192500.000000   \n",
       "mean        0.400953       0.508082       0.541712       0.499318   \n",
       "std         0.074306       0.068467       0.085276       0.096042   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.377844       0.486061       0.488569       0.484298   \n",
       "50%         0.388312       0.508553       0.539899       0.505739   \n",
       "75%         0.411963       0.535409       0.591876       0.521076   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  gY             gZ  \n",
       "count  192500.000000  192500.000000  \n",
       "mean        0.427822       0.502331  \n",
       "std         0.095247       0.095711  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.406824       0.492653  \n",
       "50%         0.420533       0.502602  \n",
       "75%         0.432317       0.517067  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normaldata = (fulldata - fulldata.min()) / (fulldata.max()-fulldata.min())\n",
    "normaldata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-39.2266  , -39.2266  , -14.848839,  -7.023951,  -5.979951,\n",
       "        -8.731442,   0.      ], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = np.array(fulldata.min(), dtype='float32')\n",
    "maxval = np.array(fulldata.max(), dtype='float32')\n",
    "\n",
    "parameters_full = pd.DataFrame([minval, maxval], columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "parameters_full.to_csv('parameters_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36514839, 0.40900282, 0.53687994, ..., 0.49930897, 0.43952637,\n",
       "        0.49567407],\n",
       "       [0.36826123, 0.55677119, 0.61452193, ..., 0.50932893, 0.42393172,\n",
       "        0.49123369],\n",
       "       [0.37146563, 0.4280766 , 0.58713156, ..., 0.50639205, 0.42553788,\n",
       "        0.49358358],\n",
       "       ...,\n",
       "       [0.3648127 , 0.37119097, 0.40265996, ..., 0.50357033, 0.42159719,\n",
       "        0.49990082],\n",
       "       [0.38944076, 0.36267643, 0.41401869, ..., 0.50669917, 0.41905722,\n",
       "        0.51453422],\n",
       "       [0.37061112, 0.37793545, 0.42573688, ..., 0.50518274, 0.41803003,\n",
       "        0.50209812]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatdata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*350 + (i-1) * 350\n",
    "        #print(index, index+250)\n",
    "        dataf = normaldata.iloc[index:index+350].to_numpy().flatten().tolist()\n",
    "        formatdata[idx*num_samples+i-1] = dataf\n",
    "        del dataf\n",
    "        \n",
    "        \n",
    "formatdata = formatdata.transpose().to_numpy()\n",
    "formatdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2100"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formatdata[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = np.array(fullwavedata.min(), dtype='float32')\n",
    "maxval = np.array(fullwavedata.max(), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pd.DataFrame([minval, maxval], columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'], index=['min','max'])\n",
    "parameters.to_csv('dataparameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX_A1</th>\n",
       "      <th>aX_D1</th>\n",
       "      <th>aY_A1</th>\n",
       "      <th>aY_D1</th>\n",
       "      <th>aZ_A1</th>\n",
       "      <th>aZ_D1</th>\n",
       "      <th>gX_A1</th>\n",
       "      <th>gX_D1</th>\n",
       "      <th>gY_A1</th>\n",
       "      <th>gY_D1</th>\n",
       "      <th>...</th>\n",
       "      <th>aY_A2</th>\n",
       "      <th>aY_D2</th>\n",
       "      <th>aZ_A2</th>\n",
       "      <th>aZ_D2</th>\n",
       "      <th>gX_A2</th>\n",
       "      <th>gX_D2</th>\n",
       "      <th>gY_A2</th>\n",
       "      <th>gY_D2</th>\n",
       "      <th>gZ_A2</th>\n",
       "      <th>gZ_D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.267300</td>\n",
       "      <td>0.474299</td>\n",
       "      <td>0.532783</td>\n",
       "      <td>0.475571</td>\n",
       "      <td>0.587976</td>\n",
       "      <td>0.513237</td>\n",
       "      <td>0.493822</td>\n",
       "      <td>0.496712</td>\n",
       "      <td>0.483855</td>\n",
       "      <td>0.515383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432839</td>\n",
       "      <td>0.449727</td>\n",
       "      <td>0.558324</td>\n",
       "      <td>0.521365</td>\n",
       "      <td>0.500183</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.410186</td>\n",
       "      <td>0.521206</td>\n",
       "      <td>0.502551</td>\n",
       "      <td>0.583230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.123643</td>\n",
       "      <td>0.066293</td>\n",
       "      <td>0.116047</td>\n",
       "      <td>0.059190</td>\n",
       "      <td>0.129127</td>\n",
       "      <td>0.080489</td>\n",
       "      <td>0.125645</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.116264</td>\n",
       "      <td>0.072924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083774</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.097088</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.102759</td>\n",
       "      <td>0.048254</td>\n",
       "      <td>0.099510</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>0.090144</td>\n",
       "      <td>0.035227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.193030</td>\n",
       "      <td>0.451570</td>\n",
       "      <td>0.475979</td>\n",
       "      <td>0.461617</td>\n",
       "      <td>0.511344</td>\n",
       "      <td>0.488324</td>\n",
       "      <td>0.429299</td>\n",
       "      <td>0.476434</td>\n",
       "      <td>0.403973</td>\n",
       "      <td>0.493319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403568</td>\n",
       "      <td>0.446310</td>\n",
       "      <td>0.494259</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.482615</td>\n",
       "      <td>0.515702</td>\n",
       "      <td>0.388433</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>0.492884</td>\n",
       "      <td>0.579189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.238372</td>\n",
       "      <td>0.475990</td>\n",
       "      <td>0.541994</td>\n",
       "      <td>0.478134</td>\n",
       "      <td>0.593200</td>\n",
       "      <td>0.513502</td>\n",
       "      <td>0.502039</td>\n",
       "      <td>0.497601</td>\n",
       "      <td>0.497887</td>\n",
       "      <td>0.511452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435093</td>\n",
       "      <td>0.449777</td>\n",
       "      <td>0.557355</td>\n",
       "      <td>0.521536</td>\n",
       "      <td>0.506969</td>\n",
       "      <td>0.519877</td>\n",
       "      <td>0.404442</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.502341</td>\n",
       "      <td>0.582993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.316260</td>\n",
       "      <td>0.497073</td>\n",
       "      <td>0.597311</td>\n",
       "      <td>0.492333</td>\n",
       "      <td>0.673205</td>\n",
       "      <td>0.538372</td>\n",
       "      <td>0.545229</td>\n",
       "      <td>0.518854</td>\n",
       "      <td>0.545459</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470832</td>\n",
       "      <td>0.453207</td>\n",
       "      <td>0.617096</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.523956</td>\n",
       "      <td>0.524138</td>\n",
       "      <td>0.415941</td>\n",
       "      <td>0.525350</td>\n",
       "      <td>0.515112</td>\n",
       "      <td>0.586998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              aX_A1         aX_D1         aY_A1         aY_D1         aZ_A1  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.267300      0.474299      0.532783      0.475571      0.587976   \n",
       "std        0.123643      0.066293      0.116047      0.059190      0.129127   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.193030      0.451570      0.475979      0.461617      0.511344   \n",
       "50%        0.238372      0.475990      0.541994      0.478134      0.593200   \n",
       "75%        0.316260      0.497073      0.597311      0.492333      0.673205   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              aZ_D1         gX_A1         gX_D1         gY_A1         gY_D1  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.513237      0.493822      0.496712      0.483855      0.515383   \n",
       "std        0.080489      0.125645      0.090167      0.116264      0.072924   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.488324      0.429299      0.476434      0.403973      0.493319   \n",
       "50%        0.513502      0.502039      0.497601      0.497887      0.511452   \n",
       "75%        0.538372      0.545229      0.518854      0.545459      0.537361   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...         aY_A2         aY_D2         aZ_A2         aZ_D2  \\\n",
       "count  ...  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean   ...      0.432839      0.449727      0.558324      0.521365   \n",
       "std    ...      0.083774      0.033548      0.097088      0.042426   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.403568      0.446310      0.494259      0.515400   \n",
       "50%    ...      0.435093      0.449777      0.557355      0.521536   \n",
       "75%    ...      0.470832      0.453207      0.617096      0.527778   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gX_A2         gX_D2         gY_A2         gY_D2         gZ_A2  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.500183      0.519830      0.410186      0.521206      0.502551   \n",
       "std        0.102759      0.048254      0.099510      0.040963      0.090144   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.482615      0.515702      0.388433      0.517965      0.492884   \n",
       "50%        0.506969      0.519877      0.404442      0.521259      0.502341   \n",
       "75%        0.523956      0.524138      0.415941      0.525350      0.515112   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gZ_D2  \n",
       "count  26400.000000  \n",
       "mean       0.583230  \n",
       "std        0.035227  \n",
       "min        0.000000  \n",
       "25%        0.579189  \n",
       "50%        0.582993  \n",
       "75%        0.586998  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalwavedata = (fullwavedata - fullwavedata.min()) / (fullwavedata.max()-fullwavedata.min())\n",
    "normalwavedata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2454407 , 0.41080022, 0.32581968, ..., 0.5188936 , 0.4929458 ,\n",
       "        0.58779549],\n",
       "       [0.19500412, 0.51896688, 0.61033764, ..., 0.52143732, 0.49012884,\n",
       "        0.58391459],\n",
       "       [0.22643872, 0.4297922 , 0.33365506, ..., 0.52195295, 0.49385348,\n",
       "        0.58364604],\n",
       "       ...,\n",
       "       [0.56100788, 0.25162484, 0.60983698, ..., 0.51909722, 0.50125362,\n",
       "        0.58275752],\n",
       "       [0.629451  , 0.41301135, 0.71584526, ..., 0.52259185, 0.51834611,\n",
       "        0.58284503],\n",
       "       [0.62376549, 0.2756082 , 0.4846425 , ..., 0.52138206, 0.5016146 ,\n",
       "        0.58184442]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*wavelen + (i-1) * wavelen\n",
    "        #print(index, index+250)\n",
    "        wavedataf = normalwavedata.iloc[index:index+wavelen].to_numpy().flatten().tolist()\n",
    "        formatwavedata[idx*num_samples+i-1] = wavedataf\n",
    "        del wavedataf\n",
    "        \n",
    "        \n",
    "formatwavedata = formatwavedata.transpose().to_numpy()\n",
    "formatwavedata \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(formatwavedata, labels, test_size=0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15/0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "1: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "2: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "3: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "4: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "5: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "6: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "7: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "8: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "9: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15)\n",
    "valsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15/0.85)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatwavedata, labels):\n",
    "    X_train, X_test = formatwavedata[train_index], formatwavedata[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "for train_index, val_index in valsplit.split(X_train, y_train):\n",
    "    X_train, X_val = X_train[train_index], X_train[val_index]\n",
    "    y_train, y_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "for i in range(0,10):\n",
    "    print('{3}: Train {0}; Test {1}; Val {2}'.format(np.size(np.where(y_train == i)) / len(y_train), np.size(np.where(y_test == i)) / len(y_test), np.size(np.where(y_val == i)) / len(y_val), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "12/12 [==============================] - 2s 70ms/step - loss: 2.4558 - sparse_categorical_accuracy: 0.1042 - val_loss: 2.3618 - val_sparse_categorical_accuracy: 0.2289\n",
      "Epoch 2/600\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 2.4169 - sparse_categorical_accuracy: 0.1120 - val_loss: 2.3018 - val_sparse_categorical_accuracy: 0.2289\n",
      "Epoch 3/600\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 2.3210 - sparse_categorical_accuracy: 0.1536 - val_loss: 2.2469 - val_sparse_categorical_accuracy: 0.2771\n",
      "Epoch 4/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 2.2587 - sparse_categorical_accuracy: 0.2214 - val_loss: 2.1676 - val_sparse_categorical_accuracy: 0.4337\n",
      "Epoch 5/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 2.2088 - sparse_categorical_accuracy: 0.2995 - val_loss: 2.0811 - val_sparse_categorical_accuracy: 0.5181\n",
      "Epoch 6/600\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 2.1496 - sparse_categorical_accuracy: 0.2865 - val_loss: 1.9682 - val_sparse_categorical_accuracy: 0.6386\n",
      "Epoch 7/600\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 2.0285 - sparse_categorical_accuracy: 0.3724 - val_loss: 1.8407 - val_sparse_categorical_accuracy: 0.4819\n",
      "Epoch 8/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 1.9028 - sparse_categorical_accuracy: 0.4271 - val_loss: 1.7069 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 9/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 1.7772 - sparse_categorical_accuracy: 0.4531 - val_loss: 1.6081 - val_sparse_categorical_accuracy: 0.6386\n",
      "Epoch 10/600\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 1.6601 - sparse_categorical_accuracy: 0.4740 - val_loss: 1.4743 - val_sparse_categorical_accuracy: 0.6145\n",
      "Epoch 11/600\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 1.5720 - sparse_categorical_accuracy: 0.4922 - val_loss: 1.4011 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 12/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 1.4976 - sparse_categorical_accuracy: 0.4870 - val_loss: 1.3594 - val_sparse_categorical_accuracy: 0.5422\n",
      "Epoch 13/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 1.4034 - sparse_categorical_accuracy: 0.5573 - val_loss: 1.2268 - val_sparse_categorical_accuracy: 0.7349\n",
      "Epoch 14/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.3310 - sparse_categorical_accuracy: 0.5807 - val_loss: 1.1815 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 15/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.2352 - sparse_categorical_accuracy: 0.6510 - val_loss: 1.1167 - val_sparse_categorical_accuracy: 0.6506\n",
      "Epoch 16/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 1.1753 - sparse_categorical_accuracy: 0.6510 - val_loss: 1.0884 - val_sparse_categorical_accuracy: 0.7229\n",
      "Epoch 17/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 1.1208 - sparse_categorical_accuracy: 0.6615 - val_loss: 1.0050 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 18/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.0530 - sparse_categorical_accuracy: 0.6849 - val_loss: 0.9569 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 19/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.9940 - sparse_categorical_accuracy: 0.7344 - val_loss: 0.9183 - val_sparse_categorical_accuracy: 0.7831\n",
      "Epoch 20/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.9499 - sparse_categorical_accuracy: 0.7214 - val_loss: 0.8547 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 21/600\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.8986 - sparse_categorical_accuracy: 0.7448 - val_loss: 0.8241 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 22/600\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.8453 - sparse_categorical_accuracy: 0.7760 - val_loss: 0.7646 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 23/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.7754 - sparse_categorical_accuracy: 0.7943 - val_loss: 0.7420 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 24/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.7507 - sparse_categorical_accuracy: 0.7943 - val_loss: 0.7006 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 25/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.6855 - sparse_categorical_accuracy: 0.8151 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 26/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.6963 - sparse_categorical_accuracy: 0.8099 - val_loss: 0.6289 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 27/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.6851 - sparse_categorical_accuracy: 0.7891 - val_loss: 0.6143 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 28/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.6230 - sparse_categorical_accuracy: 0.8307 - val_loss: 0.5795 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 29/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.5619 - sparse_categorical_accuracy: 0.8568 - val_loss: 0.5287 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 30/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.5366 - sparse_categorical_accuracy: 0.8490 - val_loss: 0.5396 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 31/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.5224 - sparse_categorical_accuracy: 0.8438 - val_loss: 0.5434 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 32/600\n",
      " 5/12 [===========>..................] - ETA: 0s - loss: 0.5160 - sparse_categorical_accuracy: 0.8750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-8869a86b144b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 11\u001b[1;33m model.fit(X_train, y_train, \n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "\n",
    ")\n",
    "model.fit(X_train, y_train, \n",
    "            epochs=600,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stopping],\n",
    "            validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2343 - sparse_categorical_accuracy: 0.9518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1abe6d2f160>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "data (Dense)                 (None, 1024)              1180672   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "result (Dense)               (None, 11)                11275     \n",
      "=================================================================\n",
      "Total params: 3,291,147\n",
      "Trainable params: 3,291,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = tf.keras.models.load_model('Training data/model1')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testvar\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testvar\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    model, 'testvar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmppn6r4u0b\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('test_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'data_input', 'index': 0, 'shape': array([   1, 1584]), 'shape_signature': array([  -1, 1584]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='test_model.tflite')\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(input_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_resize_dispatcher() got an unexpected keyword argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-51493053cb49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrydata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1584\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mresize\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _resize_dispatcher() got an unexpected keyword argument 'dtype'"
     ]
    }
   ],
   "source": [
    "trydata = np.resize(X_test[0], (1, 1584))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.004 0.    0.449 0.007 0.    0.    0.536 0.004 0.   ]]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "input_data = np.float32(np.resize(X_test[46], (1, 1584)))\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(np.round(output_data, decimals=3))\n",
    "print(y_test[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsure\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 113):\n",
    "    input_data = np.float32(np.resize(X_test[i], (1, 1584)))\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    output_data\n",
    "\n",
    "    if np.max(output_data) < 0.6:\n",
    "        print('Unsure')\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output_data)\n",
    "if max(output_data) < 0.5:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "SignatureDef method_name is None and model has 0 Signatures. None is only allowed when the model has 1 SignatureDef",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7c4bc9d72a2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msignatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_signature_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_signature_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36mget_signature_runner\u001b[1;34m(self, method_name)\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_signature_defs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;34m'SignatureDef method_name is None and model has {0} Signatures. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             'None is only allowed when the model has 1 SignatureDef'.format(\n",
      "\u001b[1;31mValueError\u001b[0m: SignatureDef method_name is None and model has 0 Signatures. None is only allowed when the model has 1 SignatureDef"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='test_model.tflite')\n",
    "\n",
    "signatures = interpreter.get_signature_list()\n",
    "print(signatures)\n",
    "predictor = interpreter.get_signature_runner()\n",
    "print(predictor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0964601e-07, 9.1763778e-04, 1.6810007e-05, 4.2849658e-03,\n",
       "        2.6555134e-03, 2.2810149e-05, 2.0116172e-04, 9.7670448e-01,\n",
       "        4.2905535e-06, 1.5192278e-02]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = predictor(data_input=np.float32(X_test[0]))['result']\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1584"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1bbd703a0d0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "output_lbl = np.argmax(output, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, output_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 2.4136 - sparse_categorical_accuracy: 0.1182 - val_loss: 2.3188 - val_sparse_categorical_accuracy: 0.0964\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 2.3183 - sparse_categorical_accuracy: 0.1795 - val_loss: 2.2308 - val_sparse_categorical_accuracy: 0.3855\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 2.2644 - sparse_categorical_accuracy: 0.2364 - val_loss: 2.1301 - val_sparse_categorical_accuracy: 0.5422\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 2.1839 - sparse_categorical_accuracy: 0.2750 - val_loss: 2.0414 - val_sparse_categorical_accuracy: 0.4699\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 2.0822 - sparse_categorical_accuracy: 0.3386 - val_loss: 1.9238 - val_sparse_categorical_accuracy: 0.4337\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.9834 - sparse_categorical_accuracy: 0.3500 - val_loss: 1.7453 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 1.8176 - sparse_categorical_accuracy: 0.4568 - val_loss: 1.6470 - val_sparse_categorical_accuracy: 0.6145\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.7097 - sparse_categorical_accuracy: 0.4773 - val_loss: 1.4899 - val_sparse_categorical_accuracy: 0.6747\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.5979 - sparse_categorical_accuracy: 0.5000 - val_loss: 1.3879 - val_sparse_categorical_accuracy: 0.6145\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.4863 - sparse_categorical_accuracy: 0.5455 - val_loss: 1.2934 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.4094 - sparse_categorical_accuracy: 0.5500 - val_loss: 1.2204 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.3096 - sparse_categorical_accuracy: 0.6045 - val_loss: 1.1370 - val_sparse_categorical_accuracy: 0.6988\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.2300 - sparse_categorical_accuracy: 0.6136 - val_loss: 1.0459 - val_sparse_categorical_accuracy: 0.8193\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.1253 - sparse_categorical_accuracy: 0.7023 - val_loss: 0.9365 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.0548 - sparse_categorical_accuracy: 0.7159 - val_loss: 0.9031 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.0513 - sparse_categorical_accuracy: 0.6977 - val_loss: 0.8833 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.9253 - sparse_categorical_accuracy: 0.7750 - val_loss: 0.8205 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.8965 - sparse_categorical_accuracy: 0.7614 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.8054 - sparse_categorical_accuracy: 0.7773 - val_loss: 0.6556 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.7887 - sparse_categorical_accuracy: 0.7932 - val_loss: 0.6251 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.7565 - sparse_categorical_accuracy: 0.7909 - val_loss: 0.6027 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.6607 - sparse_categorical_accuracy: 0.8364 - val_loss: 0.6126 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.6697 - sparse_categorical_accuracy: 0.8318 - val_loss: 0.4820 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.6106 - sparse_categorical_accuracy: 0.8273 - val_loss: 0.4946 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.5545 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.4328 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.5373 - sparse_categorical_accuracy: 0.8568 - val_loss: 0.4526 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.5054 - sparse_categorical_accuracy: 0.8705 - val_loss: 0.4272 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.4583 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.3917 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.4480 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.3614 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.4158 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.3220 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3748 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.3215 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3760 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.3073 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3757 - sparse_categorical_accuracy: 0.9068 - val_loss: 0.3424 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3547 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.2906 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3564 - sparse_categorical_accuracy: 0.9114 - val_loss: 0.3024 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.3443 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.3116 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2853 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.3118 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3007 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.2460 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3042 - sparse_categorical_accuracy: 0.9159 - val_loss: 0.3621 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3007 - sparse_categorical_accuracy: 0.9227 - val_loss: 0.2298 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2499 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.3131 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2880 - sparse_categorical_accuracy: 0.9205 - val_loss: 0.2669 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3043 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.2572 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2335 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.2254 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2313 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.2164 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 46/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2550 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.2254 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2288 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.2366 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2280 - sparse_categorical_accuracy: 0.9318 - val_loss: 0.2111 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1904 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1898 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2215 - sparse_categorical_accuracy: 0.9341 - val_loss: 0.1932 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2009 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.2194 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2203 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.1909 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2121 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.1779 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2067 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1844 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1592 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.2041 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1671 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.1681 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1763 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1390 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1401 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1505 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1400 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1902 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1595 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.1962 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1975 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.2150 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1765 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.3131 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1800 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.2216 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.1621 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.1617 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1421 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1371 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1486 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1300 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1561 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1367 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1212 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1375 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1069 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1326 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1152 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1179 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1154 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1289 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1126 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1021 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1430 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1043 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1552 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1101 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1238 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0977 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1259 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1077 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1362 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1354 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0899 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0982 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1149 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1288 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1130 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1224 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.1454 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 83/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1219 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1396 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1225 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1411 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.1164 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.1710 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.1095 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.1153 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.1143 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1390 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.1031 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1161 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0931 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1871 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1074 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0970 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 91/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0986 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1165 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1115 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1281 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0885 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1107 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0502 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.1128 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0778 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1303 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0597 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0570 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.1491 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0811 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0994 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0641 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0878 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0434 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.1320 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0740 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1127 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1090 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0543 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1030 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0613 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1181 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0878 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1520 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0834 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0398 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.1707 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0705 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1404 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0759 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0644 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1117 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0619 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1453 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0671 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1077 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0985 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0510 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.1158 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0616 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1248 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0581 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1041 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0586 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.1241 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0660 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1180 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 121/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0399 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 122/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0359 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.1134 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 123/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0466 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0794 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 124/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0378 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1494 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 125/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0435 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0790 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 126/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0955 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 127/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0437 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1269 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 128/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1218 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 129/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0565 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0896 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 130/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0438 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.1239 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 131/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0713 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0907 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 132/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0499 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0911 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 133/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0538 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0997 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 134/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0463 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1177 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 135/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0285 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.1163 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 136/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0346 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.1042 - val_sparse_categorical_accuracy: 0.9759\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmp2e0mnc20\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmp2e0mnc20\\assets\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatwavedata, labels):\n",
    "    X_train, X_test = formatwavedata[train_index], formatwavedata[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('number_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1ab998e1340>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_val, y_val)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_val)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_val\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 1s 71ms/step - loss: 2.4630 - sparse_categorical_accuracy: 0.1091 - val_loss: 2.3521 - val_sparse_categorical_accuracy: 0.0909\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 2.3794 - sparse_categorical_accuracy: 0.1409 - val_loss: 2.2573 - val_sparse_categorical_accuracy: 0.2727\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 2.3044 - sparse_categorical_accuracy: 0.2205 - val_loss: 2.1766 - val_sparse_categorical_accuracy: 0.5455\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 2.2415 - sparse_categorical_accuracy: 0.2182 - val_loss: 2.0768 - val_sparse_categorical_accuracy: 0.6091\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 2.1289 - sparse_categorical_accuracy: 0.3568 - val_loss: 1.9510 - val_sparse_categorical_accuracy: 0.6909\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 2.0594 - sparse_categorical_accuracy: 0.3273 - val_loss: 1.8445 - val_sparse_categorical_accuracy: 0.6818\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 1.9410 - sparse_categorical_accuracy: 0.4364 - val_loss: 1.6922 - val_sparse_categorical_accuracy: 0.6364\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 1.7783 - sparse_categorical_accuracy: 0.5273 - val_loss: 1.5213 - val_sparse_categorical_accuracy: 0.6636\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 1.6654 - sparse_categorical_accuracy: 0.4932 - val_loss: 1.3483 - val_sparse_categorical_accuracy: 0.7364\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 1.5187 - sparse_categorical_accuracy: 0.5955 - val_loss: 1.2139 - val_sparse_categorical_accuracy: 0.8091\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 1.3840 - sparse_categorical_accuracy: 0.6318 - val_loss: 1.1873 - val_sparse_categorical_accuracy: 0.5727\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 1.3008 - sparse_categorical_accuracy: 0.6227 - val_loss: 1.0267 - val_sparse_categorical_accuracy: 0.7273\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 1.1768 - sparse_categorical_accuracy: 0.6818 - val_loss: 0.8753 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 1.0618 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.8147 - val_sparse_categorical_accuracy: 0.8182\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.9602 - sparse_categorical_accuracy: 0.7591 - val_loss: 0.6700 - val_sparse_categorical_accuracy: 0.8727\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.8503 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.6473 - val_sparse_categorical_accuracy: 0.8455\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.8354 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.5921 - val_sparse_categorical_accuracy: 0.8727\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 1s 72ms/step - loss: 0.6974 - sparse_categorical_accuracy: 0.8409 - val_loss: 0.4652 - val_sparse_categorical_accuracy: 0.9000\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.6304 - sparse_categorical_accuracy: 0.8455 - val_loss: 0.4628 - val_sparse_categorical_accuracy: 0.8818\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.5735 - sparse_categorical_accuracy: 0.8659 - val_loss: 0.4019 - val_sparse_categorical_accuracy: 0.8909\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.5507 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.4190 - val_sparse_categorical_accuracy: 0.9000\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.5081 - sparse_categorical_accuracy: 0.8795 - val_loss: 0.3334 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.4624 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.2787 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.4603 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.2757 - val_sparse_categorical_accuracy: 0.9182\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.4417 - sparse_categorical_accuracy: 0.8864 - val_loss: 0.2762 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.4007 - sparse_categorical_accuracy: 0.8955 - val_loss: 0.2612 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.3785 - sparse_categorical_accuracy: 0.9068 - val_loss: 0.2685 - val_sparse_categorical_accuracy: 0.9182\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.3651 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.2241 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.3270 - sparse_categorical_accuracy: 0.9227 - val_loss: 0.2274 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.3329 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.2136 - val_sparse_categorical_accuracy: 0.9364\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.3217 - sparse_categorical_accuracy: 0.9227 - val_loss: 0.2443 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.3113 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.1731 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.2569 - sparse_categorical_accuracy: 0.9341 - val_loss: 0.1890 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.2537 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.1906 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.2858 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.2302 - val_sparse_categorical_accuracy: 0.9182\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.2611 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.1244 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.2440 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.1641 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.2310 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.1677 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.2480 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.1564 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.2305 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.1403 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.1709 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1179 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.2106 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.1475 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.2211 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.2062 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1852 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1282 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1833 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1321 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 46/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 45ms/step - loss: 0.1512 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1107 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1407 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.0940 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1710 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1446 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1421 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1610 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1788 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.1501 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.1936 - val_sparse_categorical_accuracy: 0.9364\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1580 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1117 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1175 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0953 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1479 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.0950 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.1779 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.0818 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1431 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1552 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0974 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1128 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0936 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1105 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0804 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0818 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0983 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.1201 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0773 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1221 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0867 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1080 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0934 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1511 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1474 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1347 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1538 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1016 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1975 - val_sparse_categorical_accuracy: 0.9364\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1205 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0930 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1043 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0687 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.0520 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.0961 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0783 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.0785 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0788 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.0652 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1173 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.0876 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1410 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 0.1163 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1713 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 1s 70ms/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0647 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0674 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0780 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.1041 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.0629 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0585 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 83/600\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0963 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 0.0708 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0759 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.0573 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0583 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0635 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.1276 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0995 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1144 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0827 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0790 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0758 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 91/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1441 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0803 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.2435 - val_sparse_categorical_accuracy: 0.9364\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0681 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0603 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0429 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0640 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0545 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0578 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0942 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0514 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0828 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0854 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0498 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0478 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0768 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0487 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0629 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0382 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0482 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0459 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0366 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0778 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0483 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0467 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0403 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0500 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0411 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0458 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0324 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0419 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0420 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0545 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0562 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0587 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0316 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0566 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0305 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0331 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0506 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0453 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0344 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0336 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0466 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0279 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0413 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0334 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0480 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 121/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0359 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0682 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 122/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0302 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0912 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 123/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0533 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0898 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 124/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0499 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0527 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 125/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0455 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0364 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 126/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0301 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0382 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 127/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0316 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 128/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0242 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0437 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 129/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0272 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0305 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 130/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0257 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0455 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 131/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0581 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0567 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 132/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0406 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0524 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 133/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0322 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0697 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 134/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0218 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0321 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 135/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0365 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0506 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 136/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0346 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0685 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 137/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0324 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0837 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 138/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0524 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0982 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 139/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0357 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0255 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 140/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0426 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0208 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 141/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0856 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 142/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0664 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0492 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 143/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0746 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0672 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 144/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0411 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0292 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 145/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0414 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0663 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 146/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0332 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0356 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 147/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0317 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0620 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 148/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0365 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0458 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 149/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0529 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 150/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0360 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0389 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 151/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0288 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0775 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 152/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0513 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0799 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 153/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0252 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 154/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0323 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0370 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 155/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0362 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0778 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 156/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0377 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 157/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0188 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0175 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 158/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0194 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0399 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 159/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0248 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0456 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 160/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0329 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0369 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 161/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0280 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 162/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0241 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 163/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0449 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 164/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0474 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0634 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 165/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1363 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 166/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0981 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0639 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 167/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0568 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1497 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 168/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0659 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.1435 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 169/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0768 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1408 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 170/600\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.0714 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0571 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 171/600\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0584 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.2038 - val_sparse_categorical_accuracy: 0.9364 0s - loss: 0.0560 - sparse_categorical_accuracy\n",
      "Epoch 172/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.1510 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.2910 - val_sparse_categorical_accuracy: 0.8818\n",
      "Epoch 173/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.2121 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.1424 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 174/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0726 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1139 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 175/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0355 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0541 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 176/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0326 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 177/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0918 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 178/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0600 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0626 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 179/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0373 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0927 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 180/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0407 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0550 - val_sparse_categorical_accuracy: 0.9909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0508 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0839 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 182/600\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 0.0281 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0368 - val_sparse_categorical_accuracy: 0.9818\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmp7mk825oo\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmp7mk825oo\\assets\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatdata, labels):\n",
    "    X_train, X_val = formatdata[train_index], formatdata[test_index]\n",
    "    y_train, y_val = labels[train_index], labels[test_index]\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "#with open('number_model_full.tflite', 'wb') as f:\n",
    "#  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('number_model_full.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1330 test_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1320 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1313 run_step  **\n        outputs = model.test_step(data)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1267 test_step\n        y_pred = self(x, training=False)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_15 is incompatible with the layer: expected axis -1 of input shape to have value 2100 but received input with shape (None, 1152)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-d58d3bcec490>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m-> 3038\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3457\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3459\u001b[1;33m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[0;32m   3460\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3379\u001b[0m           expand_composites=True)\n\u001b[0;32m   3380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3381\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3382\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1330 test_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1320 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1313 run_step  **\n        outputs = model.test_step(data)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1267 test_step\n        y_pred = self(x, training=False)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_15 is incompatible with the layer: expected axis -1 of input shape to have value 2100 but received input with shape (None, 1152)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
