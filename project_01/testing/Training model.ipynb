{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gestures = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9\n",
    "]\n",
    "num_samples = 75\n",
    "num_gestures = len(gestures)\n",
    "\n",
    "one_hot = np.eye(len(gestures))\n",
    "\n",
    "\n",
    "\n",
    "fulldata = pd.DataFrame(columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "fullwavedata = pd.DataFrame(columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'])\n",
    "formatdata = pd.DataFrame()\n",
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "labels = []\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        filepath = 'Training data/test_{0}_{1}.csv'.format(gesture, i)\n",
    "        data = pd.read_csv(filepath, index_col=False)\n",
    "        wavedata = pd.DataFrame()\n",
    "        \n",
    "        level1 = 5\n",
    "        wavetype1 = 'dmey'\n",
    "        \n",
    "        wavedata['aX_A1'], wavedata['aX_D1'] = wavelet(data['aX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aY_A1'], wavedata['aY_D1'] = wavelet(data['aY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aZ_A1'], wavedata['aZ_D1'] = wavelet(data['aZ'], level=level1, wavelet=wavetype1)\n",
    "\n",
    "        wavedata['gX_A1'], wavedata['gX_D1'] = wavelet(data['gX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gY_A1'], wavedata['gY_D1'] = wavelet(data['gY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gZ_A1'], wavedata['gZ_D1'] = wavelet(data['gZ'], level=level1, wavelet=wavetype1)\n",
    "        \n",
    "        level2 = 2\n",
    "        wavetype2 = 'rbio2.2'\n",
    "\n",
    "        wavedata['aX_A2'], wavedata['aX_D2'] = wavelet(data['aX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aY_A2'], wavedata['aY_D2'] = wavelet(data['aY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aZ_A2'], wavedata['aZ_D2'] = wavelet(data['aZ'], level=level2, wavelet=wavetype2)\n",
    "\n",
    "        wavedata['gX_A2'], wavedata['gX_D2'] = wavelet(data['gX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gY_A2'], wavedata['gY_D2'] = wavelet(data['gY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gZ_A2'], wavedata['gZ_D2'] = wavelet(data['gZ'], level=level2, wavelet=wavetype2)\n",
    "        \n",
    "        wavelen = len(wavedata)\n",
    "        \n",
    "        fullwavedata = fullwavedata.append(wavedata)\n",
    "        fulldata = fulldata.append(data)\n",
    "        label = gesture\n",
    "        labels.append(label)\n",
    "        del data, wavedata\n",
    "\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX</th>\n",
       "      <th>aY</th>\n",
       "      <th>aZ</th>\n",
       "      <th>gX</th>\n",
       "      <th>gY</th>\n",
       "      <th>gZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>187500.000000</td>\n",
       "      <td>187500.000000</td>\n",
       "      <td>187500.000000</td>\n",
       "      <td>187500.000000</td>\n",
       "      <td>187500.000000</td>\n",
       "      <td>187500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.556201</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>0.411886</td>\n",
       "      <td>0.454160</td>\n",
       "      <td>0.500663</td>\n",
       "      <td>0.462613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.078789</td>\n",
       "      <td>0.086354</td>\n",
       "      <td>0.088734</td>\n",
       "      <td>0.097145</td>\n",
       "      <td>0.082059</td>\n",
       "      <td>0.084265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.511782</td>\n",
       "      <td>0.334402</td>\n",
       "      <td>0.385616</td>\n",
       "      <td>0.433912</td>\n",
       "      <td>0.484199</td>\n",
       "      <td>0.446379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.556940</td>\n",
       "      <td>0.399080</td>\n",
       "      <td>0.418664</td>\n",
       "      <td>0.451369</td>\n",
       "      <td>0.499626</td>\n",
       "      <td>0.460416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.596337</td>\n",
       "      <td>0.448060</td>\n",
       "      <td>0.438756</td>\n",
       "      <td>0.469123</td>\n",
       "      <td>0.511177</td>\n",
       "      <td>0.475276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aX             aY             aZ             gX  \\\n",
       "count  187500.000000  187500.000000  187500.000000  187500.000000   \n",
       "mean        0.556201       0.396600       0.411886       0.454160   \n",
       "std         0.078789       0.086354       0.088734       0.097145   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.511782       0.334402       0.385616       0.433912   \n",
       "50%         0.556940       0.399080       0.418664       0.451369   \n",
       "75%         0.596337       0.448060       0.438756       0.469123   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  gY             gZ  \n",
       "count  187500.000000  187500.000000  \n",
       "mean        0.500663       0.462613  \n",
       "std         0.082059       0.084265  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.484199       0.446379  \n",
       "50%         0.499626       0.460416  \n",
       "75%         0.511177       0.475276  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normaldata = (fulldata - fulldata.min()) / (fulldata.max()-fulldata.min())\n",
    "normaldata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59109008, 0.2476167 , 0.68156393, ..., 0.46262777, 0.49748989,\n",
       "        0.45681224],\n",
       "       [0.64908418, 0.24276792, 0.60291096, ..., 0.47850967, 0.49866484,\n",
       "        0.44382851],\n",
       "       [0.68328102, 0.42784352, 0.43105023, ..., 0.44081607, 0.48673228,\n",
       "        0.46163898],\n",
       "       ...,\n",
       "       [0.49482363, 0.50887574, 0.6678653 , ..., 0.46318758, 0.56757458,\n",
       "        0.41687042],\n",
       "       [0.63240736, 0.35650888, 0.49315068, ..., 0.46642201, 0.50051118,\n",
       "        0.42793609],\n",
       "       [0.6203682 , 0.31969099, 0.4734589 , ..., 0.44228815, 0.50371557,\n",
       "        0.46279825]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatdata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, 76):#num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*250 + (i-1) * 250\n",
    "        #print(index, index+250)\n",
    "        dataf = normaldata.iloc[index:index+250].to_numpy().flatten().tolist()\n",
    "        formatdata[idx*num_samples+i-1] = dataf\n",
    "        del dataf\n",
    "        \n",
    "        \n",
    "formatdata = formatdata.transpose().to_numpy()\n",
    "formatdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "def wavelet(data, level, wavelet):\n",
    "    (cA, cD) = pywt.dwt(data, wavelet=wavelet)\n",
    "    for i in range(1, level):\n",
    "        (cA, cD) = pywt.dwt(cA, wavelet=wavelet)\n",
    "    return cA, cD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX_A1</th>\n",
       "      <th>aX_D1</th>\n",
       "      <th>aY_A1</th>\n",
       "      <th>aY_D1</th>\n",
       "      <th>aZ_A1</th>\n",
       "      <th>aZ_D1</th>\n",
       "      <th>gX_A1</th>\n",
       "      <th>gX_D1</th>\n",
       "      <th>gY_A1</th>\n",
       "      <th>gY_D1</th>\n",
       "      <th>...</th>\n",
       "      <th>aY_A2</th>\n",
       "      <th>aY_D2</th>\n",
       "      <th>aZ_A2</th>\n",
       "      <th>aZ_D2</th>\n",
       "      <th>gX_A2</th>\n",
       "      <th>gX_D2</th>\n",
       "      <th>gY_A2</th>\n",
       "      <th>gY_D2</th>\n",
       "      <th>gZ_A2</th>\n",
       "      <th>gZ_D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "      <td>49500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.497516</td>\n",
       "      <td>0.467960</td>\n",
       "      <td>0.412851</td>\n",
       "      <td>0.517696</td>\n",
       "      <td>0.513952</td>\n",
       "      <td>0.523925</td>\n",
       "      <td>0.478586</td>\n",
       "      <td>0.520926</td>\n",
       "      <td>0.511014</td>\n",
       "      <td>0.537456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398164</td>\n",
       "      <td>0.381732</td>\n",
       "      <td>0.453108</td>\n",
       "      <td>0.721203</td>\n",
       "      <td>0.429104</td>\n",
       "      <td>0.492332</td>\n",
       "      <td>0.501349</td>\n",
       "      <td>0.482749</td>\n",
       "      <td>0.457911</td>\n",
       "      <td>0.566090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.097294</td>\n",
       "      <td>0.060203</td>\n",
       "      <td>0.109414</td>\n",
       "      <td>0.083133</td>\n",
       "      <td>0.104303</td>\n",
       "      <td>0.090857</td>\n",
       "      <td>0.115142</td>\n",
       "      <td>0.074926</td>\n",
       "      <td>0.069332</td>\n",
       "      <td>0.062208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096932</td>\n",
       "      <td>0.028289</td>\n",
       "      <td>0.102511</td>\n",
       "      <td>0.026659</td>\n",
       "      <td>0.107746</td>\n",
       "      <td>0.035894</td>\n",
       "      <td>0.080755</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.087218</td>\n",
       "      <td>0.032067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.437812</td>\n",
       "      <td>0.458941</td>\n",
       "      <td>0.329817</td>\n",
       "      <td>0.506758</td>\n",
       "      <td>0.476832</td>\n",
       "      <td>0.515462</td>\n",
       "      <td>0.441037</td>\n",
       "      <td>0.514579</td>\n",
       "      <td>0.488013</td>\n",
       "      <td>0.527616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327640</td>\n",
       "      <td>0.377211</td>\n",
       "      <td>0.421493</td>\n",
       "      <td>0.717386</td>\n",
       "      <td>0.406099</td>\n",
       "      <td>0.489741</td>\n",
       "      <td>0.484787</td>\n",
       "      <td>0.479179</td>\n",
       "      <td>0.441368</td>\n",
       "      <td>0.562537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.498379</td>\n",
       "      <td>0.467819</td>\n",
       "      <td>0.416661</td>\n",
       "      <td>0.517474</td>\n",
       "      <td>0.521585</td>\n",
       "      <td>0.525455</td>\n",
       "      <td>0.499227</td>\n",
       "      <td>0.521080</td>\n",
       "      <td>0.494951</td>\n",
       "      <td>0.537779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401008</td>\n",
       "      <td>0.381723</td>\n",
       "      <td>0.459248</td>\n",
       "      <td>0.721250</td>\n",
       "      <td>0.425846</td>\n",
       "      <td>0.492822</td>\n",
       "      <td>0.499732</td>\n",
       "      <td>0.482529</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.566152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.553838</td>\n",
       "      <td>0.475911</td>\n",
       "      <td>0.484513</td>\n",
       "      <td>0.532906</td>\n",
       "      <td>0.548347</td>\n",
       "      <td>0.538299</td>\n",
       "      <td>0.514813</td>\n",
       "      <td>0.534569</td>\n",
       "      <td>0.520263</td>\n",
       "      <td>0.545159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456683</td>\n",
       "      <td>0.386304</td>\n",
       "      <td>0.482633</td>\n",
       "      <td>0.725293</td>\n",
       "      <td>0.445805</td>\n",
       "      <td>0.496821</td>\n",
       "      <td>0.511463</td>\n",
       "      <td>0.485648</td>\n",
       "      <td>0.471580</td>\n",
       "      <td>0.569730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              aX_A1         aX_D1         aY_A1         aY_D1         aZ_A1  \\\n",
       "count  49500.000000  49500.000000  49500.000000  49500.000000  49500.000000   \n",
       "mean       0.497516      0.467960      0.412851      0.517696      0.513952   \n",
       "std        0.097294      0.060203      0.109414      0.083133      0.104303   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.437812      0.458941      0.329817      0.506758      0.476832   \n",
       "50%        0.498379      0.467819      0.416661      0.517474      0.521585   \n",
       "75%        0.553838      0.475911      0.484513      0.532906      0.548347   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              aZ_D1         gX_A1         gX_D1         gY_A1         gY_D1  \\\n",
       "count  49500.000000  49500.000000  49500.000000  49500.000000  49500.000000   \n",
       "mean       0.523925      0.478586      0.520926      0.511014      0.537456   \n",
       "std        0.090857      0.115142      0.074926      0.069332      0.062208   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.515462      0.441037      0.514579      0.488013      0.527616   \n",
       "50%        0.525455      0.499227      0.521080      0.494951      0.537779   \n",
       "75%        0.538299      0.514813      0.534569      0.520263      0.545159   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...         aY_A2         aY_D2         aZ_A2         aZ_D2  \\\n",
       "count  ...  49500.000000  49500.000000  49500.000000  49500.000000   \n",
       "mean   ...      0.398164      0.381732      0.453108      0.721203   \n",
       "std    ...      0.096932      0.028289      0.102511      0.026659   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.327640      0.377211      0.421493      0.717386   \n",
       "50%    ...      0.401008      0.381723      0.459248      0.721250   \n",
       "75%    ...      0.456683      0.386304      0.482633      0.725293   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gX_A2         gX_D2         gY_A2         gY_D2         gZ_A2  \\\n",
       "count  49500.000000  49500.000000  49500.000000  49500.000000  49500.000000   \n",
       "mean       0.429104      0.492332      0.501349      0.482749      0.457911   \n",
       "std        0.107746      0.035894      0.080755      0.029401      0.087218   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.406099      0.489741      0.484787      0.479179      0.441368   \n",
       "50%        0.425846      0.492822      0.499732      0.482529      0.456847   \n",
       "75%        0.445805      0.496821      0.511463      0.485648      0.471580   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gZ_D2  \n",
       "count  49500.000000  \n",
       "mean       0.566090  \n",
       "std        0.032067  \n",
       "min        0.000000  \n",
       "25%        0.562537  \n",
       "50%        0.566152  \n",
       "75%        0.569730  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalwavedata = (fullwavedata - fullwavedata.min()) / (fullwavedata.max()-fullwavedata.min())\n",
    "normalwavedata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.63299382, 0.47970438, 0.14634482, ..., 0.48133294, 0.45298797,\n",
       "        0.56554193],\n",
       "       [0.68543138, 0.42927659, 0.23015975, ..., 0.48546033, 0.43824259,\n",
       "        0.56975438],\n",
       "       [0.49537685, 0.44529983, 0.43293935, ..., 0.48927799, 0.45733925,\n",
       "        0.55820254],\n",
       "       ...,\n",
       "       [0.48369692, 0.55754372, 0.39617257, ..., 0.48567272, 0.41288343,\n",
       "        0.56390029],\n",
       "       [0.63542805, 0.4983797 , 0.32888552, ..., 0.48247806, 0.42154822,\n",
       "        0.56637728],\n",
       "       [0.65150173, 0.45430185, 0.32573367, ..., 0.48076658, 0.46050967,\n",
       "        0.56339774]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatwavedata = pd.DataFrame()\n",
    "print(wavelen)\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, 76):#num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*wavelen + (i-1) * wavelen\n",
    "        #print(index, index+250)\n",
    "        wavedataf = normalwavedata.iloc[index:index+wavelen].to_numpy().flatten().tolist()\n",
    "        formatwavedata[idx*num_samples+i-1] = wavedataf\n",
    "        del wavedataf\n",
    "        \n",
    "        \n",
    "formatwavedata = formatwavedata.transpose().to_numpy()\n",
    "formatwavedata \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(formatdata2, labels, test_size=0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15/0.85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 2.2893 - sparse_categorical_accuracy: 0.1298 - val_loss: 2.2317 - val_sparse_categorical_accuracy: 0.2566\n",
      "Epoch 2/600\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 2.1725 - sparse_categorical_accuracy: 0.2595 - val_loss: 2.0745 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 3/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 2.0385 - sparse_categorical_accuracy: 0.3969 - val_loss: 1.9041 - val_sparse_categorical_accuracy: 0.4690\n",
      "Epoch 4/600\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 1.8795 - sparse_categorical_accuracy: 0.4427 - val_loss: 1.8215 - val_sparse_categorical_accuracy: 0.4071\n",
      "Epoch 5/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 1.7072 - sparse_categorical_accuracy: 0.4695 - val_loss: 1.5306 - val_sparse_categorical_accuracy: 0.5929\n",
      "Epoch 6/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 1.5631 - sparse_categorical_accuracy: 0.5324 - val_loss: 1.3954 - val_sparse_categorical_accuracy: 0.6372\n",
      "Epoch 7/600\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 1.4019 - sparse_categorical_accuracy: 0.6011 - val_loss: 1.2988 - val_sparse_categorical_accuracy: 0.6106\n",
      "Epoch 8/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 1.2891 - sparse_categorical_accuracy: 0.6050 - val_loss: 1.2347 - val_sparse_categorical_accuracy: 0.6372\n",
      "Epoch 9/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 1.2421 - sparse_categorical_accuracy: 0.6240 - val_loss: 1.1628 - val_sparse_categorical_accuracy: 0.6637\n",
      "Epoch 10/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 1.1494 - sparse_categorical_accuracy: 0.6508 - val_loss: 1.0456 - val_sparse_categorical_accuracy: 0.7080\n",
      "Epoch 11/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 1.0373 - sparse_categorical_accuracy: 0.7042 - val_loss: 0.9920 - val_sparse_categorical_accuracy: 0.7434\n",
      "Epoch 12/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.9916 - sparse_categorical_accuracy: 0.7290 - val_loss: 0.9501 - val_sparse_categorical_accuracy: 0.7080\n",
      "Epoch 13/600\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.9372 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.8937 - val_sparse_categorical_accuracy: 0.7257\n",
      "Epoch 14/600\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.9210 - sparse_categorical_accuracy: 0.7271 - val_loss: 0.9108 - val_sparse_categorical_accuracy: 0.7257\n",
      "Epoch 15/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.8493 - sparse_categorical_accuracy: 0.7576 - val_loss: 0.8188 - val_sparse_categorical_accuracy: 0.7788\n",
      "Epoch 16/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.8051 - sparse_categorical_accuracy: 0.7691 - val_loss: 0.8686 - val_sparse_categorical_accuracy: 0.7434\n",
      "Epoch 17/600\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.8340 - sparse_categorical_accuracy: 0.7328 - val_loss: 0.7936 - val_sparse_categorical_accuracy: 0.7788\n",
      "Epoch 18/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.7201 - sparse_categorical_accuracy: 0.7767 - val_loss: 0.7413 - val_sparse_categorical_accuracy: 0.7699\n",
      "Epoch 19/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.7236 - sparse_categorical_accuracy: 0.7844 - val_loss: 0.7798 - val_sparse_categorical_accuracy: 0.7522\n",
      "Epoch 20/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.7299 - sparse_categorical_accuracy: 0.7710 - val_loss: 0.7184 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 21/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.7009 - sparse_categorical_accuracy: 0.7824 - val_loss: 0.7077 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 22/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.6251 - sparse_categorical_accuracy: 0.8302 - val_loss: 0.7177 - val_sparse_categorical_accuracy: 0.7876\n",
      "Epoch 23/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.5914 - sparse_categorical_accuracy: 0.8187 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 24/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.6034 - sparse_categorical_accuracy: 0.8359 - val_loss: 0.7673 - val_sparse_categorical_accuracy: 0.7788\n",
      "Epoch 25/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.5779 - sparse_categorical_accuracy: 0.8321 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 26/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.5361 - sparse_categorical_accuracy: 0.8569 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 27/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.5204 - sparse_categorical_accuracy: 0.8626 - val_loss: 0.6044 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 28/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4962 - sparse_categorical_accuracy: 0.8702 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 29/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.5077 - sparse_categorical_accuracy: 0.8492 - val_loss: 0.6428 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 30/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.5062 - sparse_categorical_accuracy: 0.8569 - val_loss: 0.6259 - val_sparse_categorical_accuracy: 0.7788\n",
      "Epoch 31/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4800 - sparse_categorical_accuracy: 0.8645 - val_loss: 0.5983 - val_sparse_categorical_accuracy: 0.8319\n",
      "Epoch 32/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4634 - sparse_categorical_accuracy: 0.8721 - val_loss: 0.6238 - val_sparse_categorical_accuracy: 0.7876\n",
      "Epoch 33/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4710 - sparse_categorical_accuracy: 0.8664 - val_loss: 0.5994 - val_sparse_categorical_accuracy: 0.8230\n",
      "Epoch 34/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4533 - sparse_categorical_accuracy: 0.8626 - val_loss: 0.6357 - val_sparse_categorical_accuracy: 0.7788\n",
      "Epoch 35/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4033 - sparse_categorical_accuracy: 0.8855 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 36/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.3964 - sparse_categorical_accuracy: 0.8950 - val_loss: 0.5532 - val_sparse_categorical_accuracy: 0.8230\n",
      "Epoch 37/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.3888 - sparse_categorical_accuracy: 0.8855 - val_loss: 0.6114 - val_sparse_categorical_accuracy: 0.8142\n",
      "Epoch 38/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.3997 - sparse_categorical_accuracy: 0.8798 - val_loss: 0.5340 - val_sparse_categorical_accuracy: 0.8319\n",
      "Epoch 39/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.3580 - sparse_categorical_accuracy: 0.9046 - val_loss: 0.5685 - val_sparse_categorical_accuracy: 0.8319\n",
      "Epoch 40/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.3642 - sparse_categorical_accuracy: 0.9008 - val_loss: 0.5459 - val_sparse_categorical_accuracy: 0.8142\n",
      "Epoch 41/600\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.3393 - sparse_categorical_accuracy: 0.9065 - val_loss: 0.5499 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 42/600\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.3514 - sparse_categorical_accuracy: 0.8969 - val_loss: 0.5458 - val_sparse_categorical_accuracy: 0.8142\n",
      "Epoch 43/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.3352 - sparse_categorical_accuracy: 0.9027 - val_loss: 0.4937 - val_sparse_categorical_accuracy: 0.8230\n",
      "Epoch 44/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.3968 - sparse_categorical_accuracy: 0.8740 - val_loss: 0.4641 - val_sparse_categorical_accuracy: 0.8230\n",
      "Epoch 45/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.3734 - sparse_categorical_accuracy: 0.8893 - val_loss: 0.5751 - val_sparse_categorical_accuracy: 0.7876\n",
      "Epoch 46/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 14ms/step - loss: 0.3398 - sparse_categorical_accuracy: 0.9046 - val_loss: 0.4326 - val_sparse_categorical_accuracy: 0.8496\n",
      "Epoch 47/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.2975 - sparse_categorical_accuracy: 0.9103 - val_loss: 0.4955 - val_sparse_categorical_accuracy: 0.8673\n",
      "Epoch 48/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.2910 - sparse_categorical_accuracy: 0.9141 - val_loss: 0.5017 - val_sparse_categorical_accuracy: 0.8407\n",
      "Epoch 49/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.2677 - sparse_categorical_accuracy: 0.9237 - val_loss: 0.4639 - val_sparse_categorical_accuracy: 0.8230\n",
      "Epoch 50/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.3197 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.4958 - val_sparse_categorical_accuracy: 0.8584\n",
      "Epoch 51/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.2747 - sparse_categorical_accuracy: 0.9218 - val_loss: 0.4425 - val_sparse_categorical_accuracy: 0.8319\n",
      "Epoch 52/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.2648 - sparse_categorical_accuracy: 0.9237 - val_loss: 0.5114 - val_sparse_categorical_accuracy: 0.8584\n",
      "Epoch 53/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.2400 - sparse_categorical_accuracy: 0.9408 - val_loss: 0.4830 - val_sparse_categorical_accuracy: 0.8319\n",
      "Epoch 54/600\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.2712 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5493 - val_sparse_categorical_accuracy: 0.8142\n",
      "Epoch 55/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.2543 - sparse_categorical_accuracy: 0.9237 - val_loss: 0.6112 - val_sparse_categorical_accuracy: 0.8319\n",
      "Epoch 56/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.2637 - sparse_categorical_accuracy: 0.9179 - val_loss: 0.5558 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 57/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.2407 - sparse_categorical_accuracy: 0.9389 - val_loss: 0.4427 - val_sparse_categorical_accuracy: 0.8407\n",
      "Epoch 58/600\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.2630 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5091 - val_sparse_categorical_accuracy: 0.8496\n",
      "Epoch 59/600\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.1999 - sparse_categorical_accuracy: 0.9504 - val_loss: 0.4441 - val_sparse_categorical_accuracy: 0.8319\n",
      "Epoch 60/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.1950 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.4459 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 61/600\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.2099 - sparse_categorical_accuracy: 0.9389 - val_loss: 0.4113 - val_sparse_categorical_accuracy: 0.8407\n",
      "Epoch 62/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.2420 - sparse_categorical_accuracy: 0.9179 - val_loss: 0.4438 - val_sparse_categorical_accuracy: 0.8584\n",
      "Epoch 63/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.2008 - sparse_categorical_accuracy: 0.9466 - val_loss: 0.4700 - val_sparse_categorical_accuracy: 0.8584\n",
      "Epoch 64/600\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.1850 - sparse_categorical_accuracy: 0.9542 - val_loss: 0.4468 - val_sparse_categorical_accuracy: 0.8584\n",
      "Epoch 65/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.1992 - sparse_categorical_accuracy: 0.9466 - val_loss: 0.3787 - val_sparse_categorical_accuracy: 0.8496\n",
      "Epoch 66/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.1913 - sparse_categorical_accuracy: 0.9504 - val_loss: 0.4856 - val_sparse_categorical_accuracy: 0.8319\n",
      "Epoch 67/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.1921 - sparse_categorical_accuracy: 0.9466 - val_loss: 0.4708 - val_sparse_categorical_accuracy: 0.8584\n",
      "Epoch 68/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.1684 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.4388 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 69/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.1618 - sparse_categorical_accuracy: 0.9637 - val_loss: 0.4023 - val_sparse_categorical_accuracy: 0.8496\n",
      "Epoch 70/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.1748 - sparse_categorical_accuracy: 0.9504 - val_loss: 0.4074 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 71/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.1678 - sparse_categorical_accuracy: 0.9599 - val_loss: 0.4414 - val_sparse_categorical_accuracy: 0.8584\n",
      "Epoch 72/600\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.1694 - sparse_categorical_accuracy: 0.9637 - val_loss: 0.3707 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 73/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.2248 - sparse_categorical_accuracy: 0.9447 - val_loss: 0.4345 - val_sparse_categorical_accuracy: 0.8496\n",
      "Epoch 74/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.1514 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.3801 - val_sparse_categorical_accuracy: 0.8938\n",
      "Epoch 75/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1389 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.4297 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 76/600\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.2341 - sparse_categorical_accuracy: 0.9275 - val_loss: 0.5691 - val_sparse_categorical_accuracy: 0.8496\n",
      "Epoch 77/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.1593 - sparse_categorical_accuracy: 0.9561 - val_loss: 0.4154 - val_sparse_categorical_accuracy: 0.8496\n",
      "Epoch 78/600\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.1490 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.4693 - val_sparse_categorical_accuracy: 0.8496\n",
      "Epoch 79/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1371 - sparse_categorical_accuracy: 0.9676 - val_loss: 0.3734 - val_sparse_categorical_accuracy: 0.8673\n",
      "Epoch 80/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1301 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.4514 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 81/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1146 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.4426 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 82/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1123 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.4413 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 83/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1544 - sparse_categorical_accuracy: 0.9561 - val_loss: 0.4290 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 84/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1512 - sparse_categorical_accuracy: 0.9561 - val_loss: 0.4223 - val_sparse_categorical_accuracy: 0.8673\n",
      "Epoch 85/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1248 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.3889 - val_sparse_categorical_accuracy: 0.8584\n",
      "Epoch 86/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.1025 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.4819 - val_sparse_categorical_accuracy: 0.8584\n",
      "Epoch 87/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.1676 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.4137 - val_sparse_categorical_accuracy: 0.8673\n",
      "Epoch 88/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1212 - sparse_categorical_accuracy: 0.9676 - val_loss: 0.3959 - val_sparse_categorical_accuracy: 0.8673\n",
      "Epoch 89/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.1030 - sparse_categorical_accuracy: 0.9752 - val_loss: 0.4454 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 90/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1214 - sparse_categorical_accuracy: 0.9752 - val_loss: 0.4454 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 91/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1158 - sparse_categorical_accuracy: 0.9752 - val_loss: 0.4070 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 92/600\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.1011 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.4076 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 93/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1105 - sparse_categorical_accuracy: 0.9695 - val_loss: 0.5359 - val_sparse_categorical_accuracy: 0.8407\n",
      "Epoch 94/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.3573 - val_sparse_categorical_accuracy: 0.9115\n",
      "Epoch 95/600\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.1035 - sparse_categorical_accuracy: 0.9752 - val_loss: 0.4036 - val_sparse_categorical_accuracy: 0.8673\n",
      "Epoch 96/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0987 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.4318 - val_sparse_categorical_accuracy: 0.8673\n",
      "Epoch 97/600\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0941 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.3743 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 98/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.4507 - val_sparse_categorical_accuracy: 0.8938\n",
      "Epoch 99/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1135 - sparse_categorical_accuracy: 0.9676 - val_loss: 0.4463 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 100/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0899 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.4425 - val_sparse_categorical_accuracy: 0.8584\n",
      "Epoch 101/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0807 - sparse_categorical_accuracy: 0.9866 - val_loss: 0.4125 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 102/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1012 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.4380 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 103/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.4325 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 104/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9695 - val_loss: 0.4070 - val_sparse_categorical_accuracy: 0.8673\n",
      "Epoch 105/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.1015 - sparse_categorical_accuracy: 0.9695 - val_loss: 0.4804 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 106/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.1228 - sparse_categorical_accuracy: 0.9695 - val_loss: 0.4225 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 107/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.0653 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.5078 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 108/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.1456 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.4259 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 109/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.4279 - val_sparse_categorical_accuracy: 0.8938\n",
      "Epoch 110/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.3590 - val_sparse_categorical_accuracy: 0.9204\n",
      "Epoch 111/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.3848 - val_sparse_categorical_accuracy: 0.9115\n",
      "Epoch 112/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1364 - sparse_categorical_accuracy: 0.9637 - val_loss: 0.4240 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 113/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.1014 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.4498 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 114/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0856 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.3621 - val_sparse_categorical_accuracy: 0.8938\n",
      "Epoch 115/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0770 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.4059 - val_sparse_categorical_accuracy: 0.8938\n",
      "Epoch 116/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.3913 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 117/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.3711 - val_sparse_categorical_accuracy: 0.8938\n",
      "Epoch 118/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0669 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.4157 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 119/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0708 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.4743 - val_sparse_categorical_accuracy: 0.8584\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "\n",
    ")\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,\n",
    "                    batch_size=16,\n",
    "                    callbacks=[early_stopping],\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6273 - sparse_categorical_accuracy: 0.9027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1bfbbe95b20>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = np.round(model.predict(X_test), decimals=3)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out different network sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "hyperparameters = pd.DataFrame()\n",
    "\n",
    "validation = []\n",
    "for i in range(1,11):\n",
    "\n",
    "    model = None\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(2048, activation='relu')) # relu is used for performance\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(len(gestures), activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "        patience=25, # how many epochs to wait before stopping\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(formatdata, labels, test_size=0.15)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15/0.85)\n",
    "\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs=600,\n",
    "                        batch_size=64,\n",
    "                        callbacks=[early_stopping],\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        verbose=0)\n",
    "    \n",
    "    validation.append(model.evaluate(X_test, y_test))\n",
    "\n",
    "np.average(validation, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "hyperparameters = pd.DataFrame()\n",
    "for s in range(6,12):\n",
    "    for n in range(4, 10):\n",
    "        validation = []\n",
    "        for i in range(1,11):       \n",
    "            \n",
    "            model = None\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "            model = tf.keras.Sequential()\n",
    "            model.add(tf.keras.layers.Dense(2**s, activation='relu')) # relu is used for performance\n",
    "            model.add(tf.keras.layers.Dense(2**s, activation='relu'))\n",
    "            model.add(tf.keras.layers.Dense(2**s, activation='relu'))\n",
    "            model.add(tf.keras.layers.Dense(len(gestures), activation='softmax'))\n",
    "            model.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "            early_stopping = callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "                patience=25, # how many epochs to wait before stopping\n",
    "                restore_best_weights=True,\n",
    "            )\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(formatdata, labels, test_size=0.15)\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15/0.85)\n",
    "\n",
    "            model.fit(X_train, y_train, \n",
    "                                epochs=600,\n",
    "                                batch_size=2**n,\n",
    "                                callbacks=[early_stopping],\n",
    "                                validation_data=(X_val, y_val),\n",
    "                                verbose=0)\n",
    "            \n",
    "            validation.append(model.evaluate(X_test, y_test, verbose=0))\n",
    "            \n",
    "        indexing = 'size={0},bs={1}'.format(2**s,2**n)\n",
    "        hyperparameters[indexing] = np.average(validation, axis=0)\n",
    "        print(indexing)\n",
    "        hyperparameters.transpose().to_csv('Training data/Search results.csv') \n",
    "\n",
    "  \n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax'))\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(formatdata, labels, test_size=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bior1.1 16\n",
      "bior1.3 20\n",
      "bior1.5 24\n",
      "bior2.2 20\n",
      "bior2.4 24\n",
      "bior2.6 27\n",
      "bior2.8 31\n",
      "bior3.1 18\n",
      "bior3.3 22\n",
      "bior3.5 25\n",
      "bior3.7 29\n",
      "bior3.9 33\n",
      "bior4.4 24\n",
      "bior5.5 25\n",
      "bior6.8 31\n",
      "coif1 20\n",
      "coif2 25\n",
      "coif3 31\n",
      "coif4 37\n",
      "coif5 42\n",
      "coif6 48\n",
      "coif7 54\n",
      "coif8 59\n",
      "coif9 65\n",
      "coif10 70\n",
      "coif11 76\n",
      "coif12 82\n",
      "coif13 87\n",
      "coif14 93\n",
      "coif15 99\n",
      "coif16 104\n",
      "coif17 110\n",
      "db1 16\n",
      "db2 18\n",
      "db3 20\n",
      "db4 22\n",
      "db5 24\n",
      "db6 25\n",
      "db7 27\n",
      "db8 29\n",
      "db9 31\n",
      "db10 33\n",
      "db11 35\n",
      "db12 37\n",
      "db13 39\n",
      "db14 40\n",
      "db15 42\n",
      "db16 44\n",
      "db17 46\n",
      "db18 48\n",
      "db19 50\n",
      "db20 52\n",
      "db21 54\n",
      "db22 55\n",
      "db23 57\n",
      "db24 59\n",
      "db25 61\n",
      "db26 63\n",
      "db27 65\n",
      "db28 67\n",
      "db29 69\n",
      "db30 70\n",
      "db31 72\n",
      "db32 74\n",
      "db33 76\n",
      "db34 78\n",
      "db35 80\n",
      "db36 82\n",
      "db37 84\n",
      "db38 85\n",
      "dmey 72\n",
      "haar 16\n",
      "rbio1.1 16\n",
      "rbio1.3 20\n",
      "rbio1.5 24\n",
      "rbio2.2 20\n",
      "rbio2.4 24\n",
      "rbio2.6 27\n",
      "rbio2.8 31\n",
      "rbio3.1 18\n",
      "rbio3.3 22\n",
      "rbio3.5 25\n",
      "rbio3.7 29\n",
      "rbio3.9 33\n",
      "rbio4.4 24\n",
      "rbio5.5 25\n",
      "rbio6.8 31\n",
      "sym2 18\n",
      "sym3 20\n",
      "sym4 22\n",
      "sym5 24\n",
      "sym6 25\n",
      "sym7 27\n",
      "sym8 29\n",
      "sym9 31\n",
      "sym10 33\n",
      "sym11 35\n",
      "sym12 37\n",
      "sym13 39\n",
      "sym14 40\n",
      "sym15 42\n",
      "sym16 44\n",
      "sym17 46\n",
      "sym18 48\n",
      "sym19 50\n",
      "sym20 52\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Training data/test_0_1.csv', index_col=False)\n",
    "\n",
    "\n",
    "for wavelets in pywt.wavelist(kind='discrete'):\n",
    "    cA, cD = wavelet(data['aX'], level=4, wavelet=wavelets)\n",
    "    print(wavelets, len(cA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bior1.1 250\n",
      "bior1.3 250\n",
      "bior1.5 250\n",
      "bior2.2 250\n",
      "bior2.4 250\n",
      "bior2.6 250\n",
      "bior2.8 250\n",
      "bior3.1 250\n",
      "bior3.3 250\n",
      "bior3.5 250\n",
      "bior3.7 250\n",
      "bior3.9 250\n",
      "bior4.4 250\n",
      "bior5.5 250\n",
      "bior6.8 250\n",
      "coif1 250\n",
      "coif2 250\n",
      "coif3 250\n",
      "coif4 250\n",
      "coif5 250\n",
      "coif6 250\n",
      "coif7 250\n",
      "coif8 250\n",
      "coif9 250\n",
      "coif10 250\n",
      "coif11 250\n",
      "coif12 250\n",
      "coif13 250\n",
      "coif14 250\n",
      "coif15 250\n",
      "coif16 250\n",
      "coif17 250\n",
      "db1 250\n",
      "db2 250\n",
      "db3 250\n",
      "db4 250\n",
      "db5 250\n",
      "db6 250\n",
      "db7 250\n",
      "db8 250\n",
      "db9 250\n",
      "db10 250\n",
      "db11 250\n",
      "db12 250\n",
      "db13 250\n",
      "db14 250\n",
      "db15 250\n",
      "db16 250\n",
      "db17 250\n",
      "db18 250\n",
      "db19 250\n",
      "db20 250\n",
      "db21 250\n",
      "db22 250\n",
      "db23 250\n",
      "db24 250\n",
      "db25 250\n",
      "db26 250\n",
      "db27 250\n",
      "db28 250\n",
      "db29 250\n",
      "db30 250\n",
      "db31 250\n",
      "db32 250\n",
      "db33 250\n",
      "db34 250\n",
      "db35 250\n",
      "db36 250\n",
      "db37 250\n",
      "db38 250\n",
      "dmey 250\n",
      "haar 250\n",
      "rbio1.1 250\n",
      "rbio1.3 250\n",
      "rbio1.5 250\n",
      "rbio2.2 250\n",
      "rbio2.4 250\n",
      "rbio2.6 250\n",
      "rbio2.8 250\n",
      "rbio3.1 250\n",
      "rbio3.3 250\n",
      "rbio3.5 250\n",
      "rbio3.7 250\n",
      "rbio3.9 250\n",
      "rbio4.4 250\n",
      "rbio5.5 250\n",
      "rbio6.8 250\n",
      "sym2 250\n",
      "sym3 250\n",
      "sym4 250\n",
      "sym5 250\n",
      "sym6 250\n",
      "sym7 250\n",
      "sym8 250\n",
      "sym9 250\n",
      "sym10 250\n",
      "sym11 250\n",
      "sym12 250\n",
      "sym13 250\n",
      "sym14 250\n",
      "sym15 250\n",
      "sym16 250\n",
      "sym17 250\n",
      "sym18 250\n",
      "sym19 250\n",
      "sym20 250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.11907043, 6.82421168, 5.54193904, ..., 5.47097165, 2.03045972,\n",
       "        6.6133078 ],\n",
       "       [1.76582527, 7.07106004, 5.58133428, ..., 5.51645218, 1.65935855,\n",
       "        6.89269203],\n",
       "       [1.28792127, 7.44748464, 5.65716753, ..., 5.60261207, 1.15739409,\n",
       "        7.31969186],\n",
       "       ...,\n",
       "       [1.77345531, 1.59840199, 1.74877987, ..., 1.71594344, 1.81150374,\n",
       "        1.44454511],\n",
       "       [1.79842513, 1.46981649, 1.67034383, ..., 1.63695682, 1.84105714,\n",
       "        1.31106903],\n",
       "       [1.83006621, 1.42822707, 1.65457439, ..., 1.62030465, 1.87439826,\n",
       "        1.26555314]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Training data/test_0_1.csv', index_col=False)\n",
    "\n",
    "\n",
    "for wavelets in pywt.wavelist(kind='discrete'):\n",
    "    cA, cD = wavelet(data['aX'], level=2, wavelet=wavelets)\n",
    "    print(wavelets, len(cA))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
