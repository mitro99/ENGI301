{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "def wavelet(data, level, wavelet):\n",
    "    (cA, cD) = pywt.dwt(data, wavelet=wavelet)\n",
    "    for i in range(1, level):\n",
    "        (cA, cD) = pywt.dwt(cA, wavelet=wavelet)\n",
    "    return cA, cD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gestures = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10\n",
    "]\n",
    "num_samples = 50\n",
    "num_gestures = len(gestures)\n",
    "\n",
    "one_hot = np.eye(len(gestures))\n",
    "\n",
    "\n",
    "\n",
    "fulldata = pd.DataFrame(columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "fullwavedata = pd.DataFrame(columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'])\n",
    "formatdata = pd.DataFrame()\n",
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "labels = []\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        filepath = 'hand/hand_{0}_{1}.csv'.format(gesture, i)\n",
    "        data = pd.read_csv(filepath, index_col=False)\n",
    "        wavedata = pd.DataFrame()\n",
    "        \n",
    "        level1 = 5\n",
    "        wavetype1 = 'db20'\n",
    "        \n",
    "        wavedata['aX_A1'], wavedata['aX_D1'] = wavelet(data['aX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aY_A1'], wavedata['aY_D1'] = wavelet(data['aY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aZ_A1'], wavedata['aZ_D1'] = wavelet(data['aZ'], level=level1, wavelet=wavetype1)\n",
    "\n",
    "        wavedata['gX_A1'], wavedata['gX_D1'] = wavelet(data['gX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gY_A1'], wavedata['gY_D1'] = wavelet(data['gY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gZ_A1'], wavedata['gZ_D1'] = wavelet(data['gZ'], level=level1, wavelet=wavetype1)\n",
    "        \n",
    "        level2 = 3\n",
    "        wavetype2 = 'rbio2.2'\n",
    "\n",
    "        wavedata['aX_A2'], wavedata['aX_D2'] = wavelet(data['aX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aY_A2'], wavedata['aY_D2'] = wavelet(data['aY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aZ_A2'], wavedata['aZ_D2'] = wavelet(data['aZ'], level=level2, wavelet=wavetype2)\n",
    "\n",
    "        wavedata['gX_A2'], wavedata['gX_D2'] = wavelet(data['gX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gY_A2'], wavedata['gY_D2'] = wavelet(data['gY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gZ_A2'], wavedata['gZ_D2'] = wavelet(data['gZ'], level=level2, wavelet=wavetype2)\n",
    "        \n",
    "        wavelen = len(wavedata)\n",
    "        \n",
    "        fullwavedata = fullwavedata.append(wavedata)\n",
    "        fulldata = fulldata.append(data)\n",
    "        label = gesture\n",
    "        labels.append(label)\n",
    "        del data, wavedata\n",
    "\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normaldata = (fulldata - fulldata.min()) / (fulldata.max()-fulldata.min())\n",
    "normaldata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatdata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*250 + (i-1) * 250\n",
    "        #print(index, index+250)\n",
    "        dataf = normaldata.iloc[index:index+250].to_numpy().flatten().tolist()\n",
    "        formatdata[idx*num_samples+i-1] = dataf\n",
    "        del dataf\n",
    "        \n",
    "        \n",
    "formatdata = formatdata.transpose().to_numpy()\n",
    "formatdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = np.array(fullwavedata.min(), dtype='float32')\n",
    "maxval = np.array(fullwavedata.max(), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pd.DataFrame([minval, maxval], columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'], index=['min','max'])\n",
    "parameters.to_csv('dataparameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX_A1</th>\n",
       "      <th>aX_D1</th>\n",
       "      <th>aY_A1</th>\n",
       "      <th>aY_D1</th>\n",
       "      <th>aZ_A1</th>\n",
       "      <th>aZ_D1</th>\n",
       "      <th>gX_A1</th>\n",
       "      <th>gX_D1</th>\n",
       "      <th>gY_A1</th>\n",
       "      <th>gY_D1</th>\n",
       "      <th>...</th>\n",
       "      <th>aY_A2</th>\n",
       "      <th>aY_D2</th>\n",
       "      <th>aZ_A2</th>\n",
       "      <th>aZ_D2</th>\n",
       "      <th>gX_A2</th>\n",
       "      <th>gX_D2</th>\n",
       "      <th>gY_A2</th>\n",
       "      <th>gY_D2</th>\n",
       "      <th>gZ_A2</th>\n",
       "      <th>gZ_D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.267300</td>\n",
       "      <td>0.474299</td>\n",
       "      <td>0.532783</td>\n",
       "      <td>0.475571</td>\n",
       "      <td>0.587976</td>\n",
       "      <td>0.513237</td>\n",
       "      <td>0.493822</td>\n",
       "      <td>0.496712</td>\n",
       "      <td>0.483855</td>\n",
       "      <td>0.515383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432839</td>\n",
       "      <td>0.449727</td>\n",
       "      <td>0.558324</td>\n",
       "      <td>0.521365</td>\n",
       "      <td>0.500183</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.410186</td>\n",
       "      <td>0.521206</td>\n",
       "      <td>0.502551</td>\n",
       "      <td>0.583230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.123643</td>\n",
       "      <td>0.066293</td>\n",
       "      <td>0.116047</td>\n",
       "      <td>0.059190</td>\n",
       "      <td>0.129127</td>\n",
       "      <td>0.080489</td>\n",
       "      <td>0.125645</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.116264</td>\n",
       "      <td>0.072924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083774</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.097088</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.102759</td>\n",
       "      <td>0.048254</td>\n",
       "      <td>0.099510</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>0.090144</td>\n",
       "      <td>0.035227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.193030</td>\n",
       "      <td>0.451570</td>\n",
       "      <td>0.475979</td>\n",
       "      <td>0.461617</td>\n",
       "      <td>0.511344</td>\n",
       "      <td>0.488324</td>\n",
       "      <td>0.429299</td>\n",
       "      <td>0.476434</td>\n",
       "      <td>0.403973</td>\n",
       "      <td>0.493319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403568</td>\n",
       "      <td>0.446310</td>\n",
       "      <td>0.494259</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.482615</td>\n",
       "      <td>0.515702</td>\n",
       "      <td>0.388433</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>0.492884</td>\n",
       "      <td>0.579189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.238372</td>\n",
       "      <td>0.475990</td>\n",
       "      <td>0.541994</td>\n",
       "      <td>0.478134</td>\n",
       "      <td>0.593200</td>\n",
       "      <td>0.513502</td>\n",
       "      <td>0.502039</td>\n",
       "      <td>0.497601</td>\n",
       "      <td>0.497887</td>\n",
       "      <td>0.511452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435093</td>\n",
       "      <td>0.449777</td>\n",
       "      <td>0.557355</td>\n",
       "      <td>0.521536</td>\n",
       "      <td>0.506969</td>\n",
       "      <td>0.519877</td>\n",
       "      <td>0.404442</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.502341</td>\n",
       "      <td>0.582993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.316260</td>\n",
       "      <td>0.497073</td>\n",
       "      <td>0.597311</td>\n",
       "      <td>0.492333</td>\n",
       "      <td>0.673205</td>\n",
       "      <td>0.538372</td>\n",
       "      <td>0.545229</td>\n",
       "      <td>0.518854</td>\n",
       "      <td>0.545459</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470832</td>\n",
       "      <td>0.453207</td>\n",
       "      <td>0.617096</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.523956</td>\n",
       "      <td>0.524138</td>\n",
       "      <td>0.415941</td>\n",
       "      <td>0.525350</td>\n",
       "      <td>0.515112</td>\n",
       "      <td>0.586998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              aX_A1         aX_D1         aY_A1         aY_D1         aZ_A1  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.267300      0.474299      0.532783      0.475571      0.587976   \n",
       "std        0.123643      0.066293      0.116047      0.059190      0.129127   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.193030      0.451570      0.475979      0.461617      0.511344   \n",
       "50%        0.238372      0.475990      0.541994      0.478134      0.593200   \n",
       "75%        0.316260      0.497073      0.597311      0.492333      0.673205   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              aZ_D1         gX_A1         gX_D1         gY_A1         gY_D1  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.513237      0.493822      0.496712      0.483855      0.515383   \n",
       "std        0.080489      0.125645      0.090167      0.116264      0.072924   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.488324      0.429299      0.476434      0.403973      0.493319   \n",
       "50%        0.513502      0.502039      0.497601      0.497887      0.511452   \n",
       "75%        0.538372      0.545229      0.518854      0.545459      0.537361   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...         aY_A2         aY_D2         aZ_A2         aZ_D2  \\\n",
       "count  ...  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean   ...      0.432839      0.449727      0.558324      0.521365   \n",
       "std    ...      0.083774      0.033548      0.097088      0.042426   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.403568      0.446310      0.494259      0.515400   \n",
       "50%    ...      0.435093      0.449777      0.557355      0.521536   \n",
       "75%    ...      0.470832      0.453207      0.617096      0.527778   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gX_A2         gX_D2         gY_A2         gY_D2         gZ_A2  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.500183      0.519830      0.410186      0.521206      0.502551   \n",
       "std        0.102759      0.048254      0.099510      0.040963      0.090144   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.482615      0.515702      0.388433      0.517965      0.492884   \n",
       "50%        0.506969      0.519877      0.404442      0.521259      0.502341   \n",
       "75%        0.523956      0.524138      0.415941      0.525350      0.515112   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gZ_D2  \n",
       "count  26400.000000  \n",
       "mean       0.583230  \n",
       "std        0.035227  \n",
       "min        0.000000  \n",
       "25%        0.579189  \n",
       "50%        0.582993  \n",
       "75%        0.586998  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalwavedata = (fullwavedata - fullwavedata.min()) / (fullwavedata.max()-fullwavedata.min())\n",
    "normalwavedata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2454407 , 0.41080022, 0.32581968, ..., 0.5188936 , 0.4929458 ,\n",
       "        0.58779549],\n",
       "       [0.19500412, 0.51896688, 0.61033764, ..., 0.52143732, 0.49012884,\n",
       "        0.58391459],\n",
       "       [0.22643872, 0.4297922 , 0.33365506, ..., 0.52195295, 0.49385348,\n",
       "        0.58364604],\n",
       "       ...,\n",
       "       [0.56100788, 0.25162484, 0.60983698, ..., 0.51909722, 0.50125362,\n",
       "        0.58275752],\n",
       "       [0.629451  , 0.41301135, 0.71584526, ..., 0.52259185, 0.51834611,\n",
       "        0.58284503],\n",
       "       [0.62376549, 0.2756082 , 0.4846425 , ..., 0.52138206, 0.5016146 ,\n",
       "        0.58184442]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*wavelen + (i-1) * wavelen\n",
    "        #print(index, index+250)\n",
    "        wavedataf = normalwavedata.iloc[index:index+wavelen].to_numpy().flatten().tolist()\n",
    "        formatwavedata[idx*num_samples+i-1] = wavedataf\n",
    "        del wavedataf\n",
    "        \n",
    "        \n",
    "formatwavedata = formatwavedata.transpose().to_numpy()\n",
    "formatwavedata \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(formatwavedata, labels, test_size=0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15/0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "1: Train 0.08854166666666667; Test 0.0963855421686747; Val 0.0963855421686747\n",
      "2: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "3: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "4: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "5: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "6: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "7: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "8: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "9: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15)\n",
    "valsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15/0.85)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatwavedata, labels):\n",
    "    X_train, X_test = formatwavedata[train_index], formatwavedata[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "for train_index, val_index in valsplit.split(X_train, y_train):\n",
    "    X_train, X_val = X_train[train_index], X_train[val_index]\n",
    "    y_train, y_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "for i in range(0,10):\n",
    "    print('{3}: Train {0}; Test {1}; Val {2}'.format(np.size(np.where(y_train == i)) / len(y_train), np.size(np.where(y_test == i)) / len(y_test), np.size(np.where(y_val == i)) / len(y_val), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 2.4077 - sparse_categorical_accuracy: 0.1172 - val_loss: 2.3226 - val_sparse_categorical_accuracy: 0.3253\n",
      "Epoch 2/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 2.3528 - sparse_categorical_accuracy: 0.1484 - val_loss: 2.2602 - val_sparse_categorical_accuracy: 0.4337\n",
      "Epoch 3/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 2.2891 - sparse_categorical_accuracy: 0.2083 - val_loss: 2.1861 - val_sparse_categorical_accuracy: 0.5422\n",
      "Epoch 4/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 2.2291 - sparse_categorical_accuracy: 0.2396 - val_loss: 2.1111 - val_sparse_categorical_accuracy: 0.6024\n",
      "Epoch 5/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 2.1351 - sparse_categorical_accuracy: 0.3177 - val_loss: 2.0006 - val_sparse_categorical_accuracy: 0.5181\n",
      "Epoch 6/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 2.0483 - sparse_categorical_accuracy: 0.3672 - val_loss: 1.8997 - val_sparse_categorical_accuracy: 0.5422\n",
      "Epoch 7/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.9164 - sparse_categorical_accuracy: 0.4297 - val_loss: 1.7673 - val_sparse_categorical_accuracy: 0.6506\n",
      "Epoch 8/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.8050 - sparse_categorical_accuracy: 0.4219 - val_loss: 1.6792 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 9/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.6399 - sparse_categorical_accuracy: 0.4740 - val_loss: 1.5425 - val_sparse_categorical_accuracy: 0.6386\n",
      "Epoch 10/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.5561 - sparse_categorical_accuracy: 0.5208 - val_loss: 1.4206 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 11/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.4980 - sparse_categorical_accuracy: 0.5443 - val_loss: 1.3881 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 12/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.3854 - sparse_categorical_accuracy: 0.5781 - val_loss: 1.3012 - val_sparse_categorical_accuracy: 0.6506\n",
      "Epoch 13/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 1.3673 - sparse_categorical_accuracy: 0.5312 - val_loss: 1.2152 - val_sparse_categorical_accuracy: 0.7711\n",
      "Epoch 14/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.2629 - sparse_categorical_accuracy: 0.6198 - val_loss: 1.1526 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 15/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.1764 - sparse_categorical_accuracy: 0.6458 - val_loss: 1.0941 - val_sparse_categorical_accuracy: 0.7349\n",
      "Epoch 16/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.1206 - sparse_categorical_accuracy: 0.6615 - val_loss: 1.0927 - val_sparse_categorical_accuracy: 0.6506\n",
      "Epoch 17/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 1.0821 - sparse_categorical_accuracy: 0.6849 - val_loss: 0.9918 - val_sparse_categorical_accuracy: 0.7711\n",
      "Epoch 18/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.9821 - sparse_categorical_accuracy: 0.7240 - val_loss: 0.9236 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 19/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.9559 - sparse_categorical_accuracy: 0.7292 - val_loss: 0.9426 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 20/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.9365 - sparse_categorical_accuracy: 0.7214 - val_loss: 0.7981 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 21/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.8594 - sparse_categorical_accuracy: 0.7786 - val_loss: 0.7258 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 22/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.7460 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.7036 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 23/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.7823 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6836 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 24/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.7484 - sparse_categorical_accuracy: 0.7812 - val_loss: 0.7741 - val_sparse_categorical_accuracy: 0.7831\n",
      "Epoch 25/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.6634 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.6282 - val_sparse_categorical_accuracy: 0.8193\n",
      "Epoch 26/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.6375 - sparse_categorical_accuracy: 0.8151 - val_loss: 0.6081 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 27/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.6202 - sparse_categorical_accuracy: 0.8411 - val_loss: 0.5698 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 28/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.5640 - sparse_categorical_accuracy: 0.8620 - val_loss: 0.6022 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 29/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.6284 - sparse_categorical_accuracy: 0.8125 - val_loss: 0.6473 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 30/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.5739 - sparse_categorical_accuracy: 0.8307 - val_loss: 0.5976 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 31/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.5322 - sparse_categorical_accuracy: 0.8594 - val_loss: 0.5570 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 32/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.4946 - sparse_categorical_accuracy: 0.8724 - val_loss: 0.5083 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 33/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.4590 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.4524 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 34/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.4329 - sparse_categorical_accuracy: 0.8776 - val_loss: 0.4271 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 35/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3945 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.4127 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 36/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3943 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.4154 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 37/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.3792 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.3793 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 38/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.3819 - sparse_categorical_accuracy: 0.9036 - val_loss: 0.4140 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 39/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.3546 - sparse_categorical_accuracy: 0.9115 - val_loss: 0.3703 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 40/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3377 - sparse_categorical_accuracy: 0.9141 - val_loss: 0.3455 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 41/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.3321 - sparse_categorical_accuracy: 0.9193 - val_loss: 0.4588 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 42/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3644 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.3131 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 43/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3267 - sparse_categorical_accuracy: 0.9141 - val_loss: 0.3268 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 44/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3087 - sparse_categorical_accuracy: 0.9245 - val_loss: 0.3655 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 45/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.2973 - sparse_categorical_accuracy: 0.9271 - val_loss: 0.3749 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 46/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 42ms/step - loss: 0.2747 - sparse_categorical_accuracy: 0.9323 - val_loss: 0.3266 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 47/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.2982 - sparse_categorical_accuracy: 0.9245 - val_loss: 0.3127 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 48/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.3243 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.2954 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 49/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.2834 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.2470 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 50/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.2935 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.2743 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 51/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.2723 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.3008 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 52/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.2803 - sparse_categorical_accuracy: 0.9323 - val_loss: 0.4173 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 53/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.2682 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.3841 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 54/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.2451 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.2725 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 55/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.2897 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.2608 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 56/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.2048 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2401 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 57/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1865 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2823 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 58/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.2161 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.3273 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 59/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.1960 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.2563 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 60/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.2004 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.2510 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 61/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1891 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2315 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 62/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1929 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.2421 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 63/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1837 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2505 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 64/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.1921 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.2169 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 65/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1537 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2220 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 66/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1709 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.2539 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 67/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.1886 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.2514 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 68/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1590 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.3200 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 69/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1775 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.2722 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 70/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1966 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.3404 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 71/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1468 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2079 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 72/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1276 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2452 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 73/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1158 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1996 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 74/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1187 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2732 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 75/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1416 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.3256 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 76/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.1358 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.2087 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 77/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1147 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.3082 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 78/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2734 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 79/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.1996 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 80/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1313 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2738 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 81/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1219 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2845 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 82/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1283 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.1900 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 83/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.1196 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2059 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 84/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1244 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.2172 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 85/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1967 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 86/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2009 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 87/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.0952 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2824 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 88/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.1078 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2440 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 89/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.0789 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1667 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 90/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.3758 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 91/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2647 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 92/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1248 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2328 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 93/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.1293 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.2073 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 94/600\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1684 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 95/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.1095 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.1932 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 96/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.1083 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2022 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 97/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.1008 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2459 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 98/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0776 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2388 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 99/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0616 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2010 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 100/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.2574 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 101/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1411 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 102/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0712 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.2652 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 103/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.2531 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 104/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0880 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.2556 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 105/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1706 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 106/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0949 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2757 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 107/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2676 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 108/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2516 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 109/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0554 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.2382 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 110/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.2044 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 111/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0526 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.2097 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 112/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0604 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.3276 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 113/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0664 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1691 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 114/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2605 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 115/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0599 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2690 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 116/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0523 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1467 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 117/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.2335 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 118/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.0551 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1952 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 119/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.0735 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.3593 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 120/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2139 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 121/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0817 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.1888 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 122/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0869 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2774 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 123/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0596 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.3578 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 124/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.0504 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.1279 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 125/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0391 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2201 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 126/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.2564 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 127/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0335 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.1760 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 128/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0485 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1897 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 129/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0379 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.3387 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 130/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.3011 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 131/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1005 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.3038 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 132/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1121 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2818 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 133/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.3243 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 134/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1019 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.3939 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 135/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0604 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.2662 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 136/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0716 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2944 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 137/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0385 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.2687 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 138/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0356 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.2672 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 139/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.2163 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 140/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.1934 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 141/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0622 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.3058 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 142/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.1661 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 143/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0335 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.2679 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 144/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0263 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.2820 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 145/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0257 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.2176 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 146/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2874 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 147/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0366 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.1862 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 148/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0468 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.2598 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 149/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0303 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.2272 - val_sparse_categorical_accuracy: 0.9398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1abea8c8b50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "\n",
    ")\n",
    "model.fit(X_train, y_train, \n",
    "            epochs=600,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stopping],\n",
    "            validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2343 - sparse_categorical_accuracy: 0.9518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1abe6d2f160>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "data (Dense)                 (None, 1024)              1180672   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "result (Dense)               (None, 11)                11275     \n",
      "=================================================================\n",
      "Total params: 3,291,147\n",
      "Trainable params: 3,291,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = tf.keras.models.load_model('Training data/model1')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testvar\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testvar\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    model, 'testvar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmppn6r4u0b\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('test_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'data_input', 'index': 0, 'shape': array([   1, 1584]), 'shape_signature': array([  -1, 1584]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='test_model.tflite')\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(input_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_resize_dispatcher() got an unexpected keyword argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-51493053cb49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrydata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1584\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mresize\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _resize_dispatcher() got an unexpected keyword argument 'dtype'"
     ]
    }
   ],
   "source": [
    "trydata = np.resize(X_test[0], (1, 1584))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.004 0.    0.449 0.007 0.    0.    0.536 0.004 0.   ]]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "input_data = np.float32(np.resize(X_test[46], (1, 1584)))\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(np.round(output_data, decimals=3))\n",
    "print(y_test[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsure\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 113):\n",
    "    input_data = np.float32(np.resize(X_test[i], (1, 1584)))\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    output_data\n",
    "\n",
    "    if np.max(output_data) < 0.6:\n",
    "        print('Unsure')\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output_data)\n",
    "if max(output_data) < 0.5:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "SignatureDef method_name is None and model has 0 Signatures. None is only allowed when the model has 1 SignatureDef",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7c4bc9d72a2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msignatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_signature_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_signature_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36mget_signature_runner\u001b[1;34m(self, method_name)\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_signature_defs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;34m'SignatureDef method_name is None and model has {0} Signatures. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             'None is only allowed when the model has 1 SignatureDef'.format(\n",
      "\u001b[1;31mValueError\u001b[0m: SignatureDef method_name is None and model has 0 Signatures. None is only allowed when the model has 1 SignatureDef"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='test_model.tflite')\n",
    "\n",
    "signatures = interpreter.get_signature_list()\n",
    "print(signatures)\n",
    "predictor = interpreter.get_signature_runner()\n",
    "print(predictor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0964601e-07, 9.1763778e-04, 1.6810007e-05, 4.2849658e-03,\n",
       "        2.6555134e-03, 2.2810149e-05, 2.0116172e-04, 9.7670448e-01,\n",
       "        4.2905535e-06, 1.5192278e-02]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = predictor(data_input=np.float32(X_test[0]))['result']\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1584"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1bbd703a0d0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "output_lbl = np.argmax(output, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, output_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 2s 72ms/step - loss: 2.4147 - sparse_categorical_accuracy: 0.1205 - val_loss: 2.3086 - val_sparse_categorical_accuracy: 0.3373\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 2.3269 - sparse_categorical_accuracy: 0.1955 - val_loss: 2.2176 - val_sparse_categorical_accuracy: 0.2892\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 2.2167 - sparse_categorical_accuracy: 0.2523 - val_loss: 2.1059 - val_sparse_categorical_accuracy: 0.4699\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 2.1231 - sparse_categorical_accuracy: 0.3341 - val_loss: 1.9864 - val_sparse_categorical_accuracy: 0.5783\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.9980 - sparse_categorical_accuracy: 0.3727 - val_loss: 1.8181 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 1.8716 - sparse_categorical_accuracy: 0.4205 - val_loss: 1.6938 - val_sparse_categorical_accuracy: 0.5542\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 1.7055 - sparse_categorical_accuracy: 0.4636 - val_loss: 1.5393 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 1.5679 - sparse_categorical_accuracy: 0.5000 - val_loss: 1.3999 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 1.4499 - sparse_categorical_accuracy: 0.5659 - val_loss: 1.3510 - val_sparse_categorical_accuracy: 0.6747\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 1.3558 - sparse_categorical_accuracy: 0.6023 - val_loss: 1.2222 - val_sparse_categorical_accuracy: 0.6506\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 1.2366 - sparse_categorical_accuracy: 0.6682 - val_loss: 1.1081 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.1758 - sparse_categorical_accuracy: 0.6295 - val_loss: 1.0220 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.0802 - sparse_categorical_accuracy: 0.6932 - val_loss: 0.9489 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.0125 - sparse_categorical_accuracy: 0.7136 - val_loss: 0.8412 - val_sparse_categorical_accuracy: 0.8193\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.9388 - sparse_categorical_accuracy: 0.7409 - val_loss: 0.8391 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.8733 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.7876 - sparse_categorical_accuracy: 0.7932 - val_loss: 0.6345 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.7428 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.6306 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.6828 - sparse_categorical_accuracy: 0.8341 - val_loss: 0.5110 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6751 - sparse_categorical_accuracy: 0.8023 - val_loss: 0.4759 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.5983 - sparse_categorical_accuracy: 0.8432 - val_loss: 0.5046 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.5354 - sparse_categorical_accuracy: 0.8659 - val_loss: 0.4476 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.5004 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.4481 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.5130 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.3997 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4662 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.3381 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4426 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.3342 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4338 - sparse_categorical_accuracy: 0.8773 - val_loss: 0.3313 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4425 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.3131 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4262 - sparse_categorical_accuracy: 0.9000 - val_loss: 0.3475 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3833 - sparse_categorical_accuracy: 0.9068 - val_loss: 0.3043 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3502 - sparse_categorical_accuracy: 0.9114 - val_loss: 0.2491 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.3571 - sparse_categorical_accuracy: 0.9159 - val_loss: 0.2475 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.3121 - sparse_categorical_accuracy: 0.9000 - val_loss: 0.2679 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3404 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.2218 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2857 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.2239 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3000 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.2080 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2614 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.2367 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2877 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.1961 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2257 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.1685 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2200 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.1508 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2116 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.1492 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2055 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1217 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2237 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.1796 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2183 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.1695 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1967 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.1193 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 46/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2143 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.1608 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2133 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.1656 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1963 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.2018 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1722 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1102 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1594 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1102 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1560 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0920 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1495 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1407 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1742 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1657 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1798 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.1314 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1454 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.0864 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1625 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1198 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1368 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.0716 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1142 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0733 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1544 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1029 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0611 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0920 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0717 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0957 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0689 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1449 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.0565 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1284 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.0853 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1133 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0530 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1253 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1035 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1351 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.0998 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1155 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0777 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.0633 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0922 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0546 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0985 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0827 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 1s 70ms/step - loss: 0.1052 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0505 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0497 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 0.0970 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0599 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0714 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0842 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0904 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0503 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 0.0829 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0575 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0768 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0895 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0773 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0994 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0396 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0789 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0450 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 83/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0634 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0732 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0410 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 0.0514 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0434 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0843 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0443 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0873 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.0665 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0315 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0452 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0668 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0498 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 91/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0782 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0587 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0545 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0474 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0466 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0321 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0391 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0397 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0408 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0408 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0472 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0368 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0415 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0306 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0362 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0488 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0431 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0282 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0480 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0608 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0356 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0467 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0306 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0381 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0574 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0380 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0540 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0656 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1865 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0941 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0637 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0733 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0402 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0551 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0693 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0693 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0438 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0452 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0845 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0947 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0694 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0532 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1015 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0792 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0486 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0403 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0354 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0268 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0431 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0367 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0232 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0201 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0235 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 121/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0222 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 122/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0266 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0412 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 123/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0388 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0349 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 124/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0666 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0302 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 125/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0359 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 126/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0556 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0977 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 127/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 128/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0444 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0245 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 129/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0332 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0363 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 130/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0189 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0393 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 131/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0165 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0325 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 132/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0147 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 133/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0439 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0599 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 134/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0323 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0131 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 135/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0224 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0107 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 136/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/14 [=========>....................] - ETA: 0s - loss: 0.0353 - sparse_categorical_accuracy: 0.9937"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatwavedata, labels):\n",
    "    X_train, X_test = formatwavedata[train_index], formatwavedata[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('number_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "hyperparameters = pd.DataFrame()\n",
    "for s in range(6,12):\n",
    "    for n in range(4, 10):\n",
    "        validation = []\n",
    "        for i in range(1,11):       \n",
    "            \n",
    "            model = None\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "            model = tf.keras.Sequential()\n",
    "            model.add(tf.keras.layers.Dense(2**s, activation='relu')) # relu is used for performance\n",
    "            model.add(tf.keras.layers.Dense(2**s, activation='relu'))\n",
    "            model.add(tf.keras.layers.Dense(2**s, activation='relu'))\n",
    "            model.add(tf.keras.layers.Dense(len(gestures), activation='softmax'))\n",
    "            model.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "            early_stopping = callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "                patience=25, # how many epochs to wait before stopping\n",
    "                restore_best_weights=True,\n",
    "            )\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(formatdata, labels, test_size=0.15)\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15/0.85)\n",
    "\n",
    "            model.fit(X_train, y_train, \n",
    "                                epochs=600,\n",
    "                                batch_size=2**n,\n",
    "                                callbacks=[early_stopping],\n",
    "                                validation_data=(X_val, y_val),\n",
    "                                verbose=0)\n",
    "            \n",
    "            validation.append(model.evaluate(X_test, y_test, verbose=0))\n",
    "            \n",
    "        indexing = 'size={0},bs={1}'.format(2**s,2**n)\n",
    "        hyperparameters[indexing] = np.average(validation, axis=0)\n",
    "        print(indexing)\n",
    "        hyperparameters.transpose().to_csv('Training data/Search results.csv') \n",
    "\n",
    "  \n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
