{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Gesture Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules and define wavelet function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "def wavelet(data, level, wavelet):\n",
    "    (cA, cD) = pywt.dwt(data, wavelet=wavelet)\n",
    "    for i in range(1, level):\n",
    "        (cA, cD) = pywt.dwt(cA, wavelet=wavelet)\n",
    "    return cA, cD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and perform wavelet transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gestures = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10\n",
    "]\n",
    "num_samples = 50\n",
    "num_gestures = len(gestures)\n",
    "\n",
    "fulldata = pd.DataFrame(columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "fullwavedata = pd.DataFrame(columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'])\n",
    "formatdata = pd.DataFrame()\n",
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "labels = []\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        filepath = 'hand/hand_{0}_{1}.csv'.format(gesture, i)\n",
    "        data = pd.read_csv(filepath, index_col=False)\n",
    "        wavedata = pd.DataFrame()\n",
    "        \n",
    "        level1 = 3\n",
    "        wavetype1 = 'rbio2.2'\n",
    "        #Start creating the dataframe with transformed data\n",
    "        wavedata['aX_A1'], wavedata['aX_D1'] = wavelet(data['aX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aY_A1'], wavedata['aY_D1'] = wavelet(data['aY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aZ_A1'], wavedata['aZ_D1'] = wavelet(data['aZ'], level=level1, wavelet=wavetype1)\n",
    "\n",
    "        wavedata['gX_A1'], wavedata['gX_D1'] = wavelet(data['gX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gY_A1'], wavedata['gY_D1'] = wavelet(data['gY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gZ_A1'], wavedata['gZ_D1'] = wavelet(data['gZ'], level=level1, wavelet=wavetype1)\n",
    "        \n",
    "        level2 = 3\n",
    "        wavetype2 = 'rbio2.2'\n",
    "\n",
    "        wavedata['aX_A2'], wavedata['aX_D2'] = wavelet(data['aX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aY_A2'], wavedata['aY_D2'] = wavelet(data['aY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aZ_A2'], wavedata['aZ_D2'] = wavelet(data['aZ'], level=level2, wavelet=wavetype2)\n",
    "\n",
    "        wavedata['gX_A2'], wavedata['gX_D2'] = wavelet(data['gX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gY_A2'], wavedata['gY_D2'] = wavelet(data['gY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gZ_A2'], wavedata['gZ_D2'] = wavelet(data['gZ'], level=level2, wavelet=wavetype2)\n",
    "        \n",
    "        wavelen = len(wavedata)\n",
    "        \n",
    "        #create a full dataframe with all the data\n",
    "        fullwavedata = fullwavedata.append(wavedata)\n",
    "        fulldata = fulldata.append(data)\n",
    "        label = gesture\n",
    "        labels.append(label)\n",
    "        del data, wavedata\n",
    "\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX</th>\n",
       "      <th>aY</th>\n",
       "      <th>aZ</th>\n",
       "      <th>gX</th>\n",
       "      <th>gY</th>\n",
       "      <th>gZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.400953</td>\n",
       "      <td>0.508082</td>\n",
       "      <td>0.541712</td>\n",
       "      <td>0.499318</td>\n",
       "      <td>0.427822</td>\n",
       "      <td>0.502331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.074306</td>\n",
       "      <td>0.068467</td>\n",
       "      <td>0.085276</td>\n",
       "      <td>0.096042</td>\n",
       "      <td>0.095247</td>\n",
       "      <td>0.095711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.377844</td>\n",
       "      <td>0.486061</td>\n",
       "      <td>0.488569</td>\n",
       "      <td>0.484298</td>\n",
       "      <td>0.406824</td>\n",
       "      <td>0.492653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.388312</td>\n",
       "      <td>0.508553</td>\n",
       "      <td>0.539899</td>\n",
       "      <td>0.505739</td>\n",
       "      <td>0.420533</td>\n",
       "      <td>0.502602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.411963</td>\n",
       "      <td>0.535409</td>\n",
       "      <td>0.591876</td>\n",
       "      <td>0.521076</td>\n",
       "      <td>0.432317</td>\n",
       "      <td>0.517067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aX             aY             aZ             gX  \\\n",
       "count  192500.000000  192500.000000  192500.000000  192500.000000   \n",
       "mean        0.400953       0.508082       0.541712       0.499318   \n",
       "std         0.074306       0.068467       0.085276       0.096042   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.377844       0.486061       0.488569       0.484298   \n",
       "50%         0.388312       0.508553       0.539899       0.505739   \n",
       "75%         0.411963       0.535409       0.591876       0.521076   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  gY             gZ  \n",
       "count  192500.000000  192500.000000  \n",
       "mean        0.427822       0.502331  \n",
       "std         0.095247       0.095711  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.406824       0.492653  \n",
       "50%         0.420533       0.502602  \n",
       "75%         0.432317       0.517067  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata = fulldata.iloc[0:,0:6]\n",
    "normaldata = (fulldata - fulldata.min()) / (fulldata.max()-fulldata.min())\n",
    "normaldata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save maximum and minimum values for use in the prediction model on the PocketBeagle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = np.array(fulldata.min(), dtype='float32')\n",
    "maxval = np.array(fulldata.max(), dtype='float32')\n",
    "\n",
    "parameters_full = pd.DataFrame([minval, maxval], columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "parameters_full.to_csv('parameters_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data into numpy array for use with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36514839, 0.40900282, 0.53687994, ..., 0.49930897, 0.43952637,\n",
       "        0.49567407],\n",
       "       [0.36826123, 0.55677119, 0.61452193, ..., 0.50932893, 0.42393172,\n",
       "        0.49123369],\n",
       "       [0.37146563, 0.4280766 , 0.58713156, ..., 0.50639205, 0.42553788,\n",
       "        0.49358358],\n",
       "       ...,\n",
       "       [0.3648127 , 0.37119097, 0.40265996, ..., 0.50357033, 0.42159719,\n",
       "        0.49990082],\n",
       "       [0.38944076, 0.36267643, 0.41401869, ..., 0.50669917, 0.41905722,\n",
       "        0.51453422],\n",
       "       [0.37061112, 0.37793545, 0.42573688, ..., 0.50518274, 0.41803003,\n",
       "        0.50209812]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatdata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*350 + (i-1) * 350\n",
    "        #print(index, index+250)\n",
    "        dataf = normaldata.iloc[index:index+350].to_numpy().flatten().tolist()\n",
    "        formatdata[idx*num_samples+i-1] = dataf\n",
    "        del dataf\n",
    "        \n",
    "        \n",
    "formatdata = formatdata.transpose().to_numpy()\n",
    "formatdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelet Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save parameters from wavelet transformed data for use in PocketBeagle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = np.array(fullwavedata.min(), dtype='float32')\n",
    "maxval = np.array(fullwavedata.max(), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pd.DataFrame([minval, maxval], columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'], index=['min','max'])\n",
    "parameters.to_csv('dataparameters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Wavelet Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX_A1</th>\n",
       "      <th>aX_D1</th>\n",
       "      <th>aY_A1</th>\n",
       "      <th>aY_D1</th>\n",
       "      <th>aZ_A1</th>\n",
       "      <th>aZ_D1</th>\n",
       "      <th>gX_A1</th>\n",
       "      <th>gX_D1</th>\n",
       "      <th>gY_A1</th>\n",
       "      <th>gY_D1</th>\n",
       "      <th>...</th>\n",
       "      <th>aY_A2</th>\n",
       "      <th>aY_D2</th>\n",
       "      <th>aZ_A2</th>\n",
       "      <th>aZ_D2</th>\n",
       "      <th>gX_A2</th>\n",
       "      <th>gX_D2</th>\n",
       "      <th>gY_A2</th>\n",
       "      <th>gY_D2</th>\n",
       "      <th>gZ_A2</th>\n",
       "      <th>gZ_D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.335526</td>\n",
       "      <td>0.611492</td>\n",
       "      <td>0.432839</td>\n",
       "      <td>0.449727</td>\n",
       "      <td>0.558324</td>\n",
       "      <td>0.521365</td>\n",
       "      <td>0.500183</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.410186</td>\n",
       "      <td>0.521206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432839</td>\n",
       "      <td>0.449727</td>\n",
       "      <td>0.558324</td>\n",
       "      <td>0.521365</td>\n",
       "      <td>0.500183</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.410186</td>\n",
       "      <td>0.521206</td>\n",
       "      <td>0.502551</td>\n",
       "      <td>0.583230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.080657</td>\n",
       "      <td>0.031527</td>\n",
       "      <td>0.083774</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.097088</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.102759</td>\n",
       "      <td>0.048254</td>\n",
       "      <td>0.099510</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083774</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.097088</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.102759</td>\n",
       "      <td>0.048254</td>\n",
       "      <td>0.099510</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>0.090144</td>\n",
       "      <td>0.035227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.311361</td>\n",
       "      <td>0.608447</td>\n",
       "      <td>0.403568</td>\n",
       "      <td>0.446310</td>\n",
       "      <td>0.494259</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.482615</td>\n",
       "      <td>0.515702</td>\n",
       "      <td>0.388433</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403568</td>\n",
       "      <td>0.446310</td>\n",
       "      <td>0.494259</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.482615</td>\n",
       "      <td>0.515702</td>\n",
       "      <td>0.388433</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>0.492884</td>\n",
       "      <td>0.579189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.322813</td>\n",
       "      <td>0.611240</td>\n",
       "      <td>0.435093</td>\n",
       "      <td>0.449777</td>\n",
       "      <td>0.557355</td>\n",
       "      <td>0.521536</td>\n",
       "      <td>0.506969</td>\n",
       "      <td>0.519877</td>\n",
       "      <td>0.404442</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435093</td>\n",
       "      <td>0.449777</td>\n",
       "      <td>0.557355</td>\n",
       "      <td>0.521536</td>\n",
       "      <td>0.506969</td>\n",
       "      <td>0.519877</td>\n",
       "      <td>0.404442</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.502341</td>\n",
       "      <td>0.582993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.347766</td>\n",
       "      <td>0.613706</td>\n",
       "      <td>0.470832</td>\n",
       "      <td>0.453207</td>\n",
       "      <td>0.617096</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.523956</td>\n",
       "      <td>0.524138</td>\n",
       "      <td>0.415941</td>\n",
       "      <td>0.525350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470832</td>\n",
       "      <td>0.453207</td>\n",
       "      <td>0.617096</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.523956</td>\n",
       "      <td>0.524138</td>\n",
       "      <td>0.415941</td>\n",
       "      <td>0.525350</td>\n",
       "      <td>0.515112</td>\n",
       "      <td>0.586998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              aX_A1         aX_D1         aY_A1         aY_D1         aZ_A1  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.335526      0.611492      0.432839      0.449727      0.558324   \n",
       "std        0.080657      0.031527      0.083774      0.033548      0.097088   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.311361      0.608447      0.403568      0.446310      0.494259   \n",
       "50%        0.322813      0.611240      0.435093      0.449777      0.557355   \n",
       "75%        0.347766      0.613706      0.470832      0.453207      0.617096   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              aZ_D1         gX_A1         gX_D1         gY_A1         gY_D1  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.521365      0.500183      0.519830      0.410186      0.521206   \n",
       "std        0.042426      0.102759      0.048254      0.099510      0.040963   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.515400      0.482615      0.515702      0.388433      0.517965   \n",
       "50%        0.521536      0.506969      0.519877      0.404442      0.521259   \n",
       "75%        0.527778      0.523956      0.524138      0.415941      0.525350   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...         aY_A2         aY_D2         aZ_A2         aZ_D2  \\\n",
       "count  ...  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean   ...      0.432839      0.449727      0.558324      0.521365   \n",
       "std    ...      0.083774      0.033548      0.097088      0.042426   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.403568      0.446310      0.494259      0.515400   \n",
       "50%    ...      0.435093      0.449777      0.557355      0.521536   \n",
       "75%    ...      0.470832      0.453207      0.617096      0.527778   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gX_A2         gX_D2         gY_A2         gY_D2         gZ_A2  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.500183      0.519830      0.410186      0.521206      0.502551   \n",
       "std        0.102759      0.048254      0.099510      0.040963      0.090144   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.482615      0.515702      0.388433      0.517965      0.492884   \n",
       "50%        0.506969      0.519877      0.404442      0.521259      0.502341   \n",
       "75%        0.523956      0.524138      0.415941      0.525350      0.515112   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gZ_D2  \n",
       "count  26400.000000  \n",
       "mean       0.583230  \n",
       "std        0.035227  \n",
       "min        0.000000  \n",
       "25%        0.579189  \n",
       "50%        0.582993  \n",
       "75%        0.586998  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalwavedata = (fullwavedata - fullwavedata.min()) / (fullwavedata.max()-fullwavedata.min())\n",
    "normalwavedata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data into numpy array for use with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29540231, 0.61156848, 0.27991591, ..., 0.5188936 , 0.4929458 ,\n",
       "        0.58779549],\n",
       "       [0.29813013, 0.61073137, 0.50787481, ..., 0.52143732, 0.49012884,\n",
       "        0.58391459],\n",
       "       [0.30318832, 0.61109519, 0.3142718 , ..., 0.52195295, 0.49385348,\n",
       "        0.58364604],\n",
       "       ...,\n",
       "       [0.31135546, 0.61839787, 0.23596859, ..., 0.51909722, 0.50125362,\n",
       "        0.58275752],\n",
       "       [0.39471096, 0.63080849, 0.24139908, ..., 0.52259185, 0.51834611,\n",
       "        0.58284503],\n",
       "       [0.30184074, 0.61630349, 0.20849859, ..., 0.52138206, 0.5016146 ,\n",
       "        0.58184442]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*wavelen + (i-1) * wavelen\n",
    "        wavedataf = normalwavedata.iloc[index:index+wavelen].to_numpy().flatten().tolist()\n",
    "        formatwavedata[idx*num_samples+i-1] = wavedataf\n",
    "        del wavedataf\n",
    "        \n",
    "        \n",
    "formatwavedata = formatwavedata.transpose().to_numpy()\n",
    "formatwavedata \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training, test, and validation.\n",
    "Using StratifiedShuffleSplit to ensure even distribution of all the gestures in every dataset. (This is especially useful for small datasets such as this one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "1: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "2: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "3: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "4: Train 0.08854166666666667; Test 0.0963855421686747; Val 0.0963855421686747\n",
      "5: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "6: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "7: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "8: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "9: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15)\n",
    "valsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15/0.85)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatwavedata, labels):\n",
    "    X_train, X_test = formatwavedata[train_index], formatwavedata[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "for train_index, val_index in valsplit.split(X_train, y_train):\n",
    "    X_train, X_val = X_train[train_index], X_train[val_index]\n",
    "    y_train, y_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "for i in range(0,10):\n",
    "    print('{3}: Train {0}; Test {1}; Val {2}'.format(np.size(np.where(y_train == i)) / len(y_train), np.size(np.where(y_test == i)) / len(y_test), np.size(np.where(y_val == i)) / len(y_val), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.25)) #dropout layers help prevent overfitting\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model using optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "12/12 [==============================] - 3s 201ms/step - loss: 2.4504 - sparse_categorical_accuracy: 0.1068 - val_loss: 2.3693 - val_sparse_categorical_accuracy: 0.0964\n",
      "Epoch 2/600\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 2.4215 - sparse_categorical_accuracy: 0.1198 - val_loss: 2.3434 - val_sparse_categorical_accuracy: 0.2651\n",
      "Epoch 3/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 2.3961 - sparse_categorical_accuracy: 0.1224 - val_loss: 2.3037 - val_sparse_categorical_accuracy: 0.1687\n",
      "Epoch 4/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 2.3217 - sparse_categorical_accuracy: 0.1745 - val_loss: 2.2660 - val_sparse_categorical_accuracy: 0.3133\n",
      "Epoch 5/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 2.2861 - sparse_categorical_accuracy: 0.1875 - val_loss: 2.2267 - val_sparse_categorical_accuracy: 0.4699\n",
      "Epoch 6/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 2.2643 - sparse_categorical_accuracy: 0.2109 - val_loss: 2.1691 - val_sparse_categorical_accuracy: 0.6024\n",
      "Epoch 7/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 2.2220 - sparse_categorical_accuracy: 0.2812 - val_loss: 2.1115 - val_sparse_categorical_accuracy: 0.6145\n",
      "Epoch 8/600\n",
      "12/12 [==============================] - ETA: 0s - loss: 2.1650 - sparse_categorical_accuracy: 0.323 - 1s 45ms/step - loss: 2.1748 - sparse_categorical_accuracy: 0.3099 - val_loss: 2.0550 - val_sparse_categorical_accuracy: 0.5542\n",
      "Epoch 9/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 2.1474 - sparse_categorical_accuracy: 0.3073 - val_loss: 1.9895 - val_sparse_categorical_accuracy: 0.6265\n",
      "Epoch 10/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 2.0676 - sparse_categorical_accuracy: 0.3620 - val_loss: 1.9081 - val_sparse_categorical_accuracy: 0.6386\n",
      "Epoch 11/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.9826 - sparse_categorical_accuracy: 0.3854 - val_loss: 1.8118 - val_sparse_categorical_accuracy: 0.6506\n",
      "Epoch 12/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.8893 - sparse_categorical_accuracy: 0.4479 - val_loss: 1.6927 - val_sparse_categorical_accuracy: 0.7831\n",
      "Epoch 13/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.8143 - sparse_categorical_accuracy: 0.4661 - val_loss: 1.5907 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 14/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 1.7155 - sparse_categorical_accuracy: 0.4688 - val_loss: 1.5084 - val_sparse_categorical_accuracy: 0.6024\n",
      "Epoch 15/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 1.5535 - sparse_categorical_accuracy: 0.5859 - val_loss: 1.3948 - val_sparse_categorical_accuracy: 0.7590\n",
      "Epoch 16/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 1.4592 - sparse_categorical_accuracy: 0.6016 - val_loss: 1.3090 - val_sparse_categorical_accuracy: 0.7831\n",
      "Epoch 17/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.3779 - sparse_categorical_accuracy: 0.6328 - val_loss: 1.2283 - val_sparse_categorical_accuracy: 0.7229\n",
      "Epoch 18/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 1.3372 - sparse_categorical_accuracy: 0.6302 - val_loss: 1.1922 - val_sparse_categorical_accuracy: 0.7229\n",
      "Epoch 19/600\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 1.2280 - sparse_categorical_accuracy: 0.6953 - val_loss: 1.0631 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 20/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.1120 - sparse_categorical_accuracy: 0.7318 - val_loss: 1.0035 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 21/600\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 1.1107 - sparse_categorical_accuracy: 0.7135 - val_loss: 1.0028 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 22/600\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 1.0801 - sparse_categorical_accuracy: 0.6979 - val_loss: 0.9379 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 23/600\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.9222 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.8221 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 24/600\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.9058 - sparse_categorical_accuracy: 0.7786 - val_loss: 0.7850 - val_sparse_categorical_accuracy: 0.8193\n",
      "Epoch 25/600\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.7959 - sparse_categorical_accuracy: 0.8125 - val_loss: 0.7493 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 26/600\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.8030 - sparse_categorical_accuracy: 0.7891 - val_loss: 0.7384 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 27/600\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.7659 - sparse_categorical_accuracy: 0.8333 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 28/600\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.6711 - sparse_categorical_accuracy: 0.8385 - val_loss: 0.7281 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 29/600\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.6752 - sparse_categorical_accuracy: 0.8307 - val_loss: 0.5886 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 30/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.6404 - sparse_categorical_accuracy: 0.8568 - val_loss: 0.5711 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 31/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.6093 - sparse_categorical_accuracy: 0.8411 - val_loss: 0.5430 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 32/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.5532 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.5685 - val_sparse_categorical_accuracy: 0.8193\n",
      "Epoch 33/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.5191 - sparse_categorical_accuracy: 0.8698 - val_loss: 0.5027 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 34/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.5239 - sparse_categorical_accuracy: 0.8620 - val_loss: 0.5343 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 35/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.4899 - sparse_categorical_accuracy: 0.8802 - val_loss: 0.4446 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 36/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.4577 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.4416 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 37/600\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.4074 - sparse_categorical_accuracy: 0.9010 - val_loss: 0.4535 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 38/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.4266 - sparse_categorical_accuracy: 0.8906 - val_loss: 0.4783 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 39/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.4344 - sparse_categorical_accuracy: 0.8854 - val_loss: 0.4338 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 40/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.4149 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.3712 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 41/600\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.4857 - sparse_categorical_accuracy: 0.8594 - val_loss: 0.4349 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 42/600\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.4352 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.4252 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 43/600\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.4077 - sparse_categorical_accuracy: 0.8906 - val_loss: 0.5292 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 44/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.3384 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.5532 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 45/600\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.3733 - sparse_categorical_accuracy: 0.8854 - val_loss: 0.3430 - val_sparse_categorical_accuracy: 0.9157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.3092 - sparse_categorical_accuracy: 0.9141 - val_loss: 0.3506 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 47/600\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.2831 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.3133 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 48/600\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.2758 - sparse_categorical_accuracy: 0.9271 - val_loss: 0.3163 - val_sparse_categorical_accuracy: 0.9398A: 0s - loss: 0.2159 - sparse_categorical_accuracy:\n",
      "Epoch 49/600\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.2837 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.3096 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 50/600\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.2559 - sparse_categorical_accuracy: 0.9349 - val_loss: 0.3190 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 51/600\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.2524 - sparse_categorical_accuracy: 0.9349 - val_loss: 0.2561 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 52/600\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.2481 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.2996 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 53/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.1930 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.2903 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 54/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.2206 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2791 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 55/600\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.2092 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2814 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 56/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.2377 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.2663 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 57/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.2138 - sparse_categorical_accuracy: 0.9505 - val_loss: 0.3226 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 58/600\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.2348 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.2456 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 59/600\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.1988 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.3053 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 60/600\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.1939 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.2787 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 61/600\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.2348 - sparse_categorical_accuracy: 0.9323 - val_loss: 0.2201 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 62/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.1858 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2881 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 63/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.1818 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.2480 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 64/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.1614 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2149 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 65/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1679 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.1889 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 66/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.1665 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.2615 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 67/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1572 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2338 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 68/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.1634 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2603 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 69/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1809 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2709 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 70/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.1367 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.1922 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 71/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.1267 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2430 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 72/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.1308 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.2080 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 73/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.1634 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2048 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 74/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.1435 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.2079 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 75/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.1381 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2315 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 76/600\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2453 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 77/600\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.1451 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.2216 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 78/600\n",
      "12/12 [==============================] - 1s 95ms/step - loss: 0.1298 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2046 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 79/600\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.1293 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.1748 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 80/600\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.1426 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2110 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 81/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.1611 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2415 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 82/600\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.1404 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2371 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 83/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.1138 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1577 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 84/600\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.1212 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1895 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 85/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.1028 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2571 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 86/600\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.1068 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2044 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 87/600\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.1121 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.2003 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 88/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.1144 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.2386 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 89/600\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0840 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.2166 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 90/600\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.1046 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2969 - val_sparse_categorical_accuracy: 0.9398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.1300 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.1978 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 92/600\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0996 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.1801 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 93/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1265 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2287 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 94/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.1057 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.1881 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 95/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.1072 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1608 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 96/600\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.1085 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2189 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 97/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0772 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1909 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 98/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0822 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1965 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 99/600\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0936 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1872 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 100/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.2615 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 101/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0932 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2095 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 102/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0676 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1719 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 103/600\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0652 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.1498 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 104/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0723 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2289 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 105/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0803 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2866 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 106/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0833 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2276 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 107/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0766 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1795 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 108/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0632 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1618 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 109/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0725 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1835 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 110/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.2462 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 111/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1976 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 112/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0654 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1671 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 113/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0653 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2103 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 114/600\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1379 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 115/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2147 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 116/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0597 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.2313 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 117/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.2405 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 118/600\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0631 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.1874 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 119/600\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0560 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.1805 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 120/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0685 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1975 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 121/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1617 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 122/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0607 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2245 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 123/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0409 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1670 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 124/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1627 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 125/600\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0739 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.1920 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 126/600\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.3236 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 127/600\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1597 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 128/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0626 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.1779 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 129/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2334 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 130/600\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0414 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.1837 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 131/600\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.0630 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2770 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 132/600\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0674 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1991 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 133/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0791 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2591 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 134/600\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0694 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1597 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 135/600\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.0618 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1644 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 136/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0680 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1924 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 137/600\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0452 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.2109 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 138/600\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.0452 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.2018 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 139/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0482 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2653 - val_sparse_categorical_accuracy: 0.9518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b6cb4094c0>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "\n",
    ")\n",
    "model.fit(X_train, y_train, \n",
    "            epochs=600,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stopping],\n",
    "            validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1b6c969cb20>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model for TensorFlowLite on PocketBeagle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "data (Dense)                 (None, 1024)              1180672   \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "result (Dense)               (None, 11)                11275     \n",
      "=================================================================\n",
      "Total params: 3,291,147\n",
      "Trainable params: 3,291,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert TF model to TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmpe0py4zwf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmpe0py4zwf\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('test_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify TensorFlowLite model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'data_input', 'index': 0, 'shape': array([   1, 1152]), 'shape_signature': array([  -1, 1152]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='test_model.tflite')\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(input_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_size = X_test[0].size\n",
    "testing_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27108055, 0.60922673, 0.45772752, ..., 0.52093402, 0.48902781,\n",
       "       0.58226719])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.033 0.94  0.009 0.    0.    0.    0.018 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.998 0.    0.    0.    0.001 0.    0.   ]\n",
      " [0.    0.011 0.987 0.001 0.    0.    0.    0.001 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.977 0.012 0.    0.002 0.009 0.   ]\n",
      " [0.    0.999 0.001 0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.001 0.    0.    0.    0.004 0.    0.958 0.    0.016 0.021 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.999 0.    0.    0.001 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
      " [0.    0.    0.005 0.995 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.999 0.   ]\n",
      " [0.    0.    0.    0.    0.001 0.885 0.05  0.    0.004 0.059 0.   ]\n",
      " [0.    0.173 0.004 0.01  0.001 0.001 0.    0.716 0.012 0.083 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   ]\n",
      " [0.002 0.    0.    0.009 0.956 0.    0.008 0.    0.024 0.    0.   ]\n",
      " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.999 0.    0.    0.    0.    0.    0.   ]\n",
      " [0.001 0.    0.992 0.007 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.998 0.001 0.    0.    0.    0.    0.001 0.    0.    0.   ]\n",
      " [0.002 0.001 0.993 0.004 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.999 0.    0.    0.    0.    0.    0.    0.    0.001 0.   ]\n",
      " [0.927 0.    0.072 0.001 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.001 0.022 0.976 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.001 0.    0.    0.    0.99  0.001 0.002 0.001 0.005 0.001]\n",
      " [0.    0.022 0.96  0.001 0.    0.    0.    0.017 0.    0.    0.   ]\n",
      " [0.991 0.    0.    0.    0.    0.    0.009 0.    0.    0.    0.   ]\n",
      " [0.    0.002 0.    0.    0.    0.    0.    0.993 0.    0.005 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   ]\n",
      " [0.013 0.    0.    0.    0.    0.    0.986 0.    0.    0.    0.   ]\n",
      " [0.    0.98  0.003 0.001 0.008 0.    0.001 0.001 0.001 0.005 0.   ]\n",
      " [0.    0.989 0.002 0.001 0.002 0.    0.    0.002 0.    0.004 0.   ]\n",
      " [0.    0.001 0.    0.    0.    0.033 0.642 0.    0.002 0.322 0.   ]]\n",
      "[ 2  4  2  5  1  6  6  8  3  0  9  5  7  9  4  0  4  2  1  2  1  0  3  5\n",
      "  2  0  7 10  6  1  1  5  3 10  6  8  7  7  2  8  9  5  3 10  7  6  9  3\n",
      "  9 10  4  9  8  0  4  6  2 10  0  7  0  6  8  7  1  1 10  2 10  6  4  9\n",
      "  3  5  4  8  3  8  0  4  3  5  5]\n"
     ]
    }
   ],
   "source": [
    "#Sometimes behaves weird if no resizing of array \n",
    "input_data = np.float32(np.resize(X_test[0], (1, testing_size)))\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(np.round(output_data, decimals=3))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 1 but expected 32 for dimension 0 of input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-ed01d186557a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m113\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36mset_tensor\u001b[1;34m(self, tensor_index, value)\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0mcould\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mset\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \"\"\"\n\u001b[1;32m--> 607\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSetTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mresize_tensor_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 1 but expected 32 for dimension 0 of input 0."
     ]
    }
   ],
   "source": [
    "for i in range(0, 113):\n",
    "    input_data = np.float32(np.resize(X_test[i], (1, testing_size)))\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lbl = np.argmax(output, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, output_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 2.4458 - sparse_categorical_accuracy: 0.0795 - val_loss: 2.3590 - val_sparse_categorical_accuracy: 0.1566\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 2.4176 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3129 - val_sparse_categorical_accuracy: 0.2530\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 2.3705 - sparse_categorical_accuracy: 0.1250 - val_loss: 2.2712 - val_sparse_categorical_accuracy: 0.2169\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 2.3019 - sparse_categorical_accuracy: 0.1955 - val_loss: 2.2228 - val_sparse_categorical_accuracy: 0.5301\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 2.2629 - sparse_categorical_accuracy: 0.2068 - val_loss: 2.1623 - val_sparse_categorical_accuracy: 0.4217\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 2.2068 - sparse_categorical_accuracy: 0.2455 - val_loss: 2.0974 - val_sparse_categorical_accuracy: 0.4940\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 2.1516 - sparse_categorical_accuracy: 0.3023 - val_loss: 2.0387 - val_sparse_categorical_accuracy: 0.5301\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 2.0687 - sparse_categorical_accuracy: 0.3886 - val_loss: 1.9132 - val_sparse_categorical_accuracy: 0.7349\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0039 - sparse_categorical_accuracy: 0.3955 - val_loss: 1.8043 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 1.8828 - sparse_categorical_accuracy: 0.4091 - val_loss: 1.7587 - val_sparse_categorical_accuracy: 0.7349\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 1.8070 - sparse_categorical_accuracy: 0.4568 - val_loss: 1.6525 - val_sparse_categorical_accuracy: 0.6145\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 1.6915 - sparse_categorical_accuracy: 0.5114 - val_loss: 1.5277 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 1.5634 - sparse_categorical_accuracy: 0.5250 - val_loss: 1.3735 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 1s 67ms/step - loss: 1.4874 - sparse_categorical_accuracy: 0.5773 - val_loss: 1.2980 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 1.4223 - sparse_categorical_accuracy: 0.6091 - val_loss: 1.1791 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 1.2809 - sparse_categorical_accuracy: 0.6318 - val_loss: 1.0970 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 1.1825 - sparse_categorical_accuracy: 0.6955 - val_loss: 1.0486 - val_sparse_categorical_accuracy: 0.7590\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 1.1564 - sparse_categorical_accuracy: 0.6545 - val_loss: 0.9304 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0487 - sparse_categorical_accuracy: 0.729 - 1s 50ms/step - loss: 1.0487 - sparse_categorical_accuracy: 0.7295 - val_loss: 0.9138 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.9457 - sparse_categorical_accuracy: 0.7591 - val_loss: 0.8406 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.9373 - sparse_categorical_accuracy: 0.7477 - val_loss: 0.8491 - val_sparse_categorical_accuracy: 0.7711\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.8945 - sparse_categorical_accuracy: 0.7545 - val_loss: 0.7272 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.8348 - sparse_categorical_accuracy: 0.7659 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.7271 - sparse_categorical_accuracy: 0.8273 - val_loss: 0.6113 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.6630 - sparse_categorical_accuracy: 0.8568 - val_loss: 0.5575 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.6591 - sparse_categorical_accuracy: 0.8273 - val_loss: 0.5505 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.6003 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.6052 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.5528 - sparse_categorical_accuracy: 0.8523 - val_loss: 0.5175 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.5417 - sparse_categorical_accuracy: 0.8636 - val_loss: 0.4196 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4759 - sparse_categorical_accuracy: 0.868 - 1s 50ms/step - loss: 0.4759 - sparse_categorical_accuracy: 0.8682 - val_loss: 0.4242 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4827 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.3938 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.4883 - sparse_categorical_accuracy: 0.8636 - val_loss: 0.3634 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.4627 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.4196 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.4475 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.3292 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.4221 - sparse_categorical_accuracy: 0.8955 - val_loss: 0.3494 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.4023 - sparse_categorical_accuracy: 0.8977 - val_loss: 0.3679 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.3778 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.3279 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.3443 - sparse_categorical_accuracy: 0.9273 - val_loss: 0.2607 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3401 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.3762 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.3317 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.2691 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2889 - sparse_categorical_accuracy: 0.9205 - val_loss: 0.2566 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.2780 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.2575 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2974 - sparse_categorical_accuracy: 0.9227 - val_loss: 0.2201 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2759 - sparse_categorical_accuracy: 0.9318 - val_loss: 0.2791 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.2594 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.1987 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.2676 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.2563 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2169 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.2807 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.2517 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.2312 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2715 - sparse_categorical_accuracy: 0.9273 - val_loss: 0.2528 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2183 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.3040 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2276 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.1877 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.1938 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.2080 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1751 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.1507 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1746 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.2071 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.1634 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1791 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1458 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1761 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.1486 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1690 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.1474 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.2115 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1804 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.2194 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.1320 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1615 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1609 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1999 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1207 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1760 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1390 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.2835 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1582 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.2116 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1514 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1222 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1330 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.2075 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1211 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1218 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1115 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.2242 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1368 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1652 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1156 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1296 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1381 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.2110 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.2830 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1620 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.1454 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1521 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.2670 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1288 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1237 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.1153 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1532 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0882 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1309 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1414 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1459 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1070 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1124 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1734 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1235 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.1432 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 83/600\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1010 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1630 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0784 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1402 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1624 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.1955 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0846 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1586 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 90/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1088 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 91/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0810 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1226 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0738 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1637 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0721 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.1793 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1310 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1792 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.1711 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0904 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.2363 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1647 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0612 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.2379 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0767 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.2193 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0771 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1144 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1286 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1513 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0542 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1757 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1896 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1032 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.2318 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1086 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1547 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0888 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1170 - val_sparse_categorical_accuracy: 0.9759\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmp4uk4i7m8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmp4uk4i7m8\\assets\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatwavedata, labels):\n",
    "    X_train, X_test = formatwavedata[train_index], formatwavedata[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('hand_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_val, y_val)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_val)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_val\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
