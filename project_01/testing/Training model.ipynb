{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Gesture Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules and define wavelet function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "def wavelet(data, level, wavelet):\n",
    "    (cA, cD) = pywt.dwt(data, wavelet=wavelet)\n",
    "    for i in range(1, level):\n",
    "        (cA, cD) = pywt.dwt(cA, wavelet=wavelet)\n",
    "    return cA, cD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and perform wavelet transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gestures = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10\n",
    "]\n",
    "num_samples = 50\n",
    "num_gestures = len(gestures)\n",
    "\n",
    "fulldata = pd.DataFrame(columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "fullwavedata = pd.DataFrame(columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'])\n",
    "formatdata = pd.DataFrame()\n",
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "labels = []\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        filepath = 'hand/hand_{0}_{1}.csv'.format(gesture, i)\n",
    "        data = pd.read_csv(filepath, index_col=False)\n",
    "        wavedata = pd.DataFrame()\n",
    "        \n",
    "        level1 = 3\n",
    "        wavetype1 = 'rbio2.2'\n",
    "        #Start creating the dataframe with transformed data\n",
    "        wavedata['aX_A1'], wavedata['aX_D1'] = wavelet(data['aX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aY_A1'], wavedata['aY_D1'] = wavelet(data['aY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aZ_A1'], wavedata['aZ_D1'] = wavelet(data['aZ'], level=level1, wavelet=wavetype1)\n",
    "\n",
    "        wavedata['gX_A1'], wavedata['gX_D1'] = wavelet(data['gX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gY_A1'], wavedata['gY_D1'] = wavelet(data['gY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gZ_A1'], wavedata['gZ_D1'] = wavelet(data['gZ'], level=level1, wavelet=wavetype1)\n",
    "        \n",
    "        level2 = 3\n",
    "        wavetype2 = 'rbio2.2'\n",
    "\n",
    "        wavedata['aX_A2'], wavedata['aX_D2'] = wavelet(data['aX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aY_A2'], wavedata['aY_D2'] = wavelet(data['aY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aZ_A2'], wavedata['aZ_D2'] = wavelet(data['aZ'], level=level2, wavelet=wavetype2)\n",
    "\n",
    "        wavedata['gX_A2'], wavedata['gX_D2'] = wavelet(data['gX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gY_A2'], wavedata['gY_D2'] = wavelet(data['gY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gZ_A2'], wavedata['gZ_D2'] = wavelet(data['gZ'], level=level2, wavelet=wavetype2)\n",
    "        \n",
    "        wavelen = len(wavedata)\n",
    "        \n",
    "        #create a full dataframe with all the data\n",
    "        fullwavedata = fullwavedata.append(wavedata)\n",
    "        fulldata = fulldata.append(data)\n",
    "        label = gesture\n",
    "        labels.append(label)\n",
    "        del data, wavedata\n",
    "\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX</th>\n",
       "      <th>aY</th>\n",
       "      <th>aZ</th>\n",
       "      <th>gX</th>\n",
       "      <th>gY</th>\n",
       "      <th>gZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.400953</td>\n",
       "      <td>0.508082</td>\n",
       "      <td>0.541712</td>\n",
       "      <td>0.499318</td>\n",
       "      <td>0.427822</td>\n",
       "      <td>0.502331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.074306</td>\n",
       "      <td>0.068467</td>\n",
       "      <td>0.085276</td>\n",
       "      <td>0.096042</td>\n",
       "      <td>0.095247</td>\n",
       "      <td>0.095711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.377844</td>\n",
       "      <td>0.486061</td>\n",
       "      <td>0.488569</td>\n",
       "      <td>0.484298</td>\n",
       "      <td>0.406824</td>\n",
       "      <td>0.492653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.388312</td>\n",
       "      <td>0.508553</td>\n",
       "      <td>0.539899</td>\n",
       "      <td>0.505739</td>\n",
       "      <td>0.420533</td>\n",
       "      <td>0.502602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.411963</td>\n",
       "      <td>0.535409</td>\n",
       "      <td>0.591876</td>\n",
       "      <td>0.521076</td>\n",
       "      <td>0.432317</td>\n",
       "      <td>0.517067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aX             aY             aZ             gX  \\\n",
       "count  192500.000000  192500.000000  192500.000000  192500.000000   \n",
       "mean        0.400953       0.508082       0.541712       0.499318   \n",
       "std         0.074306       0.068467       0.085276       0.096042   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.377844       0.486061       0.488569       0.484298   \n",
       "50%         0.388312       0.508553       0.539899       0.505739   \n",
       "75%         0.411963       0.535409       0.591876       0.521076   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  gY             gZ  \n",
       "count  192500.000000  192500.000000  \n",
       "mean        0.427822       0.502331  \n",
       "std         0.095247       0.095711  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.406824       0.492653  \n",
       "50%         0.420533       0.502602  \n",
       "75%         0.432317       0.517067  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata = fulldata.iloc[0:,0:6]\n",
    "normaldata = (fulldata - fulldata.min()) / (fulldata.max()-fulldata.min())\n",
    "normaldata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save maximum and minimum values for use in the prediction model on the PocketBeagle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = np.array(fulldata.min(), dtype='float32')\n",
    "maxval = np.array(fulldata.max(), dtype='float32')\n",
    "\n",
    "parameters_full = pd.DataFrame([minval, maxval], columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "parameters_full.to_csv('parameters_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data into numpy array for use with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36514839, 0.40900282, 0.53687994, ..., 0.49930897, 0.43952637,\n",
       "        0.49567407],\n",
       "       [0.36826123, 0.55677119, 0.61452193, ..., 0.50932893, 0.42393172,\n",
       "        0.49123369],\n",
       "       [0.37146563, 0.4280766 , 0.58713156, ..., 0.50639205, 0.42553788,\n",
       "        0.49358358],\n",
       "       ...,\n",
       "       [0.3648127 , 0.37119097, 0.40265996, ..., 0.50357033, 0.42159719,\n",
       "        0.49990082],\n",
       "       [0.38944076, 0.36267643, 0.41401869, ..., 0.50669917, 0.41905722,\n",
       "        0.51453422],\n",
       "       [0.37061112, 0.37793545, 0.42573688, ..., 0.50518274, 0.41803003,\n",
       "        0.50209812]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatdata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*350 + (i-1) * 350\n",
    "        #print(index, index+250)\n",
    "        dataf = normaldata.iloc[index:index+350].to_numpy().flatten().tolist()\n",
    "        formatdata[idx*num_samples+i-1] = dataf\n",
    "        del dataf\n",
    "        \n",
    "        \n",
    "formatdata = formatdata.transpose().to_numpy()\n",
    "formatdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelet Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save parameters from wavelet transformed data for use in PocketBeagle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = np.array(fullwavedata.min(), dtype='float32')\n",
    "maxval = np.array(fullwavedata.max(), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pd.DataFrame([minval, maxval], columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'], index=['min','max'])\n",
    "parameters.to_csv('dataparameters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Wavelet Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX_A1</th>\n",
       "      <th>aX_D1</th>\n",
       "      <th>aY_A1</th>\n",
       "      <th>aY_D1</th>\n",
       "      <th>aZ_A1</th>\n",
       "      <th>aZ_D1</th>\n",
       "      <th>gX_A1</th>\n",
       "      <th>gX_D1</th>\n",
       "      <th>gY_A1</th>\n",
       "      <th>gY_D1</th>\n",
       "      <th>...</th>\n",
       "      <th>aY_A2</th>\n",
       "      <th>aY_D2</th>\n",
       "      <th>aZ_A2</th>\n",
       "      <th>aZ_D2</th>\n",
       "      <th>gX_A2</th>\n",
       "      <th>gX_D2</th>\n",
       "      <th>gY_A2</th>\n",
       "      <th>gY_D2</th>\n",
       "      <th>gZ_A2</th>\n",
       "      <th>gZ_D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.335526</td>\n",
       "      <td>0.611492</td>\n",
       "      <td>0.432839</td>\n",
       "      <td>0.449727</td>\n",
       "      <td>0.558324</td>\n",
       "      <td>0.521365</td>\n",
       "      <td>0.500183</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.410186</td>\n",
       "      <td>0.521206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432839</td>\n",
       "      <td>0.449727</td>\n",
       "      <td>0.558324</td>\n",
       "      <td>0.521365</td>\n",
       "      <td>0.500183</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.410186</td>\n",
       "      <td>0.521206</td>\n",
       "      <td>0.502551</td>\n",
       "      <td>0.583230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.080657</td>\n",
       "      <td>0.031527</td>\n",
       "      <td>0.083774</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.097088</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.102759</td>\n",
       "      <td>0.048254</td>\n",
       "      <td>0.099510</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083774</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.097088</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.102759</td>\n",
       "      <td>0.048254</td>\n",
       "      <td>0.099510</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>0.090144</td>\n",
       "      <td>0.035227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.311361</td>\n",
       "      <td>0.608447</td>\n",
       "      <td>0.403568</td>\n",
       "      <td>0.446310</td>\n",
       "      <td>0.494259</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.482615</td>\n",
       "      <td>0.515702</td>\n",
       "      <td>0.388433</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403568</td>\n",
       "      <td>0.446310</td>\n",
       "      <td>0.494259</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.482615</td>\n",
       "      <td>0.515702</td>\n",
       "      <td>0.388433</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>0.492884</td>\n",
       "      <td>0.579189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.322813</td>\n",
       "      <td>0.611240</td>\n",
       "      <td>0.435093</td>\n",
       "      <td>0.449777</td>\n",
       "      <td>0.557355</td>\n",
       "      <td>0.521536</td>\n",
       "      <td>0.506969</td>\n",
       "      <td>0.519877</td>\n",
       "      <td>0.404442</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435093</td>\n",
       "      <td>0.449777</td>\n",
       "      <td>0.557355</td>\n",
       "      <td>0.521536</td>\n",
       "      <td>0.506969</td>\n",
       "      <td>0.519877</td>\n",
       "      <td>0.404442</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.502341</td>\n",
       "      <td>0.582993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.347766</td>\n",
       "      <td>0.613706</td>\n",
       "      <td>0.470832</td>\n",
       "      <td>0.453207</td>\n",
       "      <td>0.617096</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.523956</td>\n",
       "      <td>0.524138</td>\n",
       "      <td>0.415941</td>\n",
       "      <td>0.525350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470832</td>\n",
       "      <td>0.453207</td>\n",
       "      <td>0.617096</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.523956</td>\n",
       "      <td>0.524138</td>\n",
       "      <td>0.415941</td>\n",
       "      <td>0.525350</td>\n",
       "      <td>0.515112</td>\n",
       "      <td>0.586998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              aX_A1         aX_D1         aY_A1         aY_D1         aZ_A1  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.335526      0.611492      0.432839      0.449727      0.558324   \n",
       "std        0.080657      0.031527      0.083774      0.033548      0.097088   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.311361      0.608447      0.403568      0.446310      0.494259   \n",
       "50%        0.322813      0.611240      0.435093      0.449777      0.557355   \n",
       "75%        0.347766      0.613706      0.470832      0.453207      0.617096   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              aZ_D1         gX_A1         gX_D1         gY_A1         gY_D1  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.521365      0.500183      0.519830      0.410186      0.521206   \n",
       "std        0.042426      0.102759      0.048254      0.099510      0.040963   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.515400      0.482615      0.515702      0.388433      0.517965   \n",
       "50%        0.521536      0.506969      0.519877      0.404442      0.521259   \n",
       "75%        0.527778      0.523956      0.524138      0.415941      0.525350   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...         aY_A2         aY_D2         aZ_A2         aZ_D2  \\\n",
       "count  ...  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean   ...      0.432839      0.449727      0.558324      0.521365   \n",
       "std    ...      0.083774      0.033548      0.097088      0.042426   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.403568      0.446310      0.494259      0.515400   \n",
       "50%    ...      0.435093      0.449777      0.557355      0.521536   \n",
       "75%    ...      0.470832      0.453207      0.617096      0.527778   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gX_A2         gX_D2         gY_A2         gY_D2         gZ_A2  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.500183      0.519830      0.410186      0.521206      0.502551   \n",
       "std        0.102759      0.048254      0.099510      0.040963      0.090144   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.482615      0.515702      0.388433      0.517965      0.492884   \n",
       "50%        0.506969      0.519877      0.404442      0.521259      0.502341   \n",
       "75%        0.523956      0.524138      0.415941      0.525350      0.515112   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gZ_D2  \n",
       "count  26400.000000  \n",
       "mean       0.583230  \n",
       "std        0.035227  \n",
       "min        0.000000  \n",
       "25%        0.579189  \n",
       "50%        0.582993  \n",
       "75%        0.586998  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalwavedata = (fullwavedata - fullwavedata.min()) / (fullwavedata.max()-fullwavedata.min())\n",
    "normalwavedata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data into numpy array for use with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29540231, 0.61156848, 0.27991591, ..., 0.5188936 , 0.4929458 ,\n",
       "        0.58779549],\n",
       "       [0.29813013, 0.61073137, 0.50787481, ..., 0.52143732, 0.49012884,\n",
       "        0.58391459],\n",
       "       [0.30318832, 0.61109519, 0.3142718 , ..., 0.52195295, 0.49385348,\n",
       "        0.58364604],\n",
       "       ...,\n",
       "       [0.31135546, 0.61839787, 0.23596859, ..., 0.51909722, 0.50125362,\n",
       "        0.58275752],\n",
       "       [0.39471096, 0.63080849, 0.24139908, ..., 0.52259185, 0.51834611,\n",
       "        0.58284503],\n",
       "       [0.30184074, 0.61630349, 0.20849859, ..., 0.52138206, 0.5016146 ,\n",
       "        0.58184442]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*wavelen + (i-1) * wavelen\n",
    "        wavedataf = normalwavedata.iloc[index:index+wavelen].to_numpy().flatten().tolist()\n",
    "        formatwavedata[idx*num_samples+i-1] = wavedataf\n",
    "        del wavedataf\n",
    "        \n",
    "        \n",
    "formatwavedata = formatwavedata.transpose().to_numpy()\n",
    "formatwavedata \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training, test, and validation.\n",
    "Using StratifiedShuffleSplit to ensure even distribution of all the gestures in every dataset. (This is especially useful for small datasets such as this one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "1: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "2: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "3: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "4: Train 0.08854166666666667; Test 0.0963855421686747; Val 0.0963855421686747\n",
      "5: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "6: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "7: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "8: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "9: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15)\n",
    "valsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15/0.85)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatwavedata, labels):\n",
    "    X_train, X_test = formatwavedata[train_index], formatwavedata[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "for train_index, val_index in valsplit.split(X_train, y_train):\n",
    "    X_train, X_val = X_train[train_index], X_train[val_index]\n",
    "    y_train, y_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "for i in range(0,10):\n",
    "    print('{3}: Train {0}; Test {1}; Val {2}'.format(np.size(np.where(y_train == i)) / len(y_train), np.size(np.where(y_test == i)) / len(y_test), np.size(np.where(y_val == i)) / len(y_val), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.25)) #dropout layers help prevent overfitting\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model using optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "12/12 [==============================] - 2s 96ms/step - loss: 2.4767 - sparse_categorical_accuracy: 0.1016 - val_loss: 2.3614 - val_sparse_categorical_accuracy: 0.1446\n",
      "Epoch 2/600\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 2.3743 - sparse_categorical_accuracy: 0.1224 - val_loss: 2.3352 - val_sparse_categorical_accuracy: 0.1687\n",
      "Epoch 3/600\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 2.3556 - sparse_categorical_accuracy: 0.1667 - val_loss: 2.2940 - val_sparse_categorical_accuracy: 0.3855\n",
      "Epoch 4/600\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 2.3288 - sparse_categorical_accuracy: 0.1719 - val_loss: 2.2659 - val_sparse_categorical_accuracy: 0.3614\n",
      "Epoch 5/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 2.3038 - sparse_categorical_accuracy: 0.1979 - val_loss: 2.2146 - val_sparse_categorical_accuracy: 0.5301\n",
      "Epoch 6/600\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 2.2645 - sparse_categorical_accuracy: 0.2318 - val_loss: 2.1606 - val_sparse_categorical_accuracy: 0.3253\n",
      "Epoch 7/600\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 2.2215 - sparse_categorical_accuracy: 0.2656 - val_loss: 2.1110 - val_sparse_categorical_accuracy: 0.6024\n",
      "Epoch 8/600\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 2.1542 - sparse_categorical_accuracy: 0.2891 - val_loss: 2.0339 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 9/600\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 2.1315 - sparse_categorical_accuracy: 0.3307 - val_loss: 1.9541 - val_sparse_categorical_accuracy: 0.6988\n",
      "Epoch 10/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 2.0367 - sparse_categorical_accuracy: 0.3776 - val_loss: 1.8731 - val_sparse_categorical_accuracy: 0.5904\n",
      "Epoch 11/600\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 1.9615 - sparse_categorical_accuracy: 0.4062 - val_loss: 1.7873 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 12/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 1.8726 - sparse_categorical_accuracy: 0.4089 - val_loss: 1.6363 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 13/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 1.7671 - sparse_categorical_accuracy: 0.4870 - val_loss: 1.5200 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 14/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 1.6970 - sparse_categorical_accuracy: 0.4922 - val_loss: 1.4333 - val_sparse_categorical_accuracy: 0.7590\n",
      "Epoch 15/600\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 1.5943 - sparse_categorical_accuracy: 0.5026 - val_loss: 1.3407 - val_sparse_categorical_accuracy: 0.7711\n",
      "Epoch 16/600\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 1.5010 - sparse_categorical_accuracy: 0.5755 - val_loss: 1.2069 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 17/600\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 1.3898 - sparse_categorical_accuracy: 0.6198 - val_loss: 1.1050 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 18/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 1.2771 - sparse_categorical_accuracy: 0.6641 - val_loss: 1.0278 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 19/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 1.2360 - sparse_categorical_accuracy: 0.6458 - val_loss: 0.9449 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 20/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 1.1381 - sparse_categorical_accuracy: 0.6875 - val_loss: 0.8599 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 21/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 1.0720 - sparse_categorical_accuracy: 0.7057 - val_loss: 0.8039 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 22/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 1.0081 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.7553 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 23/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.9322 - sparse_categorical_accuracy: 0.7682 - val_loss: 0.7134 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 24/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.9378 - sparse_categorical_accuracy: 0.7344 - val_loss: 0.7412 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 25/600\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.8321 - sparse_categorical_accuracy: 0.7708 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 26/600\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.8055 - sparse_categorical_accuracy: 0.7891 - val_loss: 0.5436 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 27/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.7377 - sparse_categorical_accuracy: 0.8125 - val_loss: 0.5259 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 28/600\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.6795 - sparse_categorical_accuracy: 0.8542 - val_loss: 0.5230 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 29/600\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.6395 - sparse_categorical_accuracy: 0.8411 - val_loss: 0.4749 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 30/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.5800 - sparse_categorical_accuracy: 0.8594 - val_loss: 0.4412 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 31/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.5438 - sparse_categorical_accuracy: 0.8698 - val_loss: 0.4303 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 32/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.5441 - sparse_categorical_accuracy: 0.8542 - val_loss: 0.3889 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 33/600\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.5419 - sparse_categorical_accuracy: 0.8516 - val_loss: 0.4633 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 34/600\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.5387 - sparse_categorical_accuracy: 0.8542 - val_loss: 0.4246 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 35/600\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.4731 - sparse_categorical_accuracy: 0.8906 - val_loss: 0.4230 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 36/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.4415 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.3298 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 37/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.4102 - sparse_categorical_accuracy: 0.9010 - val_loss: 0.3103 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 38/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.3639 - sparse_categorical_accuracy: 0.9036 - val_loss: 0.3100 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 39/600\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.3661 - sparse_categorical_accuracy: 0.9089 - val_loss: 0.3468 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 40/600\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.3819 - sparse_categorical_accuracy: 0.9115 - val_loss: 0.3136 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 41/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.3313 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.2656 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 42/600\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.3319 - sparse_categorical_accuracy: 0.9089 - val_loss: 0.3083 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 43/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.3590 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.3122 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 44/600\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.3194 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.2530 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 45/600\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.2504 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2419 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 46/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.2877 - sparse_categorical_accuracy: 0.9349 - val_loss: 0.2297 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 47/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.2385 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.2382 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 48/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.2346 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.2223 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 49/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.2662 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.2092 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 50/600\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.2647 - sparse_categorical_accuracy: 0.9349 - val_loss: 0.2312 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 51/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.2466 - sparse_categorical_accuracy: 0.9349 - val_loss: 0.2742 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 52/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.2114 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.2457 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 53/600\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.1998 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2372 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 54/600\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.1831 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2298 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 55/600\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.2079 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2178 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 56/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1771 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.2213 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 57/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.1638 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2088 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 58/600\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.1876 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.2316 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 59/600\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.1667 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2132 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 60/600\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.1932 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2161 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 61/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.1879 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.1860 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 62/600\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.1536 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2503 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 63/600\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.1593 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.2263 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 64/600\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.1487 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2031 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 65/600\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.1326 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.1788 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 66/600\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.1494 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.2499 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 67/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.1434 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2618 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 68/600\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.1386 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1716 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 69/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.2128 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.2137 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 70/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.1674 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.1631 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 71/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.1338 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2041 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 72/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.1154 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1840 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 73/600\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.2033 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 74/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.1389 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.2456 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 75/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.1465 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2349 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 76/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1179 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2245 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 77/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.1169 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1939 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 78/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.1121 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.1941 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 79/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0884 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1689 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 80/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.1749 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 81/600\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0989 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1423 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 82/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0841 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2296 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 83/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1598 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 84/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1800 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 85/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1786 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 86/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0690 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1982 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 87/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1599 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 88/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0668 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1868 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 89/600\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0694 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.2580 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 90/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0850 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1858 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 91/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0743 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1948 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 92/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0812 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2271 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 93/600\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0629 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.1538 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 94/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0587 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1806 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 95/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1842 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 96/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1899 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 97/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0850 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2725 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 98/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1108 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.3065 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 99/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0932 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2115 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 100/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0762 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2162 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 101/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0746 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.2093 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 102/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.1083 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.2195 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 103/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.2437 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 104/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.1688 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 105/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0535 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.1574 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 106/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0635 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1749 - val_sparse_categorical_accuracy: 0.9518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18db8baff70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "\n",
    ")\n",
    "model.fit(X_train, y_train, \n",
    "            epochs=600,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stopping],\n",
    "            validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2232 - sparse_categorical_accuracy: 0.9518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x18dbaaead90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model for TensorFlowLite on PocketBeagle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "data (Dense)                 (None, 1024)              1180672   \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "result (Dense)               (None, 11)                11275     \n",
      "=================================================================\n",
      "Total params: 3,291,147\n",
      "Trainable params: 3,291,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert TF model to TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmpe0py4zwf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmpe0py4zwf\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('test_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify TensorFlowLite model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'data_input', 'index': 0, 'shape': array([   1, 1152]), 'shape_signature': array([  -1, 1152]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='test_model.tflite')\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(input_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_size = X_test[0].size\n",
    "testing_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27108055, 0.60922673, 0.45772752, ..., 0.52093402, 0.48902781,\n",
       "       0.58226719])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.033 0.94  0.009 0.    0.    0.    0.018 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.998 0.    0.    0.    0.001 0.    0.   ]\n",
      " [0.    0.011 0.987 0.001 0.    0.    0.    0.001 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.977 0.012 0.    0.002 0.009 0.   ]\n",
      " [0.    0.999 0.001 0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.001 0.    0.    0.    0.004 0.    0.958 0.    0.016 0.021 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.999 0.    0.    0.001 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
      " [0.    0.    0.005 0.995 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.999 0.   ]\n",
      " [0.    0.    0.    0.    0.001 0.885 0.05  0.    0.004 0.059 0.   ]\n",
      " [0.    0.173 0.004 0.01  0.001 0.001 0.    0.716 0.012 0.083 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   ]\n",
      " [0.002 0.    0.    0.009 0.956 0.    0.008 0.    0.024 0.    0.   ]\n",
      " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.999 0.    0.    0.    0.    0.    0.   ]\n",
      " [0.001 0.    0.992 0.007 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.998 0.001 0.    0.    0.    0.    0.001 0.    0.    0.   ]\n",
      " [0.002 0.001 0.993 0.004 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.999 0.    0.    0.    0.    0.    0.    0.    0.001 0.   ]\n",
      " [0.927 0.    0.072 0.001 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.001 0.022 0.976 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.001 0.    0.    0.    0.99  0.001 0.002 0.001 0.005 0.001]\n",
      " [0.    0.022 0.96  0.001 0.    0.    0.    0.017 0.    0.    0.   ]\n",
      " [0.991 0.    0.    0.    0.    0.    0.009 0.    0.    0.    0.   ]\n",
      " [0.    0.002 0.    0.    0.    0.    0.    0.993 0.    0.005 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   ]\n",
      " [0.013 0.    0.    0.    0.    0.    0.986 0.    0.    0.    0.   ]\n",
      " [0.    0.98  0.003 0.001 0.008 0.    0.001 0.001 0.001 0.005 0.   ]\n",
      " [0.    0.989 0.002 0.001 0.002 0.    0.    0.002 0.    0.004 0.   ]\n",
      " [0.    0.001 0.    0.    0.    0.033 0.642 0.    0.002 0.322 0.   ]]\n",
      "[ 2  4  2  5  1  6  6  8  3  0  9  5  7  9  4  0  4  2  1  2  1  0  3  5\n",
      "  2  0  7 10  6  1  1  5  3 10  6  8  7  7  2  8  9  5  3 10  7  6  9  3\n",
      "  9 10  4  9  8  0  4  6  2 10  0  7  0  6  8  7  1  1 10  2 10  6  4  9\n",
      "  3  5  4  8  3  8  0  4  3  5  5]\n"
     ]
    }
   ],
   "source": [
    "#Sometimes behaves weird if no resizing of array \n",
    "input_data = np.float32(np.resize(X_test[0], (1, testing_size)))\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(np.round(output_data, decimals=3))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 1 but expected 32 for dimension 0 of input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-ed01d186557a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m113\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36mset_tensor\u001b[1;34m(self, tensor_index, value)\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0mcould\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mset\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \"\"\"\n\u001b[1;32m--> 607\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSetTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mresize_tensor_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 1 but expected 32 for dimension 0 of input 0."
     ]
    }
   ],
   "source": [
    "for i in range(0, 113):\n",
    "    input_data = np.float32(np.resize(X_test[i], (1, testing_size)))\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lbl = np.argmax(output, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, output_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 2.4458 - sparse_categorical_accuracy: 0.0795 - val_loss: 2.3590 - val_sparse_categorical_accuracy: 0.1566\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 2.4176 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3129 - val_sparse_categorical_accuracy: 0.2530\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 2.3705 - sparse_categorical_accuracy: 0.1250 - val_loss: 2.2712 - val_sparse_categorical_accuracy: 0.2169\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 2.3019 - sparse_categorical_accuracy: 0.1955 - val_loss: 2.2228 - val_sparse_categorical_accuracy: 0.5301\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 2.2629 - sparse_categorical_accuracy: 0.2068 - val_loss: 2.1623 - val_sparse_categorical_accuracy: 0.4217\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 2.2068 - sparse_categorical_accuracy: 0.2455 - val_loss: 2.0974 - val_sparse_categorical_accuracy: 0.4940\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 2.1516 - sparse_categorical_accuracy: 0.3023 - val_loss: 2.0387 - val_sparse_categorical_accuracy: 0.5301\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 2.0687 - sparse_categorical_accuracy: 0.3886 - val_loss: 1.9132 - val_sparse_categorical_accuracy: 0.7349\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0039 - sparse_categorical_accuracy: 0.3955 - val_loss: 1.8043 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 1.8828 - sparse_categorical_accuracy: 0.4091 - val_loss: 1.7587 - val_sparse_categorical_accuracy: 0.7349\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 1.8070 - sparse_categorical_accuracy: 0.4568 - val_loss: 1.6525 - val_sparse_categorical_accuracy: 0.6145\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 1.6915 - sparse_categorical_accuracy: 0.5114 - val_loss: 1.5277 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 1.5634 - sparse_categorical_accuracy: 0.5250 - val_loss: 1.3735 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 1s 67ms/step - loss: 1.4874 - sparse_categorical_accuracy: 0.5773 - val_loss: 1.2980 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 1.4223 - sparse_categorical_accuracy: 0.6091 - val_loss: 1.1791 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 1.2809 - sparse_categorical_accuracy: 0.6318 - val_loss: 1.0970 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 1.1825 - sparse_categorical_accuracy: 0.6955 - val_loss: 1.0486 - val_sparse_categorical_accuracy: 0.7590\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 1.1564 - sparse_categorical_accuracy: 0.6545 - val_loss: 0.9304 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0487 - sparse_categorical_accuracy: 0.729 - 1s 50ms/step - loss: 1.0487 - sparse_categorical_accuracy: 0.7295 - val_loss: 0.9138 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.9457 - sparse_categorical_accuracy: 0.7591 - val_loss: 0.8406 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.9373 - sparse_categorical_accuracy: 0.7477 - val_loss: 0.8491 - val_sparse_categorical_accuracy: 0.7711\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.8945 - sparse_categorical_accuracy: 0.7545 - val_loss: 0.7272 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.8348 - sparse_categorical_accuracy: 0.7659 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.7271 - sparse_categorical_accuracy: 0.8273 - val_loss: 0.6113 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.6630 - sparse_categorical_accuracy: 0.8568 - val_loss: 0.5575 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.6591 - sparse_categorical_accuracy: 0.8273 - val_loss: 0.5505 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.6003 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.6052 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.5528 - sparse_categorical_accuracy: 0.8523 - val_loss: 0.5175 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.5417 - sparse_categorical_accuracy: 0.8636 - val_loss: 0.4196 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4759 - sparse_categorical_accuracy: 0.868 - 1s 50ms/step - loss: 0.4759 - sparse_categorical_accuracy: 0.8682 - val_loss: 0.4242 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4827 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.3938 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.4883 - sparse_categorical_accuracy: 0.8636 - val_loss: 0.3634 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.4627 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.4196 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.4475 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.3292 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.4221 - sparse_categorical_accuracy: 0.8955 - val_loss: 0.3494 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.4023 - sparse_categorical_accuracy: 0.8977 - val_loss: 0.3679 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.3778 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.3279 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.3443 - sparse_categorical_accuracy: 0.9273 - val_loss: 0.2607 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3401 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.3762 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.3317 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.2691 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2889 - sparse_categorical_accuracy: 0.9205 - val_loss: 0.2566 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.2780 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.2575 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2974 - sparse_categorical_accuracy: 0.9227 - val_loss: 0.2201 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2759 - sparse_categorical_accuracy: 0.9318 - val_loss: 0.2791 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.2594 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.1987 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.2676 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.2563 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2169 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.2807 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.2517 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.2312 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2715 - sparse_categorical_accuracy: 0.9273 - val_loss: 0.2528 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2183 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.3040 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2276 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.1877 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.1938 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.2080 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1751 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.1507 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1746 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.2071 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.1634 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1791 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1458 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1761 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.1486 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1690 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.1474 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.2115 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1804 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.2194 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.1320 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1615 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1609 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1999 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1207 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1760 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1390 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.2835 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1582 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.2116 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1514 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1222 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1330 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.2075 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1211 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1218 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1115 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.2242 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1368 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1652 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1156 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1296 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1381 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.2110 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.2830 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1620 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.1454 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1521 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.2670 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1288 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1237 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.1153 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1532 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0882 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1309 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1414 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1459 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1070 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1124 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1734 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1235 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.1432 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 83/600\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1010 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1630 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0784 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1402 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1624 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.1955 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0846 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1586 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 90/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1088 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 91/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0810 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1226 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0738 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1637 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0721 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.1793 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1310 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1792 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.1711 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0904 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.2363 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1647 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0612 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.2379 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0767 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.2193 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0771 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1144 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1286 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1513 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0542 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1757 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1896 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1032 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.2318 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1086 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1547 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0888 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1170 - val_sparse_categorical_accuracy: 0.9759\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmp4uk4i7m8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmp4uk4i7m8\\assets\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatwavedata, labels):\n",
    "    X_train, X_test = formatwavedata[train_index], formatwavedata[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('hand_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_val, y_val)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_val)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_val\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
