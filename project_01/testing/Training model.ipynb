{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "def wavelet(data, level, wavelet):\n",
    "    (cA, cD) = pywt.dwt(data, wavelet=wavelet)\n",
    "    for i in range(1, level):\n",
    "        (cA, cD) = pywt.dwt(cA, wavelet=wavelet)\n",
    "    return cA, cD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gestures = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10\n",
    "]\n",
    "num_samples = 50\n",
    "num_gestures = len(gestures)\n",
    "\n",
    "one_hot = np.eye(len(gestures))\n",
    "\n",
    "\n",
    "\n",
    "fulldata = pd.DataFrame(columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "fullwavedata = pd.DataFrame(columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'])\n",
    "formatdata = pd.DataFrame()\n",
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "labels = []\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        filepath = 'hand/hand_{0}_{1}.csv'.format(gesture, i)\n",
    "        data = pd.read_csv(filepath, index_col=False)\n",
    "        wavedata = pd.DataFrame()\n",
    "        \n",
    "        level1 = 5\n",
    "        wavetype1 = 'db20'\n",
    "        \n",
    "        wavedata['aX_A1'], wavedata['aX_D1'] = wavelet(data['aX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aY_A1'], wavedata['aY_D1'] = wavelet(data['aY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aZ_A1'], wavedata['aZ_D1'] = wavelet(data['aZ'], level=level1, wavelet=wavetype1)\n",
    "\n",
    "        wavedata['gX_A1'], wavedata['gX_D1'] = wavelet(data['gX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gY_A1'], wavedata['gY_D1'] = wavelet(data['gY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gZ_A1'], wavedata['gZ_D1'] = wavelet(data['gZ'], level=level1, wavelet=wavetype1)\n",
    "        \n",
    "        level2 = 3\n",
    "        wavetype2 = 'rbio2.2'\n",
    "\n",
    "        wavedata['aX_A2'], wavedata['aX_D2'] = wavelet(data['aX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aY_A2'], wavedata['aY_D2'] = wavelet(data['aY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aZ_A2'], wavedata['aZ_D2'] = wavelet(data['aZ'], level=level2, wavelet=wavetype2)\n",
    "\n",
    "        wavedata['gX_A2'], wavedata['gX_D2'] = wavelet(data['gX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gY_A2'], wavedata['gY_D2'] = wavelet(data['gY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gZ_A2'], wavedata['gZ_D2'] = wavelet(data['gZ'], level=level2, wavelet=wavetype2)\n",
    "        \n",
    "        wavelen = len(wavedata)\n",
    "        \n",
    "        fullwavedata = fullwavedata.append(wavedata)\n",
    "        fulldata = fulldata.append(data)\n",
    "        label = gesture\n",
    "        labels.append(label)\n",
    "        #del data, wavedata\n",
    "\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX</th>\n",
       "      <th>aY</th>\n",
       "      <th>aZ</th>\n",
       "      <th>gX</th>\n",
       "      <th>gY</th>\n",
       "      <th>gZ</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.579977</td>\n",
       "      <td>-7.139509</td>\n",
       "      <td>3.031059</td>\n",
       "      <td>-1.203078</td>\n",
       "      <td>-1.997403</td>\n",
       "      <td>-2.221498</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.735600</td>\n",
       "      <td>-7.965509</td>\n",
       "      <td>3.031059</td>\n",
       "      <td>-1.054392</td>\n",
       "      <td>-2.066683</td>\n",
       "      <td>-2.209773</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.965444</td>\n",
       "      <td>-8.616732</td>\n",
       "      <td>2.918532</td>\n",
       "      <td>-0.877461</td>\n",
       "      <td>-2.145289</td>\n",
       "      <td>-2.162609</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11.042058</td>\n",
       "      <td>-9.119514</td>\n",
       "      <td>2.705448</td>\n",
       "      <td>-0.444193</td>\n",
       "      <td>-2.352331</td>\n",
       "      <td>-1.929721</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.187328</td>\n",
       "      <td>-9.586383</td>\n",
       "      <td>2.731784</td>\n",
       "      <td>-0.259801</td>\n",
       "      <td>-2.428539</td>\n",
       "      <td>-1.797822</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-9.746795</td>\n",
       "      <td>-0.210690</td>\n",
       "      <td>-0.208296</td>\n",
       "      <td>-0.028778</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-9.818621</td>\n",
       "      <td>-0.215478</td>\n",
       "      <td>-0.232238</td>\n",
       "      <td>-0.022649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020784</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-9.734824</td>\n",
       "      <td>-0.234632</td>\n",
       "      <td>-0.260968</td>\n",
       "      <td>-0.019985</td>\n",
       "      <td>-0.004530</td>\n",
       "      <td>0.030377</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-9.732430</td>\n",
       "      <td>-0.177171</td>\n",
       "      <td>-0.320823</td>\n",
       "      <td>-0.017054</td>\n",
       "      <td>-0.014123</td>\n",
       "      <td>0.031709</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-9.756372</td>\n",
       "      <td>-0.186748</td>\n",
       "      <td>-0.205901</td>\n",
       "      <td>-0.011191</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>0.036505</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aX        aY        aZ        gX        gY        gZ  Unnamed: 0\n",
       "0   -10.579977 -7.139509  3.031059 -1.203078 -1.997403 -2.221498         NaN\n",
       "1   -10.735600 -7.965509  3.031059 -1.054392 -2.066683 -2.209773         NaN\n",
       "2   -10.965444 -8.616732  2.918532 -0.877461 -2.145289 -2.162609         NaN\n",
       "3   -11.042058 -9.119514  2.705448 -0.444193 -2.352331 -1.929721         NaN\n",
       "4   -10.187328 -9.586383  2.731784 -0.259801 -2.428539 -1.797822         NaN\n",
       "..         ...       ...       ...       ...       ...       ...         ...\n",
       "345  -9.746795 -0.210690 -0.208296 -0.028778  0.008527 -0.000266         NaN\n",
       "346  -9.818621 -0.215478 -0.232238 -0.022649  0.000000  0.020784         NaN\n",
       "347  -9.734824 -0.234632 -0.260968 -0.019985 -0.004530  0.030377         NaN\n",
       "348  -9.732430 -0.177171 -0.320823 -0.017054 -0.014123  0.031709         NaN\n",
       "349  -9.756372 -0.186748 -0.205901 -0.011191 -0.015721  0.036505         NaN\n",
       "\n",
       "[192500 rows x 7 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata = fulldata.iloc[0:, 0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX</th>\n",
       "      <th>aY</th>\n",
       "      <th>aZ</th>\n",
       "      <th>gX</th>\n",
       "      <th>gY</th>\n",
       "      <th>gZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.579977</td>\n",
       "      <td>-7.139509</td>\n",
       "      <td>3.031059</td>\n",
       "      <td>-1.203078</td>\n",
       "      <td>-1.997403</td>\n",
       "      <td>-2.221498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.735600</td>\n",
       "      <td>-7.965509</td>\n",
       "      <td>3.031059</td>\n",
       "      <td>-1.054392</td>\n",
       "      <td>-2.066683</td>\n",
       "      <td>-2.209773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.965444</td>\n",
       "      <td>-8.616732</td>\n",
       "      <td>2.918532</td>\n",
       "      <td>-0.877461</td>\n",
       "      <td>-2.145289</td>\n",
       "      <td>-2.162609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11.042058</td>\n",
       "      <td>-9.119514</td>\n",
       "      <td>2.705448</td>\n",
       "      <td>-0.444193</td>\n",
       "      <td>-2.352331</td>\n",
       "      <td>-1.929721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.187328</td>\n",
       "      <td>-9.586383</td>\n",
       "      <td>2.731784</td>\n",
       "      <td>-0.259801</td>\n",
       "      <td>-2.428539</td>\n",
       "      <td>-1.797822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-9.746795</td>\n",
       "      <td>-0.210690</td>\n",
       "      <td>-0.208296</td>\n",
       "      <td>-0.028778</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>-0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-9.818621</td>\n",
       "      <td>-0.215478</td>\n",
       "      <td>-0.232238</td>\n",
       "      <td>-0.022649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-9.734824</td>\n",
       "      <td>-0.234632</td>\n",
       "      <td>-0.260968</td>\n",
       "      <td>-0.019985</td>\n",
       "      <td>-0.004530</td>\n",
       "      <td>0.030377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-9.732430</td>\n",
       "      <td>-0.177171</td>\n",
       "      <td>-0.320823</td>\n",
       "      <td>-0.017054</td>\n",
       "      <td>-0.014123</td>\n",
       "      <td>0.031709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-9.756372</td>\n",
       "      <td>-0.186748</td>\n",
       "      <td>-0.205901</td>\n",
       "      <td>-0.011191</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>0.036505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aX        aY        aZ        gX        gY        gZ\n",
       "0   -10.579977 -7.139509  3.031059 -1.203078 -1.997403 -2.221498\n",
       "1   -10.735600 -7.965509  3.031059 -1.054392 -2.066683 -2.209773\n",
       "2   -10.965444 -8.616732  2.918532 -0.877461 -2.145289 -2.162609\n",
       "3   -11.042058 -9.119514  2.705448 -0.444193 -2.352331 -1.929721\n",
       "4   -10.187328 -9.586383  2.731784 -0.259801 -2.428539 -1.797822\n",
       "..         ...       ...       ...       ...       ...       ...\n",
       "345  -9.746795 -0.210690 -0.208296 -0.028778  0.008527 -0.000266\n",
       "346  -9.818621 -0.215478 -0.232238 -0.022649  0.000000  0.020784\n",
       "347  -9.734824 -0.234632 -0.260968 -0.019985 -0.004530  0.030377\n",
       "348  -9.732430 -0.177171 -0.320823 -0.017054 -0.014123  0.031709\n",
       "349  -9.756372 -0.186748 -0.205901 -0.011191 -0.015721  0.036505\n",
       "\n",
       "[192500 rows x 6 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX</th>\n",
       "      <th>aY</th>\n",
       "      <th>aZ</th>\n",
       "      <th>gX</th>\n",
       "      <th>gY</th>\n",
       "      <th>gZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.400953</td>\n",
       "      <td>0.508082</td>\n",
       "      <td>0.541712</td>\n",
       "      <td>0.499318</td>\n",
       "      <td>0.427822</td>\n",
       "      <td>0.502331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.074306</td>\n",
       "      <td>0.068467</td>\n",
       "      <td>0.085276</td>\n",
       "      <td>0.096042</td>\n",
       "      <td>0.095247</td>\n",
       "      <td>0.095711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.377844</td>\n",
       "      <td>0.486061</td>\n",
       "      <td>0.488569</td>\n",
       "      <td>0.484298</td>\n",
       "      <td>0.406824</td>\n",
       "      <td>0.492653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.388312</td>\n",
       "      <td>0.508553</td>\n",
       "      <td>0.539899</td>\n",
       "      <td>0.505739</td>\n",
       "      <td>0.420533</td>\n",
       "      <td>0.502602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.411963</td>\n",
       "      <td>0.535409</td>\n",
       "      <td>0.591876</td>\n",
       "      <td>0.521076</td>\n",
       "      <td>0.432317</td>\n",
       "      <td>0.517067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aX             aY             aZ             gX  \\\n",
       "count  192500.000000  192500.000000  192500.000000  192500.000000   \n",
       "mean        0.400953       0.508082       0.541712       0.499318   \n",
       "std         0.074306       0.068467       0.085276       0.096042   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.377844       0.486061       0.488569       0.484298   \n",
       "50%         0.388312       0.508553       0.539899       0.505739   \n",
       "75%         0.411963       0.535409       0.591876       0.521076   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  gY             gZ  \n",
       "count  192500.000000  192500.000000  \n",
       "mean        0.427822       0.502331  \n",
       "std         0.095247       0.095711  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.406824       0.492653  \n",
       "50%         0.420533       0.502602  \n",
       "75%         0.432317       0.517067  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normaldata = (fulldata - fulldata.min()) / (fulldata.max()-fulldata.min())\n",
    "normaldata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-39.2266  , -39.2266  , -14.848839,  -7.023951,  -5.979951,\n",
       "        -8.731442,   0.      ], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = np.array(fulldata.min(), dtype='float32')\n",
    "maxval = np.array(fulldata.max(), dtype='float32')\n",
    "\n",
    "parameters_full = pd.DataFrame([minval, maxval], columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "parameters_full.to_csv('parameters_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36514839, 0.40900282, 0.53687994, ..., 0.49930897, 0.43952637,\n",
       "        0.49567407],\n",
       "       [0.36826123, 0.55677119, 0.61452193, ..., 0.50932893, 0.42393172,\n",
       "        0.49123369],\n",
       "       [0.37146563, 0.4280766 , 0.58713156, ..., 0.50639205, 0.42553788,\n",
       "        0.49358358],\n",
       "       ...,\n",
       "       [0.3648127 , 0.37119097, 0.40265996, ..., 0.50357033, 0.42159719,\n",
       "        0.49990082],\n",
       "       [0.38944076, 0.36267643, 0.41401869, ..., 0.50669917, 0.41905722,\n",
       "        0.51453422],\n",
       "       [0.37061112, 0.37793545, 0.42573688, ..., 0.50518274, 0.41803003,\n",
       "        0.50209812]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatdata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*350 + (i-1) * 350\n",
    "        #print(index, index+250)\n",
    "        dataf = normaldata.iloc[index:index+350].to_numpy().flatten().tolist()\n",
    "        formatdata[idx*num_samples+i-1] = dataf\n",
    "        del dataf\n",
    "        \n",
    "        \n",
    "formatdata = formatdata.transpose().to_numpy()\n",
    "formatdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2100"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formatdata[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = np.array(fullwavedata.min(), dtype='float32')\n",
    "maxval = np.array(fullwavedata.max(), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pd.DataFrame([minval, maxval], columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'], index=['min','max'])\n",
    "parameters.to_csv('dataparameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX_A1</th>\n",
       "      <th>aX_D1</th>\n",
       "      <th>aY_A1</th>\n",
       "      <th>aY_D1</th>\n",
       "      <th>aZ_A1</th>\n",
       "      <th>aZ_D1</th>\n",
       "      <th>gX_A1</th>\n",
       "      <th>gX_D1</th>\n",
       "      <th>gY_A1</th>\n",
       "      <th>gY_D1</th>\n",
       "      <th>...</th>\n",
       "      <th>aY_A2</th>\n",
       "      <th>aY_D2</th>\n",
       "      <th>aZ_A2</th>\n",
       "      <th>aZ_D2</th>\n",
       "      <th>gX_A2</th>\n",
       "      <th>gX_D2</th>\n",
       "      <th>gY_A2</th>\n",
       "      <th>gY_D2</th>\n",
       "      <th>gZ_A2</th>\n",
       "      <th>gZ_D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.267300</td>\n",
       "      <td>0.474299</td>\n",
       "      <td>0.532783</td>\n",
       "      <td>0.475571</td>\n",
       "      <td>0.587976</td>\n",
       "      <td>0.513237</td>\n",
       "      <td>0.493822</td>\n",
       "      <td>0.496712</td>\n",
       "      <td>0.483855</td>\n",
       "      <td>0.515383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432839</td>\n",
       "      <td>0.449727</td>\n",
       "      <td>0.558324</td>\n",
       "      <td>0.521365</td>\n",
       "      <td>0.500183</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.410186</td>\n",
       "      <td>0.521206</td>\n",
       "      <td>0.502551</td>\n",
       "      <td>0.583230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.123643</td>\n",
       "      <td>0.066293</td>\n",
       "      <td>0.116047</td>\n",
       "      <td>0.059190</td>\n",
       "      <td>0.129127</td>\n",
       "      <td>0.080489</td>\n",
       "      <td>0.125645</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.116264</td>\n",
       "      <td>0.072924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083774</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.097088</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.102759</td>\n",
       "      <td>0.048254</td>\n",
       "      <td>0.099510</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>0.090144</td>\n",
       "      <td>0.035227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.193030</td>\n",
       "      <td>0.451570</td>\n",
       "      <td>0.475979</td>\n",
       "      <td>0.461617</td>\n",
       "      <td>0.511344</td>\n",
       "      <td>0.488324</td>\n",
       "      <td>0.429299</td>\n",
       "      <td>0.476434</td>\n",
       "      <td>0.403973</td>\n",
       "      <td>0.493319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403568</td>\n",
       "      <td>0.446310</td>\n",
       "      <td>0.494259</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.482615</td>\n",
       "      <td>0.515702</td>\n",
       "      <td>0.388433</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>0.492884</td>\n",
       "      <td>0.579189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.238372</td>\n",
       "      <td>0.475990</td>\n",
       "      <td>0.541994</td>\n",
       "      <td>0.478134</td>\n",
       "      <td>0.593200</td>\n",
       "      <td>0.513502</td>\n",
       "      <td>0.502039</td>\n",
       "      <td>0.497601</td>\n",
       "      <td>0.497887</td>\n",
       "      <td>0.511452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435093</td>\n",
       "      <td>0.449777</td>\n",
       "      <td>0.557355</td>\n",
       "      <td>0.521536</td>\n",
       "      <td>0.506969</td>\n",
       "      <td>0.519877</td>\n",
       "      <td>0.404442</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.502341</td>\n",
       "      <td>0.582993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.316260</td>\n",
       "      <td>0.497073</td>\n",
       "      <td>0.597311</td>\n",
       "      <td>0.492333</td>\n",
       "      <td>0.673205</td>\n",
       "      <td>0.538372</td>\n",
       "      <td>0.545229</td>\n",
       "      <td>0.518854</td>\n",
       "      <td>0.545459</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470832</td>\n",
       "      <td>0.453207</td>\n",
       "      <td>0.617096</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.523956</td>\n",
       "      <td>0.524138</td>\n",
       "      <td>0.415941</td>\n",
       "      <td>0.525350</td>\n",
       "      <td>0.515112</td>\n",
       "      <td>0.586998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              aX_A1         aX_D1         aY_A1         aY_D1         aZ_A1  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.267300      0.474299      0.532783      0.475571      0.587976   \n",
       "std        0.123643      0.066293      0.116047      0.059190      0.129127   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.193030      0.451570      0.475979      0.461617      0.511344   \n",
       "50%        0.238372      0.475990      0.541994      0.478134      0.593200   \n",
       "75%        0.316260      0.497073      0.597311      0.492333      0.673205   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              aZ_D1         gX_A1         gX_D1         gY_A1         gY_D1  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.513237      0.493822      0.496712      0.483855      0.515383   \n",
       "std        0.080489      0.125645      0.090167      0.116264      0.072924   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.488324      0.429299      0.476434      0.403973      0.493319   \n",
       "50%        0.513502      0.502039      0.497601      0.497887      0.511452   \n",
       "75%        0.538372      0.545229      0.518854      0.545459      0.537361   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...         aY_A2         aY_D2         aZ_A2         aZ_D2  \\\n",
       "count  ...  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean   ...      0.432839      0.449727      0.558324      0.521365   \n",
       "std    ...      0.083774      0.033548      0.097088      0.042426   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.403568      0.446310      0.494259      0.515400   \n",
       "50%    ...      0.435093      0.449777      0.557355      0.521536   \n",
       "75%    ...      0.470832      0.453207      0.617096      0.527778   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gX_A2         gX_D2         gY_A2         gY_D2         gZ_A2  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.500183      0.519830      0.410186      0.521206      0.502551   \n",
       "std        0.102759      0.048254      0.099510      0.040963      0.090144   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.482615      0.515702      0.388433      0.517965      0.492884   \n",
       "50%        0.506969      0.519877      0.404442      0.521259      0.502341   \n",
       "75%        0.523956      0.524138      0.415941      0.525350      0.515112   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gZ_D2  \n",
       "count  26400.000000  \n",
       "mean       0.583230  \n",
       "std        0.035227  \n",
       "min        0.000000  \n",
       "25%        0.579189  \n",
       "50%        0.582993  \n",
       "75%        0.586998  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalwavedata = (fullwavedata - fullwavedata.min()) / (fullwavedata.max()-fullwavedata.min())\n",
    "normalwavedata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2454407 , 0.41080022, 0.32581968, ..., 0.5188936 , 0.4929458 ,\n",
       "        0.58779549],\n",
       "       [0.19500412, 0.51896688, 0.61033764, ..., 0.52143732, 0.49012884,\n",
       "        0.58391459],\n",
       "       [0.22643872, 0.4297922 , 0.33365506, ..., 0.52195295, 0.49385348,\n",
       "        0.58364604],\n",
       "       ...,\n",
       "       [0.56100788, 0.25162484, 0.60983698, ..., 0.51909722, 0.50125362,\n",
       "        0.58275752],\n",
       "       [0.629451  , 0.41301135, 0.71584526, ..., 0.52259185, 0.51834611,\n",
       "        0.58284503],\n",
       "       [0.62376549, 0.2756082 , 0.4846425 , ..., 0.52138206, 0.5016146 ,\n",
       "        0.58184442]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*wavelen + (i-1) * wavelen\n",
    "        #print(index, index+250)\n",
    "        wavedataf = normalwavedata.iloc[index:index+wavelen].to_numpy().flatten().tolist()\n",
    "        formatwavedata[idx*num_samples+i-1] = wavedataf\n",
    "        del wavedataf\n",
    "        \n",
    "        \n",
    "formatwavedata = formatwavedata.transpose().to_numpy()\n",
    "formatwavedata \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(formatwavedata, labels, test_size=0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15/0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "1: Train 0.08854166666666667; Test 0.0963855421686747; Val 0.0963855421686747\n",
      "2: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "3: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "4: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "5: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "6: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "7: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "8: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "9: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15)\n",
    "valsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15/0.85)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatwavedata, labels):\n",
    "    X_train, X_test = formatwavedata[train_index], formatwavedata[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "for train_index, val_index in valsplit.split(X_train, y_train):\n",
    "    X_train, X_val = X_train[train_index], X_train[val_index]\n",
    "    y_train, y_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "for i in range(0,10):\n",
    "    print('{3}: Train {0}; Test {1}; Val {2}'.format(np.size(np.where(y_train == i)) / len(y_train), np.size(np.where(y_test == i)) / len(y_test), np.size(np.where(y_val == i)) / len(y_val), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 2.4077 - sparse_categorical_accuracy: 0.1172 - val_loss: 2.3226 - val_sparse_categorical_accuracy: 0.3253\n",
      "Epoch 2/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 2.3528 - sparse_categorical_accuracy: 0.1484 - val_loss: 2.2602 - val_sparse_categorical_accuracy: 0.4337\n",
      "Epoch 3/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 2.2891 - sparse_categorical_accuracy: 0.2083 - val_loss: 2.1861 - val_sparse_categorical_accuracy: 0.5422\n",
      "Epoch 4/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 2.2291 - sparse_categorical_accuracy: 0.2396 - val_loss: 2.1111 - val_sparse_categorical_accuracy: 0.6024\n",
      "Epoch 5/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 2.1351 - sparse_categorical_accuracy: 0.3177 - val_loss: 2.0006 - val_sparse_categorical_accuracy: 0.5181\n",
      "Epoch 6/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 2.0483 - sparse_categorical_accuracy: 0.3672 - val_loss: 1.8997 - val_sparse_categorical_accuracy: 0.5422\n",
      "Epoch 7/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.9164 - sparse_categorical_accuracy: 0.4297 - val_loss: 1.7673 - val_sparse_categorical_accuracy: 0.6506\n",
      "Epoch 8/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.8050 - sparse_categorical_accuracy: 0.4219 - val_loss: 1.6792 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 9/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.6399 - sparse_categorical_accuracy: 0.4740 - val_loss: 1.5425 - val_sparse_categorical_accuracy: 0.6386\n",
      "Epoch 10/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.5561 - sparse_categorical_accuracy: 0.5208 - val_loss: 1.4206 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 11/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.4980 - sparse_categorical_accuracy: 0.5443 - val_loss: 1.3881 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 12/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.3854 - sparse_categorical_accuracy: 0.5781 - val_loss: 1.3012 - val_sparse_categorical_accuracy: 0.6506\n",
      "Epoch 13/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 1.3673 - sparse_categorical_accuracy: 0.5312 - val_loss: 1.2152 - val_sparse_categorical_accuracy: 0.7711\n",
      "Epoch 14/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.2629 - sparse_categorical_accuracy: 0.6198 - val_loss: 1.1526 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 15/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.1764 - sparse_categorical_accuracy: 0.6458 - val_loss: 1.0941 - val_sparse_categorical_accuracy: 0.7349\n",
      "Epoch 16/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.1206 - sparse_categorical_accuracy: 0.6615 - val_loss: 1.0927 - val_sparse_categorical_accuracy: 0.6506\n",
      "Epoch 17/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 1.0821 - sparse_categorical_accuracy: 0.6849 - val_loss: 0.9918 - val_sparse_categorical_accuracy: 0.7711\n",
      "Epoch 18/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.9821 - sparse_categorical_accuracy: 0.7240 - val_loss: 0.9236 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 19/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.9559 - sparse_categorical_accuracy: 0.7292 - val_loss: 0.9426 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 20/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.9365 - sparse_categorical_accuracy: 0.7214 - val_loss: 0.7981 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 21/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.8594 - sparse_categorical_accuracy: 0.7786 - val_loss: 0.7258 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 22/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.7460 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.7036 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 23/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.7823 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6836 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 24/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.7484 - sparse_categorical_accuracy: 0.7812 - val_loss: 0.7741 - val_sparse_categorical_accuracy: 0.7831\n",
      "Epoch 25/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.6634 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.6282 - val_sparse_categorical_accuracy: 0.8193\n",
      "Epoch 26/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.6375 - sparse_categorical_accuracy: 0.8151 - val_loss: 0.6081 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 27/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.6202 - sparse_categorical_accuracy: 0.8411 - val_loss: 0.5698 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 28/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.5640 - sparse_categorical_accuracy: 0.8620 - val_loss: 0.6022 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 29/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.6284 - sparse_categorical_accuracy: 0.8125 - val_loss: 0.6473 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 30/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.5739 - sparse_categorical_accuracy: 0.8307 - val_loss: 0.5976 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 31/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.5322 - sparse_categorical_accuracy: 0.8594 - val_loss: 0.5570 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 32/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.4946 - sparse_categorical_accuracy: 0.8724 - val_loss: 0.5083 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 33/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.4590 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.4524 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 34/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.4329 - sparse_categorical_accuracy: 0.8776 - val_loss: 0.4271 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 35/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3945 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.4127 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 36/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3943 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.4154 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 37/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.3792 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.3793 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 38/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.3819 - sparse_categorical_accuracy: 0.9036 - val_loss: 0.4140 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 39/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.3546 - sparse_categorical_accuracy: 0.9115 - val_loss: 0.3703 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 40/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3377 - sparse_categorical_accuracy: 0.9141 - val_loss: 0.3455 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 41/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.3321 - sparse_categorical_accuracy: 0.9193 - val_loss: 0.4588 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 42/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3644 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.3131 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 43/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3267 - sparse_categorical_accuracy: 0.9141 - val_loss: 0.3268 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 44/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3087 - sparse_categorical_accuracy: 0.9245 - val_loss: 0.3655 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 45/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.2973 - sparse_categorical_accuracy: 0.9271 - val_loss: 0.3749 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 46/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 42ms/step - loss: 0.2747 - sparse_categorical_accuracy: 0.9323 - val_loss: 0.3266 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 47/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.2982 - sparse_categorical_accuracy: 0.9245 - val_loss: 0.3127 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 48/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.3243 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.2954 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 49/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.2834 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.2470 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 50/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.2935 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.2743 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 51/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.2723 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.3008 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 52/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.2803 - sparse_categorical_accuracy: 0.9323 - val_loss: 0.4173 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 53/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.2682 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.3841 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 54/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.2451 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.2725 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 55/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.2897 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.2608 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 56/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.2048 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2401 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 57/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1865 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2823 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 58/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.2161 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.3273 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 59/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.1960 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.2563 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 60/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.2004 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.2510 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 61/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1891 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2315 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 62/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1929 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.2421 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 63/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1837 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2505 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 64/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.1921 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.2169 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 65/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1537 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2220 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 66/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1709 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.2539 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 67/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.1886 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.2514 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 68/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1590 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.3200 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 69/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1775 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.2722 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 70/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1966 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.3404 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 71/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1468 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2079 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 72/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1276 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2452 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 73/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1158 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1996 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 74/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1187 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2732 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 75/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1416 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.3256 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 76/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.1358 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.2087 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 77/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1147 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.3082 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 78/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2734 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 79/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.1996 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 80/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1313 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2738 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 81/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1219 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2845 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 82/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1283 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.1900 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 83/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.1196 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2059 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 84/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1244 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.2172 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 85/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1967 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 86/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2009 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 87/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.0952 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2824 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 88/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.1078 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2440 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 89/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.0789 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1667 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 90/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.3758 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 91/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2647 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 92/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1248 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2328 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 93/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.1293 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.2073 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 94/600\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1684 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 95/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.1095 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.1932 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 96/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.1083 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2022 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 97/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.1008 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2459 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 98/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0776 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2388 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 99/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0616 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2010 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 100/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.2574 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 101/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1411 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 102/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0712 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.2652 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 103/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.2531 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 104/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0880 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.2556 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 105/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1706 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 106/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0949 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2757 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 107/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2676 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 108/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2516 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 109/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0554 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.2382 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 110/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.2044 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 111/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0526 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.2097 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 112/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0604 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.3276 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 113/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0664 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1691 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 114/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2605 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 115/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0599 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2690 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 116/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0523 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1467 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 117/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.2335 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 118/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.0551 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1952 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 119/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.0735 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.3593 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 120/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2139 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 121/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0817 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.1888 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 122/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0869 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2774 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 123/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0596 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.3578 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 124/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.0504 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.1279 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 125/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0391 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2201 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 126/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.2564 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 127/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0335 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.1760 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 128/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0485 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1897 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 129/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0379 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.3387 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 130/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.3011 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 131/600\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.1005 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.3038 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 132/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1121 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2818 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 133/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.3243 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 134/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1019 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.3939 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 135/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0604 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.2662 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 136/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0716 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2944 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 137/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0385 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.2687 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 138/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0356 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.2672 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 139/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.2163 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 140/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.1934 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 141/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0622 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.3058 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 142/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.1661 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 143/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0335 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.2679 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 144/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0263 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.2820 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 145/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0257 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.2176 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 146/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2874 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 147/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0366 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.1862 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 148/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0468 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.2598 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 149/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0303 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.2272 - val_sparse_categorical_accuracy: 0.9398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1abea8c8b50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "\n",
    ")\n",
    "model.fit(X_train, y_train, \n",
    "            epochs=600,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stopping],\n",
    "            validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2343 - sparse_categorical_accuracy: 0.9518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1abe6d2f160>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "data (Dense)                 (None, 1024)              1180672   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "result (Dense)               (None, 11)                11275     \n",
      "=================================================================\n",
      "Total params: 3,291,147\n",
      "Trainable params: 3,291,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = tf.keras.models.load_model('Training data/model1')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testvar\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testvar\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    model, 'testvar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmppn6r4u0b\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('test_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'data_input', 'index': 0, 'shape': array([   1, 1584]), 'shape_signature': array([  -1, 1584]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='test_model.tflite')\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(input_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_resize_dispatcher() got an unexpected keyword argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-51493053cb49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrydata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1584\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mresize\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _resize_dispatcher() got an unexpected keyword argument 'dtype'"
     ]
    }
   ],
   "source": [
    "trydata = np.resize(X_test[0], (1, 1584))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.004 0.    0.449 0.007 0.    0.    0.536 0.004 0.   ]]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "input_data = np.float32(np.resize(X_test[46], (1, 1584)))\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(np.round(output_data, decimals=3))\n",
    "print(y_test[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsure\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 113):\n",
    "    input_data = np.float32(np.resize(X_test[i], (1, 1584)))\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    output_data\n",
    "\n",
    "    if np.max(output_data) < 0.6:\n",
    "        print('Unsure')\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output_data)\n",
    "if max(output_data) < 0.5:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "SignatureDef method_name is None and model has 0 Signatures. None is only allowed when the model has 1 SignatureDef",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7c4bc9d72a2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msignatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_signature_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_signature_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36mget_signature_runner\u001b[1;34m(self, method_name)\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_signature_defs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;34m'SignatureDef method_name is None and model has {0} Signatures. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             'None is only allowed when the model has 1 SignatureDef'.format(\n",
      "\u001b[1;31mValueError\u001b[0m: SignatureDef method_name is None and model has 0 Signatures. None is only allowed when the model has 1 SignatureDef"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='test_model.tflite')\n",
    "\n",
    "signatures = interpreter.get_signature_list()\n",
    "print(signatures)\n",
    "predictor = interpreter.get_signature_runner()\n",
    "print(predictor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0964601e-07, 9.1763778e-04, 1.6810007e-05, 4.2849658e-03,\n",
       "        2.6555134e-03, 2.2810149e-05, 2.0116172e-04, 9.7670448e-01,\n",
       "        4.2905535e-06, 1.5192278e-02]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = predictor(data_input=np.float32(X_test[0]))['result']\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1584"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1bbd703a0d0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "output_lbl = np.argmax(output, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, output_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 2s 72ms/step - loss: 2.4147 - sparse_categorical_accuracy: 0.1205 - val_loss: 2.3086 - val_sparse_categorical_accuracy: 0.3373\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 2.3269 - sparse_categorical_accuracy: 0.1955 - val_loss: 2.2176 - val_sparse_categorical_accuracy: 0.2892\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 2.2167 - sparse_categorical_accuracy: 0.2523 - val_loss: 2.1059 - val_sparse_categorical_accuracy: 0.4699\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 2.1231 - sparse_categorical_accuracy: 0.3341 - val_loss: 1.9864 - val_sparse_categorical_accuracy: 0.5783\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.9980 - sparse_categorical_accuracy: 0.3727 - val_loss: 1.8181 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 1.8716 - sparse_categorical_accuracy: 0.4205 - val_loss: 1.6938 - val_sparse_categorical_accuracy: 0.5542\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 1.7055 - sparse_categorical_accuracy: 0.4636 - val_loss: 1.5393 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 1.5679 - sparse_categorical_accuracy: 0.5000 - val_loss: 1.3999 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 1.4499 - sparse_categorical_accuracy: 0.5659 - val_loss: 1.3510 - val_sparse_categorical_accuracy: 0.6747\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 1.3558 - sparse_categorical_accuracy: 0.6023 - val_loss: 1.2222 - val_sparse_categorical_accuracy: 0.6506\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 1.2366 - sparse_categorical_accuracy: 0.6682 - val_loss: 1.1081 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.1758 - sparse_categorical_accuracy: 0.6295 - val_loss: 1.0220 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 1.0802 - sparse_categorical_accuracy: 0.6932 - val_loss: 0.9489 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.0125 - sparse_categorical_accuracy: 0.7136 - val_loss: 0.8412 - val_sparse_categorical_accuracy: 0.8193\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.9388 - sparse_categorical_accuracy: 0.7409 - val_loss: 0.8391 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.8733 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.7876 - sparse_categorical_accuracy: 0.7932 - val_loss: 0.6345 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.7428 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.6306 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.6828 - sparse_categorical_accuracy: 0.8341 - val_loss: 0.5110 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6751 - sparse_categorical_accuracy: 0.8023 - val_loss: 0.4759 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.5983 - sparse_categorical_accuracy: 0.8432 - val_loss: 0.5046 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.5354 - sparse_categorical_accuracy: 0.8659 - val_loss: 0.4476 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.5004 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.4481 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.5130 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.3997 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4662 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.3381 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4426 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.3342 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4338 - sparse_categorical_accuracy: 0.8773 - val_loss: 0.3313 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4425 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.3131 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4262 - sparse_categorical_accuracy: 0.9000 - val_loss: 0.3475 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3833 - sparse_categorical_accuracy: 0.9068 - val_loss: 0.3043 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3502 - sparse_categorical_accuracy: 0.9114 - val_loss: 0.2491 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.3571 - sparse_categorical_accuracy: 0.9159 - val_loss: 0.2475 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.3121 - sparse_categorical_accuracy: 0.9000 - val_loss: 0.2679 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3404 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.2218 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2857 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.2239 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3000 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.2080 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2614 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.2367 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2877 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.1961 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2257 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.1685 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2200 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.1508 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2116 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.1492 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2055 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1217 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2237 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.1796 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2183 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.1695 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1967 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.1193 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 46/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2143 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.1608 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2133 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.1656 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1963 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.2018 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1722 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1102 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1594 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1102 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1560 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0920 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1495 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1407 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1742 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1657 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1798 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.1314 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1454 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.0864 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1625 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1198 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1368 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.0716 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1142 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0733 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1544 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1029 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0611 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0920 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0717 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0957 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0689 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1449 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.0565 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1284 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.0853 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1133 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0530 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1253 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1035 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1351 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.0998 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1155 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0777 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.0633 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0922 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0546 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0985 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0827 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 1s 70ms/step - loss: 0.1052 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0505 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0497 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 0.0970 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0599 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0714 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0842 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0904 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0503 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 0.0829 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0575 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0768 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0895 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0773 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0994 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0396 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0789 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0450 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 83/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0634 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0732 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0410 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 0.0514 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0434 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0843 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0443 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0873 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.0665 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0315 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0452 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0668 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0498 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 91/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0782 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0587 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0545 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0474 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0466 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0321 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0391 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0397 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0408 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0408 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0472 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0368 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0415 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0306 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0362 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0488 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0431 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0282 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0480 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0608 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0356 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0467 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0306 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0381 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0574 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0380 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0540 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0656 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1865 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0941 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0637 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0733 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0402 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0551 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0693 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0693 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0438 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0452 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0845 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0947 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0694 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0532 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1015 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0792 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0486 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0403 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0354 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0268 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0431 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0367 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0232 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0201 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0235 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 121/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0222 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 122/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0266 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0412 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 123/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0388 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0349 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 124/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0666 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0302 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 125/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0359 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 126/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0556 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0977 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 127/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 128/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0444 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0245 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 129/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0332 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0363 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 130/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0189 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0393 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 131/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0165 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0325 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 132/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0147 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 133/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0439 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0599 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 134/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0323 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0131 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 135/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0224 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0107 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 136/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0256 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0199 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 137/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0171 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0350 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 138/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.0176 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0116 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 139/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0407 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0389 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 140/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0413 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0199 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 141/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0338 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0256 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 142/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0333 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0332 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 143/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0255 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0392 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 144/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0157 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 145/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0233 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0474 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 146/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0243 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0472 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 147/600\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0188 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0206 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 148/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0170 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 149/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0236 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0126 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 150/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0113 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0160 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 151/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0136 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0257 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 152/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0252 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0264 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 153/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0224 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0127 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 154/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0195 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0160 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 155/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0118 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 156/600\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 0.0100 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0128 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 157/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0264 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0135 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 158/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0182 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0252 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 159/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0168 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0328 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 160/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0137 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0133 - val_sparse_categorical_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmpkijwq3eq\\assets\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatwavedata, labels):\n",
    "    X_train, X_test = formatwavedata[train_index], formatwavedata[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('number_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2414 - sparse_categorical_accuracy: 0.9273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1ab8f946520>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_val, y_val)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_val)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_val\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 1s 71ms/step - loss: 2.4630 - sparse_categorical_accuracy: 0.1091 - val_loss: 2.3521 - val_sparse_categorical_accuracy: 0.0909\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 2.3794 - sparse_categorical_accuracy: 0.1409 - val_loss: 2.2573 - val_sparse_categorical_accuracy: 0.2727\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 2.3044 - sparse_categorical_accuracy: 0.2205 - val_loss: 2.1766 - val_sparse_categorical_accuracy: 0.5455\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 2.2415 - sparse_categorical_accuracy: 0.2182 - val_loss: 2.0768 - val_sparse_categorical_accuracy: 0.6091\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 2.1289 - sparse_categorical_accuracy: 0.3568 - val_loss: 1.9510 - val_sparse_categorical_accuracy: 0.6909\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 2.0594 - sparse_categorical_accuracy: 0.3273 - val_loss: 1.8445 - val_sparse_categorical_accuracy: 0.6818\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 1.9410 - sparse_categorical_accuracy: 0.4364 - val_loss: 1.6922 - val_sparse_categorical_accuracy: 0.6364\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 1.7783 - sparse_categorical_accuracy: 0.5273 - val_loss: 1.5213 - val_sparse_categorical_accuracy: 0.6636\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 1.6654 - sparse_categorical_accuracy: 0.4932 - val_loss: 1.3483 - val_sparse_categorical_accuracy: 0.7364\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 1.5187 - sparse_categorical_accuracy: 0.5955 - val_loss: 1.2139 - val_sparse_categorical_accuracy: 0.8091\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 1.3840 - sparse_categorical_accuracy: 0.6318 - val_loss: 1.1873 - val_sparse_categorical_accuracy: 0.5727\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 1.3008 - sparse_categorical_accuracy: 0.6227 - val_loss: 1.0267 - val_sparse_categorical_accuracy: 0.7273\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 1.1768 - sparse_categorical_accuracy: 0.6818 - val_loss: 0.8753 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 1.0618 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.8147 - val_sparse_categorical_accuracy: 0.8182\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.9602 - sparse_categorical_accuracy: 0.7591 - val_loss: 0.6700 - val_sparse_categorical_accuracy: 0.8727\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.8503 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.6473 - val_sparse_categorical_accuracy: 0.8455\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.8354 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.5921 - val_sparse_categorical_accuracy: 0.8727\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 1s 72ms/step - loss: 0.6974 - sparse_categorical_accuracy: 0.8409 - val_loss: 0.4652 - val_sparse_categorical_accuracy: 0.9000\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.6304 - sparse_categorical_accuracy: 0.8455 - val_loss: 0.4628 - val_sparse_categorical_accuracy: 0.8818\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.5735 - sparse_categorical_accuracy: 0.8659 - val_loss: 0.4019 - val_sparse_categorical_accuracy: 0.8909\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.5507 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.4190 - val_sparse_categorical_accuracy: 0.9000\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.5081 - sparse_categorical_accuracy: 0.8795 - val_loss: 0.3334 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.4624 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.2787 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.4603 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.2757 - val_sparse_categorical_accuracy: 0.9182\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.4417 - sparse_categorical_accuracy: 0.8864 - val_loss: 0.2762 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.4007 - sparse_categorical_accuracy: 0.8955 - val_loss: 0.2612 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.3785 - sparse_categorical_accuracy: 0.9068 - val_loss: 0.2685 - val_sparse_categorical_accuracy: 0.9182\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.3651 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.2241 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.3270 - sparse_categorical_accuracy: 0.9227 - val_loss: 0.2274 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.3329 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.2136 - val_sparse_categorical_accuracy: 0.9364\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.3217 - sparse_categorical_accuracy: 0.9227 - val_loss: 0.2443 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.3113 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.1731 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.2569 - sparse_categorical_accuracy: 0.9341 - val_loss: 0.1890 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.2537 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.1906 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.2858 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.2302 - val_sparse_categorical_accuracy: 0.9182\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.2611 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.1244 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.2440 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.1641 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.2310 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.1677 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.2480 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.1564 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.2305 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.1403 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.1709 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1179 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.2106 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.1475 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.2211 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.2062 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1852 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1282 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1833 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1321 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 46/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 45ms/step - loss: 0.1512 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1107 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1407 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.0940 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1710 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1446 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1421 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1610 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1788 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.1501 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.1936 - val_sparse_categorical_accuracy: 0.9364\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1580 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1117 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1175 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0953 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1479 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.0950 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.1779 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.0818 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1431 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1552 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0974 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1128 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0936 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1105 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0804 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0818 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0983 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.1201 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0773 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1221 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0867 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1080 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0934 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1511 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1474 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1347 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1538 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1016 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1975 - val_sparse_categorical_accuracy: 0.9364\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1205 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0930 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1043 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0687 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.0520 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.0961 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0783 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.0785 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0788 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.0652 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1173 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.0876 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1410 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 0.1163 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1713 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 1s 70ms/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0647 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0674 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0780 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.1041 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.0629 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0585 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 83/600\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0963 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 0.0708 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0759 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.0573 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0583 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0635 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.1276 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0995 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1144 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0827 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0790 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0758 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 91/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1441 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0803 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.2435 - val_sparse_categorical_accuracy: 0.9364\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0681 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0603 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0429 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0640 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0545 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0578 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0942 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0514 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0828 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0854 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0498 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0478 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0768 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0487 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0629 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0382 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0482 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0459 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0366 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0778 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0483 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0467 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0403 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0500 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0411 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0458 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0324 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0419 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0420 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0545 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0562 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0587 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0316 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0566 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0305 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0331 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0506 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0453 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0344 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0336 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0466 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0279 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0413 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0334 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0480 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 121/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0359 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0682 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 122/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0302 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0912 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 123/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0533 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0898 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 124/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0499 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0527 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 125/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0455 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0364 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 126/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0301 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0382 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 127/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0316 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 128/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0242 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0437 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 129/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0272 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0305 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 130/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0257 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0455 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 131/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0581 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0567 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 132/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0406 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0524 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 133/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0322 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0697 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 134/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0218 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0321 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 135/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0365 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0506 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 136/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0346 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0685 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 137/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0324 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0837 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 138/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0524 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0982 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 139/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0357 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0255 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 140/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0426 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0208 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 141/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0856 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 142/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0664 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0492 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 143/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0746 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0672 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 144/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0411 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0292 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 145/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0414 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0663 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 146/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0332 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0356 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 147/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0317 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0620 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 148/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0365 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0458 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 149/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0529 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 150/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0360 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0389 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 151/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0288 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0775 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 152/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0513 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0799 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 153/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0252 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 154/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0323 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0370 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 155/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0362 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0778 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 156/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0377 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 157/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0188 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0175 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 158/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0194 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0399 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 159/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0248 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0456 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 160/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0329 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0369 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 161/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0280 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 162/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0241 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 163/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0449 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 164/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0474 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0634 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 165/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1363 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 166/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0981 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0639 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 167/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0568 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1497 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 168/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0659 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.1435 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 169/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0768 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1408 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 170/600\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.0714 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0571 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 171/600\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0584 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.2038 - val_sparse_categorical_accuracy: 0.9364 0s - loss: 0.0560 - sparse_categorical_accuracy\n",
      "Epoch 172/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.1510 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.2910 - val_sparse_categorical_accuracy: 0.8818\n",
      "Epoch 173/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.2121 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.1424 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 174/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0726 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1139 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 175/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0355 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0541 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 176/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0326 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 177/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0918 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 178/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0600 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0626 - val_sparse_categorical_accuracy: 0.9727\n",
      "Epoch 179/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0373 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0927 - val_sparse_categorical_accuracy: 0.9636\n",
      "Epoch 180/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0407 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0550 - val_sparse_categorical_accuracy: 0.9909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/600\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0508 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0839 - val_sparse_categorical_accuracy: 0.9818\n",
      "Epoch 182/600\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 0.0281 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0368 - val_sparse_categorical_accuracy: 0.9818\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmp7mk825oo\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmp7mk825oo\\assets\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatdata, labels):\n",
    "    X_train, X_val = formatdata[train_index], formatdata[test_index]\n",
    "    y_train, y_val = labels[train_index], labels[test_index]\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "#with open('number_model_full.tflite', 'wb') as f:\n",
    "#  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('number_model_full.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1330 test_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1320 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1313 run_step  **\n        outputs = model.test_step(data)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1267 test_step\n        y_pred = self(x, training=False)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_15 is incompatible with the layer: expected axis -1 of input shape to have value 2100 but received input with shape (None, 1152)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-d58d3bcec490>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m-> 3038\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3457\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3459\u001b[1;33m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[0;32m   3460\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3379\u001b[0m           expand_composites=True)\n\u001b[0;32m   3380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3381\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3382\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1330 test_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1320 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1313 run_step  **\n        outputs = model.test_step(data)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1267 test_step\n        y_pred = self(x, training=False)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_15 is incompatible with the layer: expected axis -1 of input shape to have value 2100 but received input with shape (None, 1152)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
